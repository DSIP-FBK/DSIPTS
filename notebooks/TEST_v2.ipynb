{
 "cells": [
  {
   "cell_type": "raw",
   "id": "55c75749-ec70-4365-ac8a-f96552da4528",
   "metadata": {},
   "source": [
    "from dsipts import Categorical,TimeSeries, RNN\n",
    "settimana = Categorical('settimanale',1,[1,1,1,1,1,1,1],7,'multiplicative',[0.9,0.8,0.7,0.6,0.5,0.99,0.99])\n",
    "\n",
    "##montly, additive (here there are only 5 month)\n",
    "mese = Categorical('mensile',1,[31,28,20,10,33],5,'additive',[10,20,-10,20,0])\n",
    "\n",
    "##spot categorical variables: in this case it occurs every 100 days and it lasts 7 days adding 10 to the original timeseries\n",
    "spot = Categorical('spot',100,[7],1,'additive',[10])\n",
    "\n",
    "##initizate a timeseries object\n",
    "ts = TimeSeries('prova')\n",
    "ts.generate_signal(noise_mean=1,categorical_variables=[settimana,mese,spot],length=5000,type=0)\n",
    "dataset = ts.dataset\n",
    "dataset['x_num'] = 0.0\n",
    "dataset.loc[:dataset.shape[0]-10,'x_num']= dataset['x_num'].values[9:]\n",
    "cat_var_past = ts.cat_var\n",
    "cat_var_fut = ts.cat_fut\n",
    "num_var_past = ts.num_var+['x_num']\n",
    "import pickle \n",
    "with open('example.pkl', 'wb') as f:\n",
    "    pickle.dump([dataset,cat_var_past,cat_var_fut,num_var_past],f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "459c491c-98ab-4513-b5eb-9f5c604b9df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.to_csv('dataset.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b53411e-8c81-4dc9-8e2e-c83c3a568be1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "beea9295-9164-4bae-b2e1-8c5cc6c585c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import pandas as pd\n",
    "from typing import Union,List, Optional, Dict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import datetime\n",
    "import lightning as L\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import torch\n",
    "from datetime import timedelta\n",
    "with open('example.pkl', 'rb') as f:\n",
    "    dataset,cat_var_past,cat_var_fut,num_var_past = pickle.load(f)\n",
    "num_var_fut = []\n",
    "group = None\n",
    "time_var = 'time'\n",
    "target = ['signal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "db453ed2-df16-44bf-bc86-184fd4010e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = dataset.copy()\n",
    "dataset2['group'] = 2\n",
    "dataset['group'] = 1 \n",
    "dataset = pd.concat([dataset, dataset2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3810de27-fc3b-44a3-b802-f88b9aa32c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extend_time_df(x:pd.DataFrame,time:str,freq:Union[str,int],group:Union[List[str],None]=None,global_minmax:bool=False)-> pd.DataFrame:\n",
    "  \n",
    "\n",
    "    if group is None:\n",
    "\n",
    "        if isinstance(freq,int):\n",
    "            empty = pd.DataFrame({'time':list(range(x[time].min(),x[time].max(),freq))})\n",
    "        else:\n",
    "            empty = pd.DataFrame({'time':pd.date_range(x[time].min(),x[time].max(),freq=freq)})\n",
    "\n",
    "    else:\n",
    "        \n",
    "        if global_minmax:\n",
    "            _min = x[time].min()\n",
    "            _max = x[time].max()\n",
    "            _min_max = pd.DataFrame({'min':min, 'max':max})\n",
    "            for c in group:\n",
    "               _min_max[c] = _min_max[c]\n",
    "        else:\n",
    "            _min = x.groupby(group)[time].min().reset_index().rename(columns={time:'min'})\n",
    "            _max = x.groupby(group)[time].max().reset_index().rename(columns={time:'max'})\n",
    "            _min_max = pd.merge(_min,_max)\n",
    "        empty = []\n",
    "        for _,row in _min_max.iterrows():\n",
    "            if isinstance(freq,int):\n",
    "                tmp = pd.DataFrame({time:np.arange(row['min'],row['max'],freq)})\n",
    "            else:\n",
    "                tmp = pd.DataFrame({time:pd.date_range(row['min'],row['max'],freq=freq)})\n",
    "            for c in group:\n",
    "               tmp[c] = row[c]\n",
    "            empty.append(tmp)\n",
    "\n",
    "        empty = pd.concat(empty,ignore_index=True)\n",
    "    return empty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8be88042-99da-4dff-8045-6152966315e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO @Sandeep please try to replicate what is in PandasTSDataSet but for a smore compact example!\n",
    "class PandasTSDataSet_MINIMAL:\n",
    "\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: pd.DataFrame,\n",
    "        time: Optional[str] = None,\n",
    "        target: Optional[Union[str, List[str]]] = None,\n",
    "        num: Optional[List[Union[str, List[str]]]] = None,\n",
    "        \n",
    "    ):\n",
    "\n",
    "        \n",
    "        self.time = time\n",
    "        self.target = _coerce_to_list(target)\n",
    "        self.num = _coerce_to_list(num)\n",
    "        self.data = data.copy()\n",
    "\n",
    "        \n",
    "        self.feature_cols = self.num \n",
    "        #use set ensuring unique columns\n",
    "        self.data = data[list(set(self.feature_cols + self.target + [self.time]))].copy()\n",
    "        \n",
    "\n",
    "        self.label_encoders = {}\n",
    "\n",
    "        ##ensure to have a coherent dataset\n",
    "        self.data.drop_duplicates(subset= [time],keep='first',inplace=True,ignore_index=True)\n",
    "\n",
    "        ##compute minumum frequency\n",
    "        freq = self.data['time'].diff.min()\n",
    "      \n",
    "\n",
    "        if isinstance(freq, timedelta):\n",
    "            freq = pd.to_timedelta(freq)   \n",
    "        elif isinstance(freq,  (int, float)):\n",
    "            freq = int(freq)\n",
    "        else:\n",
    "            raise TypeError(\"time must be integer or datetime\")\n",
    "        \n",
    "\n",
    "        ##extend dataset\n",
    "        self.data = extend_time_df(self.data,self.time,freq,None).merge(self.data,how='left').reset_index()\n",
    "\n",
    "        \n",
    "        self._groups = {\"_single_group\": self.data.index}\n",
    "        self._group_ids = [\"_single_group\"]\n",
    "\n",
    "        ## we know on the fly which rows are valid and wich contains nans\n",
    "        self.data['valid'] = ~pd.isnull(self.data.max(axis=1)) \n",
    "        \n",
    "        self._prepare_metadata()\n",
    "\n",
    "    def _prepare_metadata(self):\n",
    "        \"\"\"Prepare metadata for the dataset.\"\"\"\n",
    "        self.metadata = {\n",
    "            \"cols\": {\n",
    "                \"y\": self.target,\n",
    "                \"x\": self.feature_cols,\n",
    "                \"st\": [],\n",
    "            },\n",
    "            \"col_type\": {},\n",
    "            \"col_known\": {},\n",
    "            \"cat_index\":[]\n",
    "        }\n",
    "        for c in self.feature_cols:\n",
    "            if c in self.cat:\n",
    "                self.metadata['cat_index'].append(i)\n",
    "                \n",
    "     \n",
    "        all_cols = self.target + self.feature_cols \n",
    "        for col in all_cols:\n",
    "            self.metadata[\"col_type\"][col] = \"F\"\n",
    "\n",
    "            self.metadata[\"col_known\"][col] = \"K\" if col in self.feature_cols else \"U\"\n",
    "        self.metadata['encoders'] = self.label_encoders\n",
    "            \n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Return number of time series in the dataset.\"\"\"\n",
    "        return len(self._group_ids)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Dict[str, torch.Tensor]: ##NOT USED INDEX!\n",
    "        \"\"\"Get time series data for given index.\"\"\"\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "     \n",
    "        data = self.data.sort_values(by=self.time)\n",
    "\n",
    "        result = {\n",
    "            \"t\": data[self.time].values,\n",
    "            \"y\": torch.tensor(data[self.target].values,dtype=torch.float32,device=device),\n",
    "            \"x\": torch.tensor(data[self.feature_cols].values,dtype=torch.float32,device=device),\n",
    "            'is_valid': torch.tensor(data.valid.values,dtype=torch.int,device=device),\n",
    "        }\n",
    "\n",
    "       \n",
    "\n",
    "\n",
    "        return result\n",
    "\n",
    "    def get_metadata(self) -> Dict:\n",
    "        \"\"\"Return metadata about the dataset.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Dict\n",
    "            Dictionary containing:\n",
    "            - cols: column names for y, x, and static features\n",
    "            - col_type: mapping of columns to their types (F/C)\n",
    "            - col_known: mapping of columns to their future known status (K/U)\n",
    "        \"\"\"\n",
    "        return self.metadata\n",
    "\n",
    "def _coerce_to_list(obj):\n",
    "    \"\"\"Coerce object to list.\n",
    "\n",
    "    None is coerced to empty list, otherwise list constructor is used.\n",
    "    Single values are coerced into list\n",
    "    \"\"\"\n",
    "    if obj is None:\n",
    "        return []\n",
    "    if isinstance(obj,list):\n",
    "        return obj\n",
    "    else:\n",
    "        return [obj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "52e76fa2-1a64-40fe-b282-575edbf39e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PandasTSDataSet:\n",
    "\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: pd.DataFrame,\n",
    "        time: Optional[str] = None,\n",
    "        target: Optional[Union[str, List[str]]] = None,\n",
    "        group: Optional[List[str]] = None,\n",
    "        num: Optional[List[Union[str, List[str]]]] = None,\n",
    "        cat: Optional[List[Union[str, List[str]]]] = None,\n",
    "        known: Optional[List[Union[str, List[str]]]] = None,\n",
    "        unknown: Optional[List[Union[str, List[str]]]] = None,\n",
    "        static: Optional[List[Union[str, List[str]]]] = None,\n",
    "        label_encoders: Optional[dict] = None\n",
    "    ):\n",
    "\n",
    "        \n",
    "        self.time = time\n",
    "        self.target = _coerce_to_list(target)\n",
    "        self.num = _coerce_to_list(num)\n",
    "        self.cat = _coerce_to_list(cat)\n",
    "        self.known = _coerce_to_list(known)\n",
    "        self.unknown = _coerce_to_list(unknown)\n",
    "        self.static = _coerce_to_list(static)\n",
    "        self.data = data.copy()\n",
    "\n",
    "        self.group = _coerce_to_list(group)\n",
    "\n",
    "        \n",
    "        self.feature_cols = self.num + self.cat \n",
    "        #use set ensuring unique columns\n",
    "        self.data = data[list(set(self.static + self.feature_cols + self.target + [self.time] +self.group))].copy()\n",
    "        \n",
    "        ##Encoders for categorical since we want to return tensors\n",
    "        if label_encoders is None:\n",
    "            label_encoders = {}\n",
    "            ##Encoders for categorical since we want to return tensors\n",
    "            for c in self.cat+self.group:\n",
    "                label_encoders[c] = OrdinalEncoder()\n",
    "                self.data[c] = label_encoders[c].fit_transform(self.data[c].values.reshape(-1,1)).flatten()\n",
    "            self.label_encoders = label_encoders\n",
    "        else:\n",
    "            for c in self.cat+self.group:\n",
    "                self.data[c] = label_encoders[c].transform(self.data[c].values.reshape(-1,1)).flatten()\n",
    "            self.label_encoders = label_encoders\n",
    "\n",
    "        \n",
    "        ##ensure to have a coherent dataset\n",
    "        self.data.drop_duplicates(subset= self.group+[self.time],keep='first',inplace=True,ignore_index=True)\n",
    "\n",
    "        ##compute minumum frequency\n",
    "        if self.group is None:\n",
    "            freq = self.data[self.time].diff.min()\n",
    "        else:\n",
    "            freq = self.data.groupby(self.group).time.diff().min()\n",
    "\n",
    "        if isinstance(freq, timedelta):\n",
    "            freq = pd.to_timedelta(freq)   \n",
    "        elif isinstance(freq,  (int, float)):\n",
    "            freq = int(freq)\n",
    "        else:\n",
    "            raise TypeError(\"time must be integer or datetime\")\n",
    "        \n",
    "\n",
    "        ##extend dataset\n",
    "        self.data = extend_time_df(self.data,self.time,freq,self.group).merge(self.data,how='left').reset_index()\n",
    "\n",
    "        \n",
    "        ##now we are sure that data is in a coherent form!\n",
    "        self.lengths  = {}\n",
    "        if self.group:\n",
    "            self._groups = self.data.groupby(self.group).groups\n",
    "            self._group_ids =  list(self._groups.keys())\n",
    "            for k in self._groups:\n",
    "                self.lengths[k] = len(self._groups[k])\n",
    "        else:\n",
    "            self._groups = {0: self.data.index}\n",
    "            self._group_ids = [0]\n",
    "            self.lengths[0] = len( self.data.index)\n",
    "\n",
    "\n",
    "        \n",
    "        ## we know on the fly which rows are valid and wich contains nans\n",
    "        self.data['valid'] = ~pd.isnull(self.data.max(axis=1)) \n",
    "        \n",
    "        self._prepare_metadata()\n",
    "\n",
    "    def _prepare_metadata(self):\n",
    "        \"\"\"Prepare metadata for the dataset.\"\"\"\n",
    "        self.metadata = {\n",
    "            \"cols\": {\n",
    "                \"y\": self.target,\n",
    "                \"x\": self.feature_cols,\n",
    "                \"st\": self.static,\n",
    "            },\n",
    "            \"col_type\": {},\n",
    "            \"col_known\": {},\n",
    "            \"cat_index\":[]\n",
    "        }\n",
    "        for c in self.feature_cols:\n",
    "            if c in self.cat:\n",
    "                self.metadata['cat_index'].append(i)\n",
    "                \n",
    "        self.metadata[\"col_known\"]\n",
    "        all_cols = self.target + self.feature_cols + self.static\n",
    "        for col in all_cols:\n",
    "            self.metadata[\"col_type\"][col] = \"C\" if col in self.cat else \"F\"\n",
    "\n",
    "            self.metadata[\"col_known\"][col] = \"K\" if col in self.known else \"U\"\n",
    "        self.metadata['encoders'] = self.label_encoders\n",
    "            \n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Return number of time series in the dataset.\"\"\"\n",
    "        return len(self._group_ids)\n",
    "\n",
    "    def get_id_ts_by_idx(self,idx):\n",
    "        \n",
    "        tmp = np.cumsum(list(self.lengths.values()))\n",
    "        idx =  min(np.where(tmp>idx)[0])\n",
    "        return idx, 0 if idx==0 else tmp[idx-1]\n",
    "    \n",
    "    def get_total_len(self):\n",
    "        l = 0\n",
    "        for k in  self._groups:\n",
    "            l+= self.lengths[k]\n",
    "        return l\n",
    "    \n",
    "    def __getitem__(self, index: int) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"Get time series data for given index.\"\"\"\n",
    "        group_id = self._group_ids[index]\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        if self.group:\n",
    "            mask = self._groups[group_id]\n",
    "            data = self.data.loc[mask].sort_values(by=self.time)\n",
    "        else:\n",
    "            data = self.data.sort_values(by=self.time)\n",
    "\n",
    "        result = {\n",
    "            \"t\": data[self.time].values,\n",
    "            \"y\": torch.tensor(data[self.target].values,dtype=torch.float32,device=device),\n",
    "            \"x\": torch.tensor(data[self.feature_cols].values,dtype=torch.float32,device=device),\n",
    "            \"group\": torch.tensor([group_id],dtype=torch.float32,device=device),\n",
    "            \"st\": torch.tensor(data[self.static].iloc[0].values if self.static else []),\n",
    "            'is_valid': torch.tensor(data.valid.values,dtype=torch.int,device=device),\n",
    "        }\n",
    "\n",
    "       \n",
    "\n",
    "\n",
    "        return result\n",
    "\n",
    "    def get_metadata(self) -> Dict:\n",
    "        \"\"\"Return metadata about the dataset.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Dict\n",
    "            Dictionary containing:\n",
    "            - cols: column names for y, x, and static features\n",
    "            - col_type: mapping of columns to their types (F/C)\n",
    "            - col_known: mapping of columns to their future known status (K/U)\n",
    "        \"\"\"\n",
    "        return self.metadata\n",
    "\n",
    "def _coerce_to_list(obj):\n",
    "    \"\"\"Coerce object to list.\n",
    "\n",
    "    None is coerced to empty list, otherwise list constructor is used.\n",
    "    Single values are coerced into list\n",
    "    \"\"\"\n",
    "    if obj is None:\n",
    "        return []\n",
    "    if isinstance(obj,list):\n",
    "        return obj\n",
    "    else:\n",
    "        return [obj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "290ab40d-f440-4f7f-9ae9-8855a04f1ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module_metadata = dict(\n",
    "  perc_train= 0.7,\n",
    "  perc_valid= 0.1,\n",
    "    \n",
    "  range_train= None,\n",
    "  range_validation= None ,\n",
    "  range_test= None,\n",
    "  shift= 0,\n",
    "  starting_point= None,\n",
    "  skip_step= 1,\n",
    "  past_steps=16,\n",
    "  future_steps= 16,\n",
    "    precompute=True,\n",
    "  scaler= 'sklearn.preprocessing.StandardScaler()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "e4ca4055-7f36-446c-9b21-6c0456b152cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = PandasTSDataSet(dataset,\n",
    "                     'time', \n",
    "                     target, \n",
    "                     'group',\n",
    "                     list(set(num_var_past+num_var_fut)),\n",
    "                     list(set(cat_var_fut+cat_var_past)),\n",
    "                     list(set(cat_var_fut+num_var_fut)),\n",
    "                     list(set(cat_var_past+num_var_past)),\n",
    "                )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "519ebe66-3d64-41df-a191-81c0ba518e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "12bc5f1c-2de1-4837-9d2a-e764fa395bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import default_collate\n",
    "import torch\n",
    "def my_collate(batch):\n",
    "    batch = list(filter(lambda x : x is not None, batch))\n",
    "    print(len(batch))\n",
    "    return default_collate(batch)\n",
    "\n",
    "## @SANDEEP rework this using some cleaner code you can find here\n",
    "#https://colab.research.google.com/drive/1FvLlmEOgm3D3JgNFVeAtwPk4cXagJ0CY?usp=sharing#scrollTo=jFuSwWrhTg6y\n",
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self,data,metadata,valid_index)->torch.utils.data.Dataset:\n",
    "        \n",
    "        self.metadata = metadata\n",
    "        self.metadata_dataset = data.metadata\n",
    "        self.data = data\n",
    "        self.valid_index = valid_index\n",
    "        sum = 0\n",
    "        self.lengths = {}\n",
    "        #fix this, probably we need to add something (check validity, check past and future)\n",
    "        for k in self.valid_index:\n",
    "            sum+=(len(self.valid_index[k])-self.metadata['future_steps'])\n",
    "            self.lengths[k] = len(self.valid_index[k])\n",
    "        self.length = sum\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def get_id_ts_by_idx(self,idx):\n",
    "        \n",
    "        tmp = np.cumsum(list(self.lengths.values()))\n",
    "\n",
    "        idx =  min(np.where(tmp>idx)[0])\n",
    "        return idx, 0 if idx==0 else tmp[idx-1]\n",
    "    ## TODO: rewrite this using the Aryan code and names! and the D1 C, F and K U feature labeling!!\n",
    "    def __getitem__(self, idxs): \n",
    "\n",
    "        ##crucial point there: correctly identifying which are the indexes that we need!\n",
    "        sample = {}\n",
    "        IDX,difference = self.get_id_ts_by_idx(idxs)\n",
    "\n",
    "        idxs -= difference\n",
    "        idxs = self.valid_index[IDX][idxs]\n",
    "        tmp = self.data.__getitem__(IDX) ##use the getitem of the data!\n",
    "        \n",
    "        if idxs+self.metadata['future_steps']>self.data.lengths[IDX]:\n",
    "            return None\n",
    "        \n",
    "        for k in tmp.keys():\n",
    "\n",
    "            if len(tmp[k][idxs-self.metadata['past_steps']:idxs]) + len(tmp[k][idxs:idxs+self.metadata['future_steps']]) == self.metadata['future_steps']+self.metadata['past_steps']:\n",
    "                if tmp['is_valid'][idxs-self.metadata['past_steps']:idxs+self.metadata['future_steps']].sum()==self.metadata['future_steps']+self.metadata['past_steps']:\n",
    "                    if '_past' in k:\n",
    "                        sample[k] = tmp[k][idxs-self.metadata['past_steps']:idxs]\n",
    "                    elif '_fut' in k or k=='y':\n",
    "                        sample[k] = tmp[k][idxs:idxs+self.metadata['future_steps']]\n",
    "                    else:\n",
    "                        pass\n",
    "        if len(sample)==0:\n",
    "            return None\n",
    "        else:\n",
    "            return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "ac4a66d5-753b-4030-a88d-e5b8efd73d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ranges( d1_dataset,metadata):\n",
    "    ##suppose for now we use only percentage! \n",
    "    train_ranges = {}\n",
    "    valid_ranges = {}\n",
    "    test_ranges = {}\n",
    "    for k in d1_dataset.lengths:\n",
    "        ls = d1_dataset.lengths[k] \n",
    "        train_ranges[k] = list(range(0,int(metadata['perc_train']*ls)))\n",
    "        valid_ranges[k] = list(range(int(metadata['perc_train']*ls), int((metadata['perc_valid'] + metadata['perc_train'])*ls)))\n",
    "        test_ranges[k] = list(range(int((metadata['perc_valid'] + metadata['perc_train'])*ls),ls))\n",
    "        \n",
    "    ## in case of datetime ranges we need to use np.where and create a mask\n",
    "    return train_ranges,valid_ranges,test_ranges\n",
    "train_ranges,valid_ranges,test_ranges = compute_ranges( ds,data_module_metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "7e43bfd7-12b3-48c2-8b33-d5ca6681959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl =  DataLoader(\n",
    "            MyDataset(ds,data_module_metadata,train_ranges), ##change respect to the initial vignette, can not use standard dataset\n",
    "            batch_size=32,\n",
    "            collate_fn=my_collate\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "dde2ba1f-f6f8-483c-a404-5917b84ce37a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "torch.Size([16, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "16\n",
      "torch.Size([16, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "22\n",
      "torch.Size([22, 16, 1])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "for x in dl:\n",
    "    \n",
    "    print(x['y'].shape)  #It works! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaff143f-9754-4335-8a68-c5829d2d22d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "66c27834-a4a9-4f1d-81d3-35450823c9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ranges( d1_dataset,metadata):\n",
    "    ##suppose for now we use only percentage! \n",
    "    train_ranges = {}\n",
    "    valid_ranges = {}\n",
    "    test_ranges = {}\n",
    "    for k in d1_dataset.lengths:\n",
    "        ls = d1_dataset.lengths[k] ##the time\n",
    "        train_ranges[k] = list(range(0,int(metadata['perc_train']*ls)))\n",
    "        valid_ranges[k] = list(range(int(metadata['perc_train']*ls), int((metadata['perc_valid'] + metadata['perc_train'])*ls)))\n",
    "        test_ranges[k] = list(range(int(metadata['perc_valid'] + metadata['perc_train'])*ls),ls)\n",
    "        \n",
    "    ## in case of ranges we can \n",
    "    return train_ranges,valid_ranges,test_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "8f4c6bec-ee6e-4c54-9223-bf3a72ed46da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DecoderEncoderDataModule(L.LightningDataModule):\n",
    "    def __init__(self, d1_dataset, batch_size=32, num_workers=4,metadata=None):\n",
    "        super().__init__()\n",
    "        # initialize other  params\n",
    "        self.d1_dataset = d1_dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.metadata = metadata  \n",
    "\n",
    "\n",
    "    def prepare_data(self):\n",
    "    ##split is performed here\n",
    "        if self.metadata['precompute']:\n",
    "            self.precompute = True\n",
    "            ## @SANDEEP this is what is returned by DSIPTS split_for_train!! \n",
    "            ## the only difference is that we need to use the __getitem__ of the d1 layer\n",
    "            self.train_dataset, self.validation_dataset, self.test_dataset = split_data(self.d1_dataset,self.metadata)\n",
    "            \n",
    "            \n",
    "          \n",
    "        else:\n",
    "            self.precompute = False\n",
    "            ##in this case we need to pass only the data that are referring to the trainin period\n",
    "            ## but data can be chunked, we need to create a function that transform a D1 object into a D1 object or, even better\n",
    "            ## something that can be used by the dataset for filtering only valid samples!\n",
    "            ##for example\n",
    "            self.train_ranges, self.validation_ranges, self.test_ranges = compute_ranges(self.d1_dataset,self.metadata)\n",
    "            self.predict_data = None ##??? need to study this\n",
    "            ##TODO normalization???? maybe we can precompute here some statistics and pass them to the dataset!\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        # Get metadata from D1 layer during setup\n",
    "        #self.metadata = self.d1_dataset.get_metadata() ##NO SEE COMMENT BEFORE!\n",
    "        ##create dataset here\n",
    "        if stage == 'fit': \n",
    "            if self.precompute:\n",
    "                pass\n",
    "            else:\n",
    "                self.train_dataset = MyDataset(self.d1_dataset,self.train_ranges)\n",
    "                self.validation_dataset = MyDataset(self.validation_data,self.validation_ranges)\n",
    "                    \n",
    "        \n",
    "        if stage == 'test':\n",
    "            if self.precompute:\n",
    "                pass\n",
    "            else:\n",
    "                self.test_dataset = MyDataset(self.test_data,self.test_ranges)\n",
    "            \n",
    "        if stage == 'predict':\n",
    "            if self.precompute:\n",
    "                pass\n",
    "            else:\n",
    "                self.predict_datasset = MyDataset(self.predict_data)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size,shuffle=True,remove_last=True,collate_fn=my_collate)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.validation_dataset, batch_size=self.batch_size,shuffle=True,remove_last=True,collate_fn=my_collate)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size,shuffle=True,remove_last=True,collate_fn=my_collate)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(self.predict_datasset, batch_size=self.batch_size,shuffle=False,remove_last=False,collate_fn=my_collate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9a07bd-35cd-4cbd-8843-081b7d3d8580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694a020f-7f8d-4503-a023-bfdcda90667b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Layer M\n",
    "class DecoderEncoderModel(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.metadata = None\n",
    "        \n",
    "    def setup(self, stage=None):\n",
    "        # Get metadata from datamodule during setup\n",
    "        self.metadata = self.trainer.datamodule.metadata\n",
    "        \n",
    "        # Initialize layer T model using metadata\n",
    "    \n",
    "    def forward(self, x):\n",
    "     # forward logic\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec43226c-f99f-4a77-8793-c3e9db5c4536",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
