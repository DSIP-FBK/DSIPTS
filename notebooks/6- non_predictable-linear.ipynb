{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef8f4456-39e8-4bac-9514-dac172858380",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dsipts import TimeSeries, RNN,read_public_dataset, LinearTS, Persistent, TFT\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n",
    "import logging\n",
    "import sys\n",
    "import random\n",
    "\n",
    "file_handler = logging.FileHandler(filename='tmp.log')\n",
    "stdout_handler = logging.StreamHandler(stream=sys.stdout)\n",
    "handlers = [file_handler, stdout_handler]\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, \n",
    "    format='[%(asctime)s] {%(filename)s:%(lineno)d} %(levelname)s - %(message)s',\n",
    "    handlers=handlers\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "98dc5459-3670-4357-8059-f3cccade6431",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def random_walk(n):\n",
    "    tot = np.zeros(n)\n",
    "    probs = np.zeros(n)\n",
    "    for i in range(n-1):\n",
    "        prob = random.random()\n",
    "        if prob<0.5:\n",
    "            delta = 1\n",
    "        else:\n",
    "            delta = -1\n",
    "        tot[i+1] = tot[i] + delta\n",
    "        probs[i+1]= prob\n",
    "    return tot, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "b3f54954-cd4e-4651-90f5-c7c3d68be7d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>p</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.793340</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.821954</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.485035</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.261621</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>97.0</td>\n",
       "      <td>0.785012</td>\n",
       "      <td>19995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>96.0</td>\n",
       "      <td>0.908452</td>\n",
       "      <td>19996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>95.0</td>\n",
       "      <td>0.918215</td>\n",
       "      <td>19997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>96.0</td>\n",
       "      <td>0.488358</td>\n",
       "      <td>19998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>95.0</td>\n",
       "      <td>0.656042</td>\n",
       "      <td>19999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          y         p   time\n",
       "0       0.0  0.000000      0\n",
       "1      -1.0  0.793340      1\n",
       "2      -2.0  0.821954      2\n",
       "3      -1.0  0.485035      3\n",
       "4       0.0  0.261621      4\n",
       "...     ...       ...    ...\n",
       "19995  97.0  0.785012  19995\n",
       "19996  96.0  0.908452  19996\n",
       "19997  95.0  0.918215  19997\n",
       "19998  96.0  0.488358  19998\n",
       "19999  95.0  0.656042  19999\n",
       "\n",
       "[20000 rows x 3 columns]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "843f0c90-c4aa-4118-a167-e8e409c53092",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N = 20000\n",
    "random.seed(6)\n",
    "x, p = random_walk(N)\n",
    "data = pd.DataFrame({'y':x/x.max(),'p':p,'time':range(N)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "8ccce8d9-27b5-4d1f-82a7-9c2df21b89ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fab1c304c10>]"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "fe218d82-40f9-43c9-8118-818249679ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-13 11:15:30,423] {utils.py:24} INFO - \n",
      "\n",
      "[2023-10-13 11:15:30,424] {utils.py:25} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 11:15:30,425] {utils.py:26} INFO -                                                        I will drop duplicates, I dont like them                                                       \n",
      "[2023-10-13 11:15:30,426] {utils.py:27} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 11:15:30,429] {utils.py:29} INFO -                I will update past column adding all target columns, if you want to avoid this beahviour please use check_pass as false                \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timeseries named weather of length 20000.\n",
       " Categorical variable: [],\n",
       " Future variables: ['p'],\n",
       " Past variables: ['y'],\n",
       " Target variables: ['y']\n",
       " With no group"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##load the timeseries to the datastructure, adding the hour column and use all the covariates\n",
    "ts = TimeSeries('weather')\n",
    "ts.load_signal(data,enrich_cat=[],target_variables=['y'],past_variables= [],future_variables=['p'])\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e51045-5762-455c-9998-6129b3c7de46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "5dc5ed48-70d2-45d4-9c21-4a5eb8122290",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Let now prepare a model predictin the next 16 step using the past 16 steps \n",
    "past_steps = 64\n",
    "future_steps = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "3f6ad41f-6baf-43d2-961a-736a698785de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y']"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.past_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "e963fb18-02fe-4382-bf1a-ac27d62241e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "config = dict(model_configs =dict(\n",
    "                                    past_steps = past_steps,\n",
    "                                    future_steps = future_steps,\n",
    "                                    past_channels = len(ts.past_variables),\n",
    "                                    future_channels = len(ts.future_variables),\n",
    "                                    embs = [ts.dataset[c].nunique() for c in ts.cat_var],\n",
    "                                    cat_emb_dim = 8,\n",
    "                                    kernel_size = 3,\n",
    "                                     use_bn = False,\n",
    "                                    dropout_rate=0.0,\n",
    "                                      optim='torch.optim.Adam',\n",
    "                                      activation= 'torch.nn.PReLU',\n",
    "                                     sum_emb = True,\n",
    "                                     out_channels = len(ts.target_variables),\n",
    "                                    hidden_size = 16,\n",
    "                                    kind='linear',\n",
    "                                    quantiles= [],\n",
    "                                    persistence_weight = 1,\n",
    "                                    simple=False,loss_type='high_order'\n",
    "                                    ),\n",
    "                scheduler_config = dict(gamma=0.1,step_size=24000000000000000),\n",
    "                optim_config = dict(lr = 0.0005,weight_decay=0.00))\n",
    "model_linear = LinearTS(**config['model_configs'],optim_config = config['optim_config'],scheduler_config =config['scheduler_config'],verbose=False )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "1be1b3ad-36ef-4fdc-95df-cf0739633915",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-13 12:22:43,153] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 12:22:43,154] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 12:22:43,155] {utils.py:19} INFO - ####################################                                                                              ####################################\n",
      "[2023-10-13 12:22:43,155] {utils.py:20} INFO -                                                                   Setting the model                                                                   \n",
      "[2023-10-13 12:22:43,156] {utils.py:21} INFO - ####################################                                                                              ####################################\n",
      "[2023-10-13 12:22:43,157] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 12:22:43,158] {utils.py:31} INFO - LinearTS(\n",
      "  (embs): ModuleList()\n",
      "  (loss): L1Loss()\n",
      "  (linear): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=16, bias=True)\n",
      "      (1): PReLU(num_parameters=1)\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "      (3): Linear(in_features=16, out_features=8, bias=True)\n",
      "      (4): PReLU(num_parameters=1)\n",
      "      (5): Dropout(p=0.0, inplace=False)\n",
      "      (6): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (7): PReLU(num_parameters=1)\n",
      "      (8): Dropout(p=0.0, inplace=False)\n",
      "      (9): Linear(in_features=4, out_features=2, bias=True)\n",
      "      (10): PReLU(num_parameters=1)\n",
      "      (11): Dropout(p=0.0, inplace=False)\n",
      "      (12): Linear(in_features=2, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#set the desirere model\n",
    "ts.set_model(model_linear,config=config )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "2959dcdb-36fa-47c5-bc33-cc88c20d39ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##splitting parameters\n",
    "split_params = {'perc_train':0.6,'perc_valid':0.2,                             ##if not None it will split 70% 10% 20%\n",
    "               'range_train':None, 'range_validation':None, 'range_test':None, ## or we can split using ranges for example range_train=['2021-02-03','2022-04-08']\n",
    "               'past_steps':past_steps,\n",
    "               'future_steps':future_steps,\n",
    "               'shift':0,\n",
    "               'starting_point':None,                                          ## do not skip samples\n",
    "               'skip_step' : 1                                                 ## distance between two consecutive samples\n",
    "                             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fcda7e-4b30-45d7-9991-27dedcfd58cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-13 12:22:44,776] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 12:22:44,777] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 12:22:44,778] {utils.py:19} INFO - ####################################                                                                              ####################################\n",
      "[2023-10-13 12:22:44,779] {utils.py:20} INFO -                                                                   Training the model                                                                  \n",
      "[2023-10-13 12:22:44,780] {utils.py:21} INFO - ####################################                                                                              ####################################\n",
      "[2023-10-13 12:22:44,781] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 12:22:44,781] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 12:22:44,782] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 12:22:44,783] {utils.py:19} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 12:22:44,784] {utils.py:20} INFO -                                                                  Splitting for train                                                                  \n",
      "[2023-10-13 12:22:44,785] {utils.py:21} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 12:22:44,786] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 12:22:44,788] {utils.py:24} INFO - \n",
      "\n",
      "[2023-10-13 12:22:44,789] {utils.py:25} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 12:22:44,789] {utils.py:26} INFO -                                               Split temporally using perc_train: 0.6 and perc_valid:0.2                                               \n",
      "[2023-10-13 12:22:44,790] {utils.py:27} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 12:22:44,791] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 12:22:44,792] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 12:22:44,793] {utils.py:19} INFO - #########################                                                                                                    #########################\n",
      "[2023-10-13 12:22:44,794] {utils.py:20} INFO -                                                        Train categorical and numerical scalers                                                        \n",
      "[2023-10-13 12:22:44,795] {utils.py:21} INFO - #########################                                                                                                    #########################\n",
      "[2023-10-13 12:22:44,796] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 12:22:44,796] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 12:22:44,797] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 12:22:44,798] {utils.py:19} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 12:22:44,799] {utils.py:20} INFO -                                                                  Creating data loader                                                                 \n",
      "[2023-10-13 12:22:44,800] {utils.py:21} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 12:22:44,802] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 12:22:45,357] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 12:22:45,358] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 12:22:45,359] {utils.py:19} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 12:22:45,360] {utils.py:20} INFO -                                                                  Creating data loader                                                                 \n",
      "[2023-10-13 12:22:45,361] {utils.py:21} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 12:22:45,362] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 12:22:45,507] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 12:22:45,508] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 12:22:45,509] {utils.py:19} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 12:22:45,510] {utils.py:20} INFO -                                                                  Creating data loader                                                                 \n",
      "[2023-10-13 12:22:45,511] {utils.py:21} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 12:22:45,513] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 12:22:45,703] {utils.py:24} INFO - \n",
      "\n",
      "[2023-10-13 12:22:45,704] {utils.py:25} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 12:22:45,706] {utils.py:26} INFO -                                                        train:11872, validation:3872, test:3872                                                        \n",
      "[2023-10-13 12:22:45,707] {utils.py:27} INFO - ######################################################################################################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/agobbi/.conda/envs/tt/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:613: UserWarning: Checkpoint directory /home/agobbi/Projects/ExpTS/rf/linear exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "/home/agobbi/.conda/envs/tt/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/agobbi/.conda/envs/tt/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:488: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
      "  rank_zero_warn(\n",
      "/home/agobbi/.conda/envs/tt/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30812b96e3f340ba9f1d6143b3b906a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LR finder stopped early after 99 steps due to diverging loss.\n",
      "Learning rate set to 1.9054607179632475e-07\n",
      "Restoring states from the checkpoint path at /home/agobbi/Projects/ExpTS/rf/linear/.lr_find_497103a2-b7d9-4c33-a3b4-9d8d17f16619.ckpt\n",
      "Restored all states from the checkpoint file at /home/agobbi/Projects/ExpTS/rf/linear/.lr_find_497103a2-b7d9-4c33-a3b4-9d8d17f16619.ckpt\n",
      "\n",
      "  | Name   | Type       | Params\n",
      "--------------------------------------\n",
      "0 | embs   | ModuleList | 0     \n",
      "1 | loss   | L1Loss     | 0     \n",
      "2 | linear | ModuleList | 2.4 K \n",
      "--------------------------------------\n",
      "2.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n",
      "/home/agobbi/.conda/envs/tt/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "Epoch 0, global step 371: 'val_loss' reached 1.30809 (best 1.30809), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v43.ckpt' as top 1\n",
      "Epoch 1, global step 742: 'val_loss' reached 1.19119 (best 1.19119), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v43.ckpt' as top 1\n",
      "Epoch 2, global step 1113: 'val_loss' reached 1.11559 (best 1.11559), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v43.ckpt' as top 1\n",
      "Epoch 3, global step 1484: 'val_loss' reached 1.06052 (best 1.06052), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v43.ckpt' as top 1\n",
      "Epoch 4, global step 1855: 'val_loss' reached 1.01267 (best 1.01267), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v43.ckpt' as top 1\n",
      "Epoch 5, global step 2226: 'val_loss' reached 0.97153 (best 0.97153), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v43.ckpt' as top 1\n",
      "Epoch 6, global step 2597: 'val_loss' reached 0.94067 (best 0.94067), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v43.ckpt' as top 1\n",
      "Epoch 7, global step 2968: 'val_loss' reached 0.90396 (best 0.90396), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v43.ckpt' as top 1\n",
      "Epoch 8, global step 3339: 'val_loss' reached 0.88118 (best 0.88118), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v43.ckpt' as top 1\n",
      "Epoch 9, global step 3710: 'val_loss' reached 0.86614 (best 0.86614), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v43.ckpt' as top 1\n",
      "Epoch 10, global step 4081: 'val_loss' reached 0.85298 (best 0.85298), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v43.ckpt' as top 1\n",
      "Epoch 11, global step 4452: 'val_loss' reached 0.84233 (best 0.84233), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v43.ckpt' as top 1\n",
      "Epoch 12, global step 4823: 'val_loss' reached 0.83322 (best 0.83322), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v43.ckpt' as top 1\n",
      "Epoch 13, global step 5194: 'val_loss' reached 0.83172 (best 0.83172), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v43.ckpt' as top 1\n",
      "Epoch 14, global step 5565: 'val_loss' reached 0.82366 (best 0.82366), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v43.ckpt' as top 1\n",
      "Epoch 15, global step 5936: 'val_loss' was not in top 1\n",
      "Epoch 16, global step 6307: 'val_loss' reached 0.81947 (best 0.81947), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v43.ckpt' as top 1\n",
      "Epoch 17, global step 6678: 'val_loss' was not in top 1\n",
      "Epoch 18, global step 7049: 'val_loss' reached 0.81125 (best 0.81125), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v43.ckpt' as top 1\n",
      "Epoch 19, global step 7420: 'val_loss' reached 0.81041 (best 0.81041), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v43.ckpt' as top 1\n",
      "Epoch 20, global step 7791: 'val_loss' was not in top 1\n",
      "Epoch 21, global step 8162: 'val_loss' reached 0.80576 (best 0.80576), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v43.ckpt' as top 1\n",
      "Epoch 22, global step 8533: 'val_loss' was not in top 1\n",
      "Epoch 23, global step 8904: 'val_loss' reached 0.80255 (best 0.80255), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v43.ckpt' as top 1\n",
      "Epoch 24, global step 9275: 'val_loss' was not in top 1\n",
      "Epoch 25, global step 9646: 'val_loss' was not in top 1\n",
      "Epoch 26, global step 10017: 'val_loss' reached 0.80044 (best 0.80044), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v43.ckpt' as top 1\n",
      "Epoch 27, global step 10388: 'val_loss' was not in top 1\n",
      "Epoch 28, global step 10759: 'val_loss' was not in top 1\n",
      "Epoch 29, global step 11130: 'val_loss' reached 0.79947 (best 0.79947), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v43.ckpt' as top 1\n",
      "Epoch 30, global step 11501: 'val_loss' was not in top 1\n",
      "Epoch 31, global step 11872: 'val_loss' was not in top 1\n",
      "Epoch 32, global step 12243: 'val_loss' was not in top 1\n",
      "Epoch 33, global step 12614: 'val_loss' reached 0.79316 (best 0.79316), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v43.ckpt' as top 1\n",
      "Epoch 34, global step 12985: 'val_loss' was not in top 1\n",
      "Epoch 35, global step 13356: 'val_loss' was not in top 1\n",
      "Epoch 36, global step 13727: 'val_loss' was not in top 1\n",
      "Epoch 37, global step 14098: 'val_loss' was not in top 1\n"
     ]
    }
   ],
   "source": [
    "#train the model for 50 epochs with auto_lr_find \n",
    "ts.train_model(dirpath=f\"/home/agobbi/Projects/ExpTS/rf/linear\",\n",
    "               split_params=split_params,\n",
    "               batch_size=32,\n",
    "               num_workers=2,\n",
    "               max_epochs=100,\n",
    "               auto_lr_find=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "8d0974c9-fc85-436d-b7c7-c6605b2a423a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print the losses, check overfitting\n",
    "ts.losses.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "9df63a20-83b6-42c4-a7e4-30e4c7778cf3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-13 12:22:02,763] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 12:22:02,768] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 12:22:02,769] {utils.py:19} INFO - ######################                                                                                                          ######################\n",
      "[2023-10-13 12:22:02,770] {utils.py:20} INFO -                                                     Inference on a set (train, validation o test)                                                     \n",
      "[2023-10-13 12:22:02,772] {utils.py:21} INFO - ######################                                                                                                          ######################\n",
      "[2023-10-13 12:22:02,774] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 12:22:02,775] {utils.py:24} INFO - \n",
      "\n",
      "[2023-10-13 12:22:02,776] {utils.py:25} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 12:22:02,778] {utils.py:26} INFO - splitting using train parameters {'perc_train': 0.6, 'perc_valid': 0.2, 'range_train': None, 'range_validation': None, 'range_test': None, 'past_steps': 64, 'future_steps': 64, 'shift': 0, 'starting_point': None, 'skip_step': 1}\n",
      "[2023-10-13 12:22:02,779] {utils.py:27} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 12:22:02,781] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 12:22:02,784] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 12:22:02,785] {utils.py:19} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 12:22:02,787] {utils.py:20} INFO -                                                                  Splitting for train                                                                  \n",
      "[2023-10-13 12:22:02,788] {utils.py:21} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 12:22:02,789] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 12:22:02,790] {utils.py:24} INFO - \n",
      "\n",
      "[2023-10-13 12:22:02,791] {utils.py:25} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 12:22:02,791] {utils.py:26} INFO -                                               Split temporally using perc_train: 0.6 and perc_valid:0.2                                               \n",
      "[2023-10-13 12:22:02,792] {utils.py:27} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 12:22:02,793] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 12:22:02,794] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 12:22:02,795] {utils.py:19} INFO - #########################                                                                                                    #########################\n",
      "[2023-10-13 12:22:02,796] {utils.py:20} INFO -                                                        Train categorical and numerical scalers                                                        \n",
      "[2023-10-13 12:22:02,797] {utils.py:21} INFO - #########################                                                                                                    #########################\n",
      "[2023-10-13 12:22:02,798] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 12:22:02,799] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 12:22:02,800] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 12:22:02,801] {utils.py:19} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 12:22:02,802] {utils.py:20} INFO -                                                                  Creating data loader                                                                 \n",
      "[2023-10-13 12:22:02,802] {utils.py:21} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 12:22:02,803] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 12:22:03,260] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 12:22:03,261] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 12:22:03,262] {utils.py:19} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 12:22:03,263] {utils.py:20} INFO -                                                                  Creating data loader                                                                 \n",
      "[2023-10-13 12:22:03,264] {utils.py:21} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 12:22:03,265] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 12:22:03,395] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 12:22:03,396] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 12:22:03,396] {utils.py:19} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 12:22:03,397] {utils.py:20} INFO -                                                                  Creating data loader                                                                 \n",
      "[2023-10-13 12:22:03,398] {utils.py:21} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 12:22:03,400] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 12:22:03,542] {utils.py:29} INFO -                                                                    Device used: cpu                                                                   \n",
      "[2023-10-13 12:22:04,183] {utils.py:29} INFO -                                                                      Scaling back                                                                     \n"
     ]
    }
   ],
   "source": [
    "#make inferences on \n",
    "res = ts.inference_on_set(200,4,set='test',rescaling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "3cb2875c-5f47-4e47-9553-739dc821fe2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fab15dc4580>"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "lag = 10\n",
    "\n",
    "plt.plot(res[res.lag==lag].time, res[res.lag==lag].y,label='real',alpha=0.5)\n",
    "plt.plot(res[res.lag==lag].time, res[res.lag==lag].y_pred,label='pred',alpha=0.5)\n",
    "\n",
    "plt.title('Prediction on test for lag=7')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "77df437b-1a51-4447-89a4-3ccde0e393bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res['prediction_time'] = res.apply(lambda x: int(x.time-x.lag), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "b5110597-f859-47bd-afaf-d21f8f9ddc08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fab15b03b50>]"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = res.groupby('lag').apply(lambda x: np.sqrt(np.mean((x.y_pred-x.y)**2))).reset_index()\n",
    "plt.plot(error.lag,error[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "aaa18b47-eca2-4e5d-aebc-8d28e0c2f009",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.026814144"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error[0].mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "825d311e-c340-4e9e-8340-3f5e7d129201",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.026652765"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##0 -- 0.026814144\n",
    "##2 -- 0.026652765\n",
    "##5 -- 0.026685152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "65c0e384-596d-4f78-b867-36add5ce63a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.188419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.188246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.109994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2.150867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.118228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>60</td>\n",
       "      <td>4.406476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>61</td>\n",
       "      <td>4.446941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>62</td>\n",
       "      <td>4.653346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>63</td>\n",
       "      <td>4.655902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>4.651867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    lag         0\n",
       "0     1  2.188419\n",
       "1     2  2.188246\n",
       "2     3  2.109994\n",
       "3     4  2.150867\n",
       "4     5  2.118228\n",
       "..  ...       ...\n",
       "59   60  4.406476\n",
       "60   61  4.446941\n",
       "61   62  4.653346\n",
       "62   63  4.655902\n",
       "63   64  4.651867\n",
       "\n",
       "[64 rows x 2 columns]"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "55e04216-3178-4b2f-86ec-3abaad372424",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fab1edc9210>"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "date = 16066\n",
    "\n",
    "plt.plot(res[res.prediction_time==date].time, res[res.prediction_time==date].y,label='real',alpha=0.5)\n",
    "plt.plot(res[res.prediction_time==date].time, res[res.prediction_time==date].y_pred,label='pred',alpha=0.5)\n",
    "#plt.ylim(res.y.min(),res.y.max())\n",
    "plt.title('Prediction on test for lag=7')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bf41c3a1-4108-4d5e-a81f-baaaa00bcf26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'y_median'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## get the median MSE for each lag\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlag\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_median\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreset_index()\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m0\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m}) \n",
      "File \u001b[0;32m~/.conda/envs/tt/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:1567\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1559\u001b[0m     new_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe operation \u001b[39m\u001b[38;5;132;01m{\u001b[39;00morig_func\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failed on a column. If any error is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraised, this will raise an exception in a future version \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1562\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof pandas. Drop these columns to avoid this warning.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1563\u001b[0m     )\n\u001b[1;32m   1564\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m rewrite_warning(\n\u001b[1;32m   1565\u001b[0m         old_msg, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, new_msg\n\u001b[1;32m   1566\u001b[0m     ) \u001b[38;5;28;01mif\u001b[39;00m is_np_func \u001b[38;5;28;01melse\u001b[39;00m nullcontext():\n\u001b[0;32m-> 1567\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_apply_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selected_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   1569\u001b[0m     \u001b[38;5;66;03m# gh-20949\u001b[39;00m\n\u001b[1;32m   1570\u001b[0m     \u001b[38;5;66;03m# try again, with .apply acting as a filtering\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1574\u001b[0m     \u001b[38;5;66;03m# fails on *some* columns, e.g. a numeric operation\u001b[39;00m\n\u001b[1;32m   1575\u001b[0m     \u001b[38;5;66;03m# on a string grouper column\u001b[39;00m\n\u001b[1;32m   1577\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group_selection_context():\n\u001b[1;32m   1578\u001b[0m         \u001b[38;5;66;03m# GH#50538\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/tt/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:1629\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[0;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[0m\n\u001b[1;32m   1592\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   1593\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_python_apply_general\u001b[39m(\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1599\u001b[0m     is_agg: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1600\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[1;32m   1601\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1602\u001b[0m \u001b[38;5;124;03m    Apply function f in python space\u001b[39;00m\n\u001b[1;32m   1603\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1627\u001b[0m \u001b[38;5;124;03m        data after applying f\u001b[39;00m\n\u001b[1;32m   1628\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1629\u001b[0m     values, mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1630\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m not_indexed_same \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1631\u001b[0m         not_indexed_same \u001b[38;5;241m=\u001b[39m mutated \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmutated\n",
      "File \u001b[0;32m~/.conda/envs/tt/lib/python3.10/site-packages/pandas/core/groupby/ops.py:839\u001b[0m, in \u001b[0;36mBaseGrouper.apply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;66;03m# group might be modified\u001b[39;00m\n\u001b[1;32m    838\u001b[0m group_axes \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39maxes\n\u001b[0;32m--> 839\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mutated \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n\u001b[1;32m    841\u001b[0m     mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[74], line 3\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## get the median MSE for each lag\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m res\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlag\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39mnanmean((x\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m-\u001b[39m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_median\u001b[49m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m))\u001b[38;5;241m.\u001b[39mreset_index()\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m0\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m}) \n",
      "File \u001b[0;32m~/.conda/envs/tt/lib/python3.10/site-packages/pandas/core/generic.py:5902\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5895\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5896\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[1;32m   5897\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[1;32m   5898\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[1;32m   5899\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5900\u001b[0m ):\n\u001b[1;32m   5901\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[0;32m-> 5902\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'y_median'"
     ]
    }
   ],
   "source": [
    "## get the median MSE for each lag\n",
    "import numpy as np\n",
    "res.groupby('lag').apply(lambda x: np.nanmean((x.y-x.y_median)**2)).reset_index().rename(columns={0:'error'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8abe2ae-d010-4e95-b712-8e4084639d17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#save model \n",
    "ts.save(f\"{model_to_use}_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972f7417-48ea-4498-8724-89fb1eedccf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## load the model and check if we obtain the same result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1712bce-071f-4ea9-92bd-e4f4637ebb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.load(LinearTS,f\"{model_to_use}_test\",load_last=False)\n",
    "res = ts.inference_on_set(200,4,set='test',rescaling=True)\n",
    "error = res.groupby('lag').apply(lambda x: np.nanmean((x.y-x.y_median)**2)).reset_index().rename(columns={0:'error'}) \n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bcd30c-d798-4a15-8f8c-7587c807d284",
   "metadata": {},
   "outputs": [],
   "source": [
    "##print the mean MSE along the lag steps\n",
    "plt.plot(error.lag,error.error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b0f069-dc3c-4b16-9ede-747df97721f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "lag = 7\n",
    "try:\n",
    "    %matplotlib qast\n",
    "    to_plot = res\n",
    "except:\n",
    "    print('better to have qt, i will reduce the dataset')\n",
    "    plt.figure(figsize=(15,7))\n",
    "    to_plot = res[res.time>pd.to_datetime('2020-12-28')]\n",
    "plt.plot(to_plot[to_plot.lag==lag].time, to_plot[to_plot.lag==lag].y,label='real',alpha=0.5)\n",
    "plt.plot(to_plot[to_plot.lag==lag].time, to_plot[to_plot.lag==lag].y_median,label='median',alpha=0.5)\n",
    "plt.fill_between(to_plot[to_plot.lag==lag].time, to_plot[to_plot.lag==lag].y_low , to_plot[to_plot.lag==lag].y_high, alpha=0.2,label='error band')\n",
    "\n",
    "plt.title('Prediction on test for lag=7')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d6fd90-b6ae-4763-8d51-cb05de421797",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tot = pd.read_csv('/home/agobbi/Projects/ExpTS/csv/prova_test_tot_predictions.csv')\n",
    "tot.time = pd.to_datetime(tot.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f5246d-6540-4817-a342-bc164514ff29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pers = tot[(tot.model=='persistent_weather_1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f74643-7f33-411f-ba84-b046616ccb84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "lag = 7\n",
    "try:\n",
    "    %matplotlib qast\n",
    "    to_plot = pers\n",
    "except:\n",
    "    print('better to have qt, i will reduce the dataset')\n",
    "    plt.figure(figsize=(15,7))\n",
    "    to_plot = pers[pers.time>pd.to_datetime('2020-12-28')]\n",
    "plt.plot(to_plot[to_plot.lag==lag].time, to_plot[to_plot.lag==lag].y,label='real',alpha=0.5)\n",
    "plt.plot(to_plot[to_plot.lag==lag].time, to_plot[to_plot.lag==lag].y_pred,label='median',alpha=0.5)\n",
    "plt.fill_between(to_plot[to_plot.lag==lag].time, to_plot[to_plot.lag==lag].y_low , to_plot[to_plot.lag==lag].y_high, alpha=0.2,label='error band')\n",
    "\n",
    "plt.title('Prediction on test for lag=7')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470d8600-b39d-42b1-8ed4-b1cc198c2da3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
