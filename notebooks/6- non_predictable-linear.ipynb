{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef8f4456-39e8-4bac-9514-dac172858380",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dsipts import TimeSeries, RNN,read_public_dataset, LinearTS, Persistent, TFT\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n",
    "import logging\n",
    "import sys\n",
    "import random\n",
    "\n",
    "file_handler = logging.FileHandler(filename='tmp.log')\n",
    "stdout_handler = logging.StreamHandler(stream=sys.stdout)\n",
    "handlers = [file_handler, stdout_handler]\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, \n",
    "    format='[%(asctime)s] {%(filename)s:%(lineno)d} %(levelname)s - %(message)s',\n",
    "    handlers=handlers\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98dc5459-3670-4357-8059-f3cccade6431",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def random_walk(n):\n",
    "    tot = np.zeros(n)\n",
    "    probs = np.zeros(n)\n",
    "    for i in range(n-1):\n",
    "        prob = random.random()\n",
    "        if prob<0.5:\n",
    "            delta = 1\n",
    "        else:\n",
    "            delta = -1\n",
    "        tot[i+1] = tot[i] + delta\n",
    "        probs[i+1]= prob\n",
    "    return tot, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "843f0c90-c4aa-4118-a167-e8e409c53092",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N = 20000\n",
    "random.seed(6)\n",
    "x, p = random_walk(N)\n",
    "data = pd.DataFrame({'y':x/x.max(),'p':p,'time':range(N)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe218d82-40f9-43c9-8118-818249679ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-13 13:43:36,496] {utils.py:24} INFO - \n",
      "\n",
      "[2023-10-13 13:43:36,497] {utils.py:25} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 13:43:36,497] {utils.py:26} INFO -                                                        I will drop duplicates, I dont like them                                                       \n",
      "[2023-10-13 13:43:36,498] {utils.py:27} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 13:43:36,501] {utils.py:29} INFO -                I will update past column adding all target columns, if you want to avoid this beahviour please use check_pass as false                \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timeseries named weather of length 20000.\n",
       " Categorical variable: [],\n",
       " Future variables: ['p'],\n",
       " Past variables: ['y'],\n",
       " Target variables: ['y']\n",
       " With no group"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##load the timeseries to the datastructure, adding the hour column and use all the covariates\n",
    "ts = TimeSeries('weather')\n",
    "ts.load_signal(data,enrich_cat=[],target_variables=['y'],past_variables= [],future_variables=['p'])\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e51045-5762-455c-9998-6129b3c7de46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dc5ed48-70d2-45d4-9c21-4a5eb8122290",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Let now prepare a model predictin the next 16 step using the past 16 steps \n",
    "past_steps = 64\n",
    "future_steps = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f6ad41f-6baf-43d2-961a-736a698785de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.past_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e963fb18-02fe-4382-bf1a-ac27d62241e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "config = dict(model_configs =dict(\n",
    "                                    past_steps = past_steps,\n",
    "                                    future_steps = future_steps,\n",
    "                                    past_channels = len(ts.past_variables),\n",
    "                                    future_channels = len(ts.future_variables),\n",
    "                                    embs = [ts.dataset[c].nunique() for c in ts.cat_var],\n",
    "                                    cat_emb_dim = 8,\n",
    "                                    kernel_size = 3,\n",
    "                                     use_bn = False,\n",
    "                                    dropout_rate=0.0,\n",
    "                                      optim='torch.optim.Adam',\n",
    "                                      activation= 'torch.nn.PReLU',\n",
    "                                     sum_emb = True,\n",
    "                                     out_channels = len(ts.target_variables),\n",
    "                                    hidden_size = 64,\n",
    "                                    kind='linear',\n",
    "                                    quantiles= [],\n",
    "                                    persistence_weight =2,\n",
    "                                    simple=False,loss_type='additive_iv'\n",
    "                                    ),\n",
    "                scheduler_config = dict(gamma=0.1,step_size=24000000000000000),\n",
    "                optim_config = dict(lr = 0.0005,weight_decay=0.00))\n",
    "model_linear = LinearTS(**config['model_configs'],optim_config = config['optim_config'],scheduler_config =config['scheduler_config'],verbose=False )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1be1b3ad-36ef-4fdc-95df-cf0739633915",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-13 15:26:31,856] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 15:26:31,858] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:26:31,859] {utils.py:19} INFO - ####################################                                                                              ####################################\n",
      "[2023-10-13 15:26:31,860] {utils.py:20} INFO -                                                                   Setting the model                                                                   \n",
      "[2023-10-13 15:26:31,861] {utils.py:21} INFO - ####################################                                                                              ####################################\n",
      "[2023-10-13 15:26:31,864] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:26:31,866] {utils.py:31} INFO - LinearTS(\n",
      "  (embs): ModuleList()\n",
      "  (loss): L1Loss()\n",
      "  (linear): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (1): PReLU(num_parameters=1)\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "      (3): Linear(in_features=64, out_features=32, bias=True)\n",
      "      (4): PReLU(num_parameters=1)\n",
      "      (5): Dropout(p=0.0, inplace=False)\n",
      "      (6): Linear(in_features=32, out_features=16, bias=True)\n",
      "      (7): PReLU(num_parameters=1)\n",
      "      (8): Dropout(p=0.0, inplace=False)\n",
      "      (9): Linear(in_features=16, out_features=8, bias=True)\n",
      "      (10): PReLU(num_parameters=1)\n",
      "      (11): Dropout(p=0.0, inplace=False)\n",
      "      (12): Linear(in_features=8, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#set the desirere model\n",
    "ts.set_model(model_linear,config=config )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2959dcdb-36fa-47c5-bc33-cc88c20d39ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##splitting parameters\n",
    "split_params = {'perc_train':0.6,'perc_valid':0.2,                             ##if not None it will split 70% 10% 20%\n",
    "               'range_train':None, 'range_validation':None, 'range_test':None, ## or we can split using ranges for example range_train=['2021-02-03','2022-04-08']\n",
    "               'past_steps':past_steps,\n",
    "               'future_steps':future_steps,\n",
    "               'shift':0,\n",
    "               'starting_point':None,                                          ## do not skip samples\n",
    "               'skip_step' : 1                                                 ## distance between two consecutive samples\n",
    "                             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fcda7e-4b30-45d7-9991-27dedcfd58cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-13 15:26:32,445] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 15:26:32,447] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:26:32,448] {utils.py:19} INFO - ####################################                                                                              ####################################\n",
      "[2023-10-13 15:26:32,449] {utils.py:20} INFO -                                                                   Training the model                                                                  \n",
      "[2023-10-13 15:26:32,450] {utils.py:21} INFO - ####################################                                                                              ####################################\n",
      "[2023-10-13 15:26:32,451] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:26:32,453] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 15:26:32,454] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:26:32,455] {utils.py:19} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 15:26:32,457] {utils.py:20} INFO -                                                                  Splitting for train                                                                  \n",
      "[2023-10-13 15:26:32,459] {utils.py:21} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 15:26:32,461] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:26:32,463] {utils.py:24} INFO - \n",
      "\n",
      "[2023-10-13 15:26:32,464] {utils.py:25} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:26:32,465] {utils.py:26} INFO -                                               Split temporally using perc_train: 0.6 and perc_valid:0.2                                               \n",
      "[2023-10-13 15:26:32,466] {utils.py:27} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:26:32,468] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 15:26:32,469] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:26:32,470] {utils.py:19} INFO - #########################                                                                                                    #########################\n",
      "[2023-10-13 15:26:32,471] {utils.py:20} INFO -                                                        Train categorical and numerical scalers                                                        \n",
      "[2023-10-13 15:26:32,472] {utils.py:21} INFO - #########################                                                                                                    #########################\n",
      "[2023-10-13 15:26:32,473] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:26:32,475] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 15:26:32,476] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:26:32,478] {utils.py:19} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 15:26:32,479] {utils.py:20} INFO -                                                                  Creating data loader                                                                 \n",
      "[2023-10-13 15:26:32,480] {utils.py:21} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 15:26:32,481] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:26:32,937] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 15:26:32,937] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:26:32,938] {utils.py:19} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 15:26:32,939] {utils.py:20} INFO -                                                                  Creating data loader                                                                 \n",
      "[2023-10-13 15:26:32,940] {utils.py:21} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 15:26:32,941] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:26:33,083] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 15:26:33,084] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:26:33,085] {utils.py:19} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 15:26:33,086] {utils.py:20} INFO -                                                                  Creating data loader                                                                 \n",
      "[2023-10-13 15:26:33,087] {utils.py:21} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 15:26:33,088] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:26:33,233] {utils.py:24} INFO - \n",
      "\n",
      "[2023-10-13 15:26:33,234] {utils.py:25} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:26:33,235] {utils.py:26} INFO -                                                        train:11872, validation:3872, test:3872                                                        \n",
      "[2023-10-13 15:26:33,236] {utils.py:27} INFO - ######################################################################################################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/agobbi/.conda/envs/tt/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:613: UserWarning: Checkpoint directory /home/agobbi/Projects/ExpTS/rf/linear exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "/home/agobbi/.conda/envs/tt/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/agobbi/.conda/envs/tt/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:488: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
      "  rank_zero_warn(\n",
      "/home/agobbi/.conda/envs/tt/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d8b8f92cb81422086665327e1aa4ae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LR finder stopped early after 92 steps due to diverging loss.\n",
      "Learning rate set to 2.2908676527677735e-07\n",
      "Restoring states from the checkpoint path at /home/agobbi/Projects/ExpTS/rf/linear/.lr_find_d7af1aa4-ca7d-4266-a45b-200a4af84163.ckpt\n",
      "Restored all states from the checkpoint file at /home/agobbi/Projects/ExpTS/rf/linear/.lr_find_d7af1aa4-ca7d-4266-a45b-200a4af84163.ckpt\n",
      "\n",
      "  | Name   | Type       | Params\n",
      "--------------------------------------\n",
      "0 | embs   | ModuleList | 0     \n",
      "1 | loss   | L1Loss     | 0     \n",
      "2 | linear | ModuleList | 11.6 K\n",
      "--------------------------------------\n",
      "11.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "11.6 K    Total params\n",
      "0.046     Total estimated model params size (MB)\n",
      "/home/agobbi/.conda/envs/tt/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "Epoch 0, global step 371: 'val_loss' reached 0.13434 (best 0.13434), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v52.ckpt' as top 1\n",
      "Epoch 1, global step 742: 'val_loss' reached 0.11415 (best 0.11415), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v52.ckpt' as top 1\n",
      "Epoch 2, global step 1113: 'val_loss' reached 0.10847 (best 0.10847), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v52.ckpt' as top 1\n",
      "Epoch 3, global step 1484: 'val_loss' reached 0.10411 (best 0.10411), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v52.ckpt' as top 1\n",
      "Epoch 4, global step 1855: 'val_loss' reached 0.10081 (best 0.10081), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v52.ckpt' as top 1\n",
      "Epoch 5, global step 2226: 'val_loss' reached 0.09932 (best 0.09932), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v52.ckpt' as top 1\n",
      "Epoch 6, global step 2597: 'val_loss' reached 0.09598 (best 0.09598), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v52.ckpt' as top 1\n",
      "Epoch 7, global step 2968: 'val_loss' reached 0.09502 (best 0.09502), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v52.ckpt' as top 1\n",
      "Epoch 8, global step 3339: 'val_loss' reached 0.09311 (best 0.09311), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v52.ckpt' as top 1\n",
      "Epoch 9, global step 3710: 'val_loss' reached 0.09199 (best 0.09199), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v52.ckpt' as top 1\n",
      "Epoch 10, global step 4081: 'val_loss' was not in top 1\n",
      "Epoch 11, global step 4452: 'val_loss' reached 0.09101 (best 0.09101), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v52.ckpt' as top 1\n",
      "Epoch 12, global step 4823: 'val_loss' reached 0.09030 (best 0.09030), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v52.ckpt' as top 1\n",
      "Epoch 13, global step 5194: 'val_loss' reached 0.08963 (best 0.08963), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v52.ckpt' as top 1\n",
      "Epoch 14, global step 5565: 'val_loss' was not in top 1\n",
      "Epoch 15, global step 5936: 'val_loss' was not in top 1\n",
      "Epoch 16, global step 6307: 'val_loss' was not in top 1\n",
      "Epoch 17, global step 6678: 'val_loss' reached 0.08937 (best 0.08937), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v52.ckpt' as top 1\n",
      "Epoch 18, global step 7049: 'val_loss' reached 0.08888 (best 0.08888), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v52.ckpt' as top 1\n",
      "Epoch 19, global step 7420: 'val_loss' reached 0.08777 (best 0.08777), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v52.ckpt' as top 1\n",
      "Epoch 20, global step 7791: 'val_loss' was not in top 1\n",
      "Epoch 21, global step 8162: 'val_loss' reached 0.08718 (best 0.08718), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v52.ckpt' as top 1\n",
      "Epoch 22, global step 8533: 'val_loss' was not in top 1\n",
      "Epoch 23, global step 8904: 'val_loss' was not in top 1\n",
      "Epoch 24, global step 9275: 'val_loss' reached 0.08638 (best 0.08638), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v52.ckpt' as top 1\n",
      "Epoch 25, global step 9646: 'val_loss' was not in top 1\n",
      "Epoch 26, global step 10017: 'val_loss' was not in top 1\n",
      "Epoch 27, global step 10388: 'val_loss' reached 0.08601 (best 0.08601), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v52.ckpt' as top 1\n",
      "Epoch 28, global step 10759: 'val_loss' reached 0.08538 (best 0.08538), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v52.ckpt' as top 1\n",
      "Epoch 29, global step 11130: 'val_loss' was not in top 1\n",
      "Epoch 30, global step 11501: 'val_loss' was not in top 1\n",
      "Epoch 31, global step 11872: 'val_loss' was not in top 1\n",
      "Epoch 32, global step 12243: 'val_loss' was not in top 1\n",
      "Epoch 33, global step 12614: 'val_loss' was not in top 1\n",
      "Epoch 34, global step 12985: 'val_loss' was not in top 1\n",
      "Epoch 35, global step 13356: 'val_loss' was not in top 1\n",
      "Epoch 36, global step 13727: 'val_loss' was not in top 1\n",
      "Epoch 37, global step 14098: 'val_loss' was not in top 1\n",
      "Epoch 38, global step 14469: 'val_loss' was not in top 1\n",
      "Epoch 39, global step 14840: 'val_loss' was not in top 1\n",
      "Epoch 40, global step 15211: 'val_loss' was not in top 1\n",
      "Epoch 41, global step 15582: 'val_loss' was not in top 1\n",
      "Epoch 42, global step 15953: 'val_loss' was not in top 1\n",
      "Epoch 43, global step 16324: 'val_loss' was not in top 1\n",
      "Epoch 44, global step 16695: 'val_loss' was not in top 1\n",
      "Epoch 45, global step 17066: 'val_loss' was not in top 1\n",
      "Epoch 46, global step 17437: 'val_loss' was not in top 1\n",
      "Epoch 47, global step 17808: 'val_loss' was not in top 1\n",
      "Epoch 48, global step 18179: 'val_loss' was not in top 1\n",
      "Epoch 49, global step 18550: 'val_loss' was not in top 1\n",
      "Epoch 50, global step 18921: 'val_loss' was not in top 1\n",
      "Epoch 51, global step 19292: 'val_loss' was not in top 1\n",
      "Epoch 52, global step 19663: 'val_loss' was not in top 1\n",
      "Epoch 53, global step 20034: 'val_loss' was not in top 1\n",
      "Epoch 54, global step 20405: 'val_loss' reached 0.08519 (best 0.08519), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v52.ckpt' as top 1\n",
      "Epoch 55, global step 20776: 'val_loss' reached 0.08488 (best 0.08488), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v52.ckpt' as top 1\n",
      "Epoch 56, global step 21147: 'val_loss' was not in top 1\n",
      "Epoch 57, global step 21518: 'val_loss' was not in top 1\n",
      "Epoch 58, global step 21889: 'val_loss' was not in top 1\n",
      "Epoch 59, global step 22260: 'val_loss' reached 0.08478 (best 0.08478), saving model to '/home/agobbi/Projects/ExpTS/rf/linear/checkpoint-v52.ckpt' as top 1\n"
     ]
    }
   ],
   "source": [
    "#train the model for 50 epochs with auto_lr_find \n",
    "ts.train_model(dirpath=f\"/home/agobbi/Projects/ExpTS/rf/linear\",\n",
    "               split_params=split_params,\n",
    "               batch_size=32,\n",
    "               num_workers=2,\n",
    "               max_epochs=100,\n",
    "               auto_lr_find=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0974c9-fc85-436d-b7c7-c6605b2a423a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Print the losses, check overfitting\n",
    "ts.losses.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9df63a20-83b6-42c4-a7e4-30e4c7778cf3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-13 15:26:02,606] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 15:26:02,608] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:26:02,610] {utils.py:19} INFO - ######################                                                                                                          ######################\n",
      "[2023-10-13 15:26:02,611] {utils.py:20} INFO -                                                     Inference on a set (train, validation o test)                                                     \n",
      "[2023-10-13 15:26:02,614] {utils.py:21} INFO - ######################                                                                                                          ######################\n",
      "[2023-10-13 15:26:02,620] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:26:02,622] {utils.py:24} INFO - \n",
      "\n",
      "[2023-10-13 15:26:02,624] {utils.py:25} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:26:02,628] {utils.py:26} INFO - splitting using train parameters {'perc_train': 0.6, 'perc_valid': 0.2, 'range_train': None, 'range_validation': None, 'range_test': None, 'past_steps': 64, 'future_steps': 64, 'shift': 0, 'starting_point': None, 'skip_step': 1}\n",
      "[2023-10-13 15:26:02,630] {utils.py:27} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:26:02,634] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 15:26:02,636] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:26:02,640] {utils.py:19} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 15:26:02,642] {utils.py:20} INFO -                                                                  Splitting for train                                                                  \n",
      "[2023-10-13 15:26:02,643] {utils.py:21} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 15:26:02,644] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:26:02,645] {utils.py:24} INFO - \n",
      "\n",
      "[2023-10-13 15:26:02,646] {utils.py:25} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:26:02,647] {utils.py:26} INFO -                                               Split temporally using perc_train: 0.6 and perc_valid:0.2                                               \n",
      "[2023-10-13 15:26:02,648] {utils.py:27} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:26:02,649] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 15:26:02,650] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:26:02,652] {utils.py:19} INFO - #########################                                                                                                    #########################\n",
      "[2023-10-13 15:26:02,653] {utils.py:20} INFO -                                                        Train categorical and numerical scalers                                                        \n",
      "[2023-10-13 15:26:02,654] {utils.py:21} INFO - #########################                                                                                                    #########################\n",
      "[2023-10-13 15:26:02,655] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:26:02,655] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 15:26:02,656] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:26:02,657] {utils.py:19} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 15:26:02,658] {utils.py:20} INFO -                                                                  Creating data loader                                                                 \n",
      "[2023-10-13 15:26:02,659] {utils.py:21} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 15:26:02,660] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:26:03,120] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 15:26:03,124] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:26:03,125] {utils.py:19} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 15:26:03,126] {utils.py:20} INFO -                                                                  Creating data loader                                                                 \n",
      "[2023-10-13 15:26:03,128] {utils.py:21} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 15:26:03,129] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:26:03,287] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 15:26:03,291] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:26:03,295] {utils.py:19} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 15:26:03,298] {utils.py:20} INFO -                                                                  Creating data loader                                                                 \n",
      "[2023-10-13 15:26:03,302] {utils.py:21} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 15:26:03,306] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:26:03,630] {utils.py:29} INFO -                                                                    Device used: cpu                                                                   \n",
      "[2023-10-13 15:26:04,654] {utils.py:29} INFO -                                                                      Scaling back                                                                     \n"
     ]
    }
   ],
   "source": [
    "#make inferences on \n",
    "res = ts.inference_on_set(200,4,set='test',rescaling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3cb2875c-5f47-4e47-9553-739dc821fe2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f93f8502050>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "lag = 10\n",
    "\n",
    "plt.plot(res[res.lag==lag].time, res[res.lag==lag].y,label='real',alpha=0.5)\n",
    "plt.plot(res[res.lag==lag].time, res[res.lag==lag].y_pred,label='pred',alpha=0.5)\n",
    "\n",
    "plt.title('Prediction on test for lag=7')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b5110597-f859-47bd-afaf-d21f8f9ddc08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f937f71f040>]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = res.groupby('lag').apply(lambda x: np.sqrt(np.mean((x.y_pred-x.y)**2))).reset_index()\n",
    "plt.plot(error.lag,error[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aaa18b47-eca2-4e5d-aebc-8d28e0c2f009",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.027390912"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error[0].mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ef4256-7518-4418-878f-a7f3681be2ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e439300-d754-4ee7-a7c3-4dc4891e8bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39f5fef-92e5-4e6a-81c7-21cc0f39d473",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.5 --  0.026778758\n",
    "#0   -- 0.027390912"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "825d311e-c340-4e9e-8340-3f5e7d129201",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.026652765"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##0 -- 0.026814144\n",
    "##2 -- 0.026652765\n",
    "##5 -- 0.026685152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65c0e384-596d-4f78-b867-36add5ce63a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.019626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.020414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.018932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.018823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.019095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>60</td>\n",
       "      <td>0.035511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>61</td>\n",
       "      <td>0.036271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>62</td>\n",
       "      <td>0.037724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>63</td>\n",
       "      <td>0.037139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>0.037839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    lag         0\n",
       "0     1  0.019626\n",
       "1     2  0.020414\n",
       "2     3  0.018932\n",
       "3     4  0.018823\n",
       "4     5  0.019095\n",
       "..  ...       ...\n",
       "59   60  0.035511\n",
       "60   61  0.036271\n",
       "61   62  0.037724\n",
       "62   63  0.037139\n",
       "63   64  0.037839\n",
       "\n",
       "[64 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "55e04216-3178-4b2f-86ec-3abaad372424",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fab1edc9210>"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "date = 16066\n",
    "\n",
    "plt.plot(res[res.prediction_time==date].time, res[res.prediction_time==date].y,label='real',alpha=0.5)\n",
    "plt.plot(res[res.prediction_time==date].time, res[res.prediction_time==date].y_pred,label='pred',alpha=0.5)\n",
    "#plt.ylim(res.y.min(),res.y.max())\n",
    "plt.title('Prediction on test for lag=7')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bf41c3a1-4108-4d5e-a81f-baaaa00bcf26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'y_median'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## get the median MSE for each lag\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlag\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_median\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreset_index()\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m0\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m}) \n",
      "File \u001b[0;32m~/.conda/envs/tt/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:1567\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1559\u001b[0m     new_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe operation \u001b[39m\u001b[38;5;132;01m{\u001b[39;00morig_func\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failed on a column. If any error is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraised, this will raise an exception in a future version \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1562\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof pandas. Drop these columns to avoid this warning.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1563\u001b[0m     )\n\u001b[1;32m   1564\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m rewrite_warning(\n\u001b[1;32m   1565\u001b[0m         old_msg, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, new_msg\n\u001b[1;32m   1566\u001b[0m     ) \u001b[38;5;28;01mif\u001b[39;00m is_np_func \u001b[38;5;28;01melse\u001b[39;00m nullcontext():\n\u001b[0;32m-> 1567\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_apply_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selected_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   1569\u001b[0m     \u001b[38;5;66;03m# gh-20949\u001b[39;00m\n\u001b[1;32m   1570\u001b[0m     \u001b[38;5;66;03m# try again, with .apply acting as a filtering\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1574\u001b[0m     \u001b[38;5;66;03m# fails on *some* columns, e.g. a numeric operation\u001b[39;00m\n\u001b[1;32m   1575\u001b[0m     \u001b[38;5;66;03m# on a string grouper column\u001b[39;00m\n\u001b[1;32m   1577\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group_selection_context():\n\u001b[1;32m   1578\u001b[0m         \u001b[38;5;66;03m# GH#50538\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/tt/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:1629\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[0;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[0m\n\u001b[1;32m   1592\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   1593\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_python_apply_general\u001b[39m(\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1599\u001b[0m     is_agg: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1600\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[1;32m   1601\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1602\u001b[0m \u001b[38;5;124;03m    Apply function f in python space\u001b[39;00m\n\u001b[1;32m   1603\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1627\u001b[0m \u001b[38;5;124;03m        data after applying f\u001b[39;00m\n\u001b[1;32m   1628\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1629\u001b[0m     values, mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1630\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m not_indexed_same \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1631\u001b[0m         not_indexed_same \u001b[38;5;241m=\u001b[39m mutated \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmutated\n",
      "File \u001b[0;32m~/.conda/envs/tt/lib/python3.10/site-packages/pandas/core/groupby/ops.py:839\u001b[0m, in \u001b[0;36mBaseGrouper.apply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;66;03m# group might be modified\u001b[39;00m\n\u001b[1;32m    838\u001b[0m group_axes \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39maxes\n\u001b[0;32m--> 839\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mutated \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n\u001b[1;32m    841\u001b[0m     mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[74], line 3\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## get the median MSE for each lag\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m res\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlag\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39mnanmean((x\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m-\u001b[39m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_median\u001b[49m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m))\u001b[38;5;241m.\u001b[39mreset_index()\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m0\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m}) \n",
      "File \u001b[0;32m~/.conda/envs/tt/lib/python3.10/site-packages/pandas/core/generic.py:5902\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5895\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5896\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[1;32m   5897\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[1;32m   5898\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[1;32m   5899\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5900\u001b[0m ):\n\u001b[1;32m   5901\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[0;32m-> 5902\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'y_median'"
     ]
    }
   ],
   "source": [
    "## get the median MSE for each lag\n",
    "import numpy as np\n",
    "res.groupby('lag').apply(lambda x: np.nanmean((x.y-x.y_median)**2)).reset_index().rename(columns={0:'error'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8abe2ae-d010-4e95-b712-8e4084639d17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#save model \n",
    "ts.save(f\"{model_to_use}_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972f7417-48ea-4498-8724-89fb1eedccf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## load the model and check if we obtain the same result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1712bce-071f-4ea9-92bd-e4f4637ebb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.load(LinearTS,f\"{model_to_use}_test\",load_last=False)\n",
    "res = ts.inference_on_set(200,4,set='test',rescaling=True)\n",
    "error = res.groupby('lag').apply(lambda x: np.nanmean((x.y-x.y_median)**2)).reset_index().rename(columns={0:'error'}) \n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bcd30c-d798-4a15-8f8c-7587c807d284",
   "metadata": {},
   "outputs": [],
   "source": [
    "##print the mean MSE along the lag steps\n",
    "plt.plot(error.lag,error.error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b0f069-dc3c-4b16-9ede-747df97721f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "lag = 7\n",
    "try:\n",
    "    %matplotlib qast\n",
    "    to_plot = res\n",
    "except:\n",
    "    print('better to have qt, i will reduce the dataset')\n",
    "    plt.figure(figsize=(15,7))\n",
    "    to_plot = res[res.time>pd.to_datetime('2020-12-28')]\n",
    "plt.plot(to_plot[to_plot.lag==lag].time, to_plot[to_plot.lag==lag].y,label='real',alpha=0.5)\n",
    "plt.plot(to_plot[to_plot.lag==lag].time, to_plot[to_plot.lag==lag].y_median,label='median',alpha=0.5)\n",
    "plt.fill_between(to_plot[to_plot.lag==lag].time, to_plot[to_plot.lag==lag].y_low , to_plot[to_plot.lag==lag].y_high, alpha=0.2,label='error band')\n",
    "\n",
    "plt.title('Prediction on test for lag=7')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d6fd90-b6ae-4763-8d51-cb05de421797",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tot = pd.read_csv('/home/agobbi/Projects/ExpTS/csv/prova_test_tot_predictions.csv')\n",
    "tot.time = pd.to_datetime(tot.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f5246d-6540-4817-a342-bc164514ff29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pers = tot[(tot.model=='persistent_weather_1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f74643-7f33-411f-ba84-b046616ccb84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "lag = 7\n",
    "try:\n",
    "    %matplotlib qast\n",
    "    to_plot = pers\n",
    "except:\n",
    "    print('better to have qt, i will reduce the dataset')\n",
    "    plt.figure(figsize=(15,7))\n",
    "    to_plot = pers[pers.time>pd.to_datetime('2020-12-28')]\n",
    "plt.plot(to_plot[to_plot.lag==lag].time, to_plot[to_plot.lag==lag].y,label='real',alpha=0.5)\n",
    "plt.plot(to_plot[to_plot.lag==lag].time, to_plot[to_plot.lag==lag].y_pred,label='median',alpha=0.5)\n",
    "plt.fill_between(to_plot[to_plot.lag==lag].time, to_plot[to_plot.lag==lag].y_low , to_plot[to_plot.lag==lag].y_high, alpha=0.2,label='error band')\n",
    "\n",
    "plt.title('Prediction on test for lag=7')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470d8600-b39d-42b1-8ed4-b1cc198c2da3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
