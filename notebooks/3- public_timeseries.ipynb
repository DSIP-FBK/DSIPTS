{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8f4456-39e8-4bac-9514-dac172858380",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dsipts import TimeSeries, RNN, Attention,read_public_dataset, LinearTS, Persistent\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dc5459-3670-4357-8059-f3cccade6431",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## reading weather dataset\n",
    "## time column is the time, y is the target, the others are covariates (in the past)\n",
    "data, columns = read_public_dataset('/home/agobbi/Projects/ExpTS/data','weather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3aa4ec-16b8-4c83-a32b-b446dd5605a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0eb8ff-69e9-43ca-a8b4-c874be1bd8b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_to_use = 'linear' #attention, rnn\n",
    "use_covariates = False  #use only y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e51045-5762-455c-9998-6129b3c7de46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##load the timeseries to the datastructure, adding the hour column and use all the covariates\n",
    "ts = TimeSeries('weather')\n",
    "if model_to_use!='attention':\n",
    "    ts.load_signal(data,enrich_cat=['hour'],target_variables=['y'],past_variables=columns if use_covariates else [])\n",
    "else:\n",
    "    ##attention will use also y in the future, using a masking mechanism\n",
    "    ts.load_signal(data,enrich_cat=['hour'],target_variables=['y'],future_variables=['y'],past_variables=columns if use_covariates else [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a22ed7c-65b5-4f1b-b2d4-50359bf29be6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ts.past_variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d46b747-be56-48cb-84ae-ba7a5e3c61ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = ts.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc5ed48-70d2-45d4-9c21-4a5eb8122290",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Let now prepare a model predictin the next 16 step using the past 16 steps \n",
    "past_steps = 16\n",
    "future_steps = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b549a0-6b5d-4d13-b0b2-b6dbde63f37a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#RNN\n",
    "config = dict(model_configs =dict(\n",
    "                                    cat_emb_dim = 16,\n",
    "                                    hidden_RNN = 256,\n",
    "                                    num_layers_RNN = 2,\n",
    "                                    sum_emb = True,                                        #not influent here, there is only 'hour' as categorical variable\n",
    "                                    kind = 'lstm',\n",
    "                                    kernel_size_encoder = 7,\n",
    "                                    past_steps = past_steps,\n",
    "                                    future_steps = future_steps,\n",
    "                                    past_channels = len(ts.num_var),                       #parameter that depends on the ts dataset\n",
    "                                    future_channels = len(ts.future_variables),            #parameter that depends on the ts dataset\n",
    "                                    embs = [ts.dataset[c].nunique() for c in ts.cat_var],  #parameter that depends on the ts dataset\n",
    "                                    quantiles=[0.1,0.5,0.9],                               #use quantile loss\n",
    "                                    out_channels = len(ts.target_variables)),              #parameter that depends on the ts dataset\n",
    "                scheduler_config = dict(gamma=0.1,step_size=100),\n",
    "                optim_config = dict(lr = 0.0005,weight_decay=0.01))\n",
    "model_sum = RNN(**config['model_configs'],optim_config = config['optim_config'],scheduler_config =config['scheduler_config'] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71712372-65cd-4f29-8fda-4cc26555c801",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "config = dict(model_configs =dict(\n",
    "                                    past_channels = len(ts.num_var),\n",
    "                                    future_channels = len(ts.future_variables),\n",
    "                                    d_model = 128,\n",
    "                                    cat_emb_dim = 16,\n",
    "                                    num_heads = 8,\n",
    "                                    dropout = 0.5,\n",
    "                                    n_layer_encoder = 6,\n",
    "                                    n_layer_decoder  = 3,\n",
    "                                    past_steps = past_steps,\n",
    "                                    future_steps = future_steps,\n",
    "                                    embs = [ts.dataset[c].nunique() for c in ts.cat_var],\n",
    "                                    quantiles= [0.1,0.5,0.9],\n",
    "                                    out_channels= len(ts.target_variables)),\n",
    "                    scheduler_config = dict(gamma=0.1,step_size=100),\n",
    "                    optim_config = dict(lr = 0.0005,weight_decay=0.2))\n",
    "model_sum = Attention(**config['model_configs'],optim_config = config['optim_config'],scheduler_config =config['scheduler_config'] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e963fb18-02fe-4382-bf1a-ac27d62241e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "config = dict(model_configs =dict(\n",
    "                                    past_steps = past_steps,\n",
    "                                    future_steps = future_steps,\n",
    "                                    past_channels = len(ts.num_var),\n",
    "                                    future_channels = len(ts.future_variables),\n",
    "                                    embs = [ts.dataset[c].nunique() for c in ts.cat_var],\n",
    "                                    cat_emb_dim = 8,\n",
    "                                    kernel_size_encoder = 7,\n",
    "                                     sum_emb = True,\n",
    "                                     out_channels = len(ts.target_variables),\n",
    "                                    hidden_size = 256,\n",
    "                                   kind='nlinear',\n",
    "                                    quantiles=[],\n",
    "    \n",
    "                                    ),\n",
    "                scheduler_config = dict(gamma=0.1,step_size=24),\n",
    "                optim_config = dict(lr = 0.0005,weight_decay=0.01))\n",
    "model_sum = LinearTS(**config['model_configs'],optim_config = config['optim_config'],scheduler_config =config['scheduler_config'] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be1b3ad-36ef-4fdc-95df-cf0739633915",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#set the desirere model\n",
    "ts.set_model(model_sum,config=config )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2959dcdb-36fa-47c5-bc33-cc88c20d39ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##splitting parameters\n",
    "split_params = {'perc_train':0.7,'perc_valid':0.1,                             ##if not None it will split 70% 10% 20%\n",
    "               'range_train':None, 'range_validation':None, 'range_test':None, ## or we can split using ranges for example range_train=['2021-02-03','2022-04-08']\n",
    "               'past_steps':past_steps,\n",
    "               'future_steps':future_steps,\n",
    "               'shift':0 if model_to_use!='attention' else 1 ,                 ## if there is a shift in the dataset, usually for attention models\n",
    "               'starting_point':None,                                          ## do not skip samples\n",
    "               'skip_step' : 1                                                 ## distance between two consecutive samples\n",
    "                             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fcda7e-4b30-45d7-9991-27dedcfd58cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train the model for 50 epochs with auto_lr_find \n",
    "ts.train_model(dirpath=f\"/home/agobbi/Projects/ExpTS/tmp/{model_to_use}\",\n",
    "               split_params=split_params,\n",
    "               batch_size=128,\n",
    "               num_workers=4,\n",
    "               max_epochs=50,\n",
    "               auto_lr_find=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0974c9-fc85-436d-b7c7-c6605b2a423a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Print the losses, check overfitting\n",
    "ts.losses.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df63a20-83b6-42c4-a7e4-30e4c7778cf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#make inferences on \n",
    "res = ts.inference_on_set(200,4,set='test',rescaling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf41c3a1-4108-4d5e-a81f-baaaa00bcf26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## get the median MSE for each lag\n",
    "import numpy as np\n",
    "res.groupby('lag').apply(lambda x: np.nanmean((x.y-x.y_median)**2)).reset_index().rename(columns={0:'error'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8abe2ae-d010-4e95-b712-8e4084639d17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#save model \n",
    "ts.save(f\"{model_to_use}_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972f7417-48ea-4498-8724-89fb1eedccf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## load the model and check if we obtain the same result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1712bce-071f-4ea9-92bd-e4f4637ebb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.load(LinearTS,f\"{model_to_use}_test\",load_last=False)\n",
    "res = ts.inference_on_set(200,4,set='test',rescaling=True)\n",
    "error = res.groupby('lag').apply(lambda x: np.nanmean((x.y-x.y_median)**2)).reset_index().rename(columns={0:'error'}) \n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bcd30c-d798-4a15-8f8c-7587c807d284",
   "metadata": {},
   "outputs": [],
   "source": [
    "##print the mean MSE along the lag steps\n",
    "plt.plot(error.lag,error.error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b0f069-dc3c-4b16-9ede-747df97721f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "lag = 7\n",
    "try:\n",
    "    %matplotlib qast\n",
    "    to_plot = res\n",
    "except:\n",
    "    print('better to have qt, i will reduce the dataset')\n",
    "    plt.figure(figsize=(15,7))\n",
    "    to_plot = res[res.time>pd.to_datetime('2020-12-28')]\n",
    "plt.plot(to_plot[to_plot.lag==lag].time, to_plot[to_plot.lag==lag].y,label='real',alpha=0.5)\n",
    "plt.plot(to_plot[to_plot.lag==lag].time, to_plot[to_plot.lag==lag].y_median,label='median',alpha=0.5)\n",
    "plt.fill_between(to_plot[to_plot.lag==lag].time, to_plot[to_plot.lag==lag].y_low , to_plot[to_plot.lag==lag].y_high, alpha=0.2,label='error band')\n",
    "\n",
    "plt.title('Prediction on test for lag=7')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9476a7-b77c-4032-826d-aec889f71dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##check for persistence effects\n",
    "res['time_lagged'] = res.time-res.apply(lambda x: timedelta(minutes=10*x.lag),axis=1)\n",
    "res_pers = pd.merge(res,res[['time','y']].rename(columns={'time': 'time_lagged', 'y':'last'}).drop_duplicates(),on='time_lagged')\n",
    "error_persistent = res_pers.groupby('lag').apply(lambda x: np.nanmean((x['last']-x.y_median)**2)).reset_index().rename(columns={0:'error'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53338028-e70c-4c42-bddb-d3d1317f510f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09c29c7-437a-4fc4-8352-199a3bfb0080",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(error.lag,error.error,label='model')\n",
    "plt.plot(error_persistent.lag,error_persistent.error,label = 'persistent')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d6fd90-b6ae-4763-8d51-cb05de421797",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
