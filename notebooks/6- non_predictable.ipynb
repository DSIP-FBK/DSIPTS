{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef8f4456-39e8-4bac-9514-dac172858380",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dsipts import TimeSeries, RNN,read_public_dataset, LinearTS, Persistent, TFT\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n",
    "import logging\n",
    "import sys\n",
    "import random\n",
    "\n",
    "file_handler = logging.FileHandler(filename='tmp.log')\n",
    "stdout_handler = logging.StreamHandler(stream=sys.stdout)\n",
    "handlers = [file_handler, stdout_handler]\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, \n",
    "    format='[%(asctime)s] {%(filename)s:%(lineno)d} %(levelname)s - %(message)s',\n",
    "    handlers=handlers\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98dc5459-3670-4357-8059-f3cccade6431",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def random_walk(n):\n",
    "    tot = np.zeros(n)\n",
    "    probs = np.zeros(n)\n",
    "    for i in range(n-1):\n",
    "        prob = random.random()\n",
    "        if prob<0.5:\n",
    "            delta = 1\n",
    "        else:\n",
    "            delta = -1\n",
    "        tot[i+1] = tot[i] + delta\n",
    "        probs[i+1]= prob\n",
    "    return tot, probs\n",
    "N = 20000\n",
    "random.seed(6)\n",
    "x, p = random_walk(N)\n",
    "data = pd.DataFrame({'y':x/x.max(),'p':p,'time':range(N)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe218d82-40f9-43c9-8118-818249679ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-13 15:37:15,009] {utils.py:24} INFO - \n",
      "\n",
      "[2023-10-13 15:37:15,010] {utils.py:25} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:37:15,011] {utils.py:26} INFO -                                                        I will drop duplicates, I dont like them                                                       \n",
      "[2023-10-13 15:37:15,012] {utils.py:27} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:37:15,016] {utils.py:29} INFO -                I will update past column adding all target columns, if you want to avoid this beahviour please use check_pass as false                \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timeseries named weather of length 20000.\n",
       " Categorical variable: [],\n",
       " Future variables: ['p'],\n",
       " Past variables: ['y'],\n",
       " Target variables: ['y']\n",
       " With no group"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##loasklearnthe timeseries to the datastructure, adding the hour column and use all the covariates\n",
    "ts = TimeSeries('weather')\n",
    "ts.load_signal(data,enrich_cat=[],target_variables=['y'],past_variables= [],future_variables=['p'])\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e51045-5762-455c-9998-6129b3c7de46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dc5ed48-70d2-45d4-9c21-4a5eb8122290",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Let now prepare a model predictin the next 16 step using the past 16 steps \n",
    "past_steps = 64\n",
    "future_steps = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f6ad41f-6baf-43d2-961a-736a698785de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['p']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.future_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1342a2f5-2992-447e-8c2b-ce7e04980a71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "config = dict(model_configs =dict(\n",
    "                                    past_steps = past_steps,\n",
    "                                    future_steps = future_steps,\n",
    "                                    past_channels = len(ts.past_variables),\n",
    "                                    future_channels = len(ts.future_variables),\n",
    "                                    embs = [ts.dataset[c].nunique() for c in ts.cat_var],\n",
    "                                      d_model=128,\n",
    "                                      d_head= 32,\n",
    "                                      n_head=8,\n",
    "                                     dropout_rate = 0.01,\n",
    "                                      num_layers_RNN= 8,\n",
    "                                      optim='torch.optim.SGD',\n",
    "                                     out_channels = len(ts.target_variables),\n",
    "                                    quantiles= [],\n",
    "                                   loss_type='exponential_penalization',\n",
    "                                 persistence_weight = 0,\n",
    "                                    ),\n",
    "                scheduler_config = dict(gamma=0.1,step_size=2400000000000),\n",
    "                optim_config = dict(lr = 0.0005,weight_decay=0.0))\n",
    "model_linear = TFT(**config['model_configs'],optim_config = config['optim_config'],scheduler_config =config['scheduler_config'],verbose=False )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1be1b3ad-36ef-4fdc-95df-cf0739633915",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-13 15:37:16,802] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 15:37:16,802] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:37:16,804] {utils.py:19} INFO - ####################################                                                                              ####################################\n",
      "[2023-10-13 15:37:16,804] {utils.py:20} INFO -                                                                   Setting the model                                                                   \n",
      "[2023-10-13 15:37:16,805] {utils.py:21} INFO - ####################################                                                                              ####################################\n",
      "[2023-10-13 15:37:16,806] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:37:16,806] {utils.py:31} INFO - TFT(\n",
      "  (target_linear): Linear(in_features=1, out_features=128, bias=True)\n",
      "  (linear_aux_past): ModuleList()\n",
      "  (linear_aux_fut): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=128, bias=True)\n",
      "  )\n",
      "  (emb_cat_var): embedding_cat_variables(\n",
      "    (cat_n_embd): ModuleList(\n",
      "      (0): Embedding(128, 128)\n",
      "      (1): Embedding(65, 128)\n",
      "      (2): Embedding(2, 128)\n",
      "    )\n",
      "  )\n",
      "  (rnn): LSTM_Model(\n",
      "    (lstm): LSTM(128, 128, num_layers=8, batch_first=True, dropout=0.01)\n",
      "    (linear): Linear(in_features=128, out_features=64, bias=True)\n",
      "  )\n",
      "  (res_conn1_past): ResidualConnection(\n",
      "    (dropout): Dropout(p=0.01, inplace=False)\n",
      "    (glu): GLU(\n",
      "      (linear1): Linear(in_features=128, out_features=128, bias=False)\n",
      "      (linear2): Linear(in_features=128, out_features=128, bias=False)\n",
      "      (sigmoid): Sigmoid()\n",
      "    )\n",
      "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (res_conn1_fut): ResidualConnection(\n",
      "    (dropout): Dropout(p=0.01, inplace=False)\n",
      "    (glu): GLU(\n",
      "      (linear1): Linear(in_features=128, out_features=128, bias=False)\n",
      "      (linear2): Linear(in_features=128, out_features=128, bias=False)\n",
      "      (sigmoid): Sigmoid()\n",
      "    )\n",
      "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (grn1_past): GRN(\n",
      "    (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (elu): ELU(alpha=1.0)\n",
      "    (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (res_conn): ResidualConnection(\n",
      "      (dropout): Dropout(p=0.01, inplace=False)\n",
      "      (glu): GLU(\n",
      "        (linear1): Linear(in_features=128, out_features=128, bias=False)\n",
      "        (linear2): Linear(in_features=128, out_features=128, bias=False)\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (grn1_fut): GRN(\n",
      "    (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (elu): ELU(alpha=1.0)\n",
      "    (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (res_conn): ResidualConnection(\n",
      "      (dropout): Dropout(p=0.01, inplace=False)\n",
      "      (glu): GLU(\n",
      "        (linear1): Linear(in_features=128, out_features=128, bias=False)\n",
      "        (linear2): Linear(in_features=128, out_features=128, bias=False)\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (InterpretableMultiHead): InterpretableMultiHead(\n",
      "    (Q_layers): ModuleList(\n",
      "      (0): Linear(in_features=128, out_features=32, bias=True)\n",
      "      (1): Linear(in_features=128, out_features=32, bias=True)\n",
      "      (2): Linear(in_features=128, out_features=32, bias=True)\n",
      "      (3): Linear(in_features=128, out_features=32, bias=True)\n",
      "      (4): Linear(in_features=128, out_features=32, bias=True)\n",
      "      (5): Linear(in_features=128, out_features=32, bias=True)\n",
      "      (6): Linear(in_features=128, out_features=32, bias=True)\n",
      "      (7): Linear(in_features=128, out_features=32, bias=True)\n",
      "    )\n",
      "    (K_layers): ModuleList(\n",
      "      (0): Linear(in_features=128, out_features=32, bias=True)\n",
      "      (1): Linear(in_features=128, out_features=32, bias=True)\n",
      "      (2): Linear(in_features=128, out_features=32, bias=True)\n",
      "      (3): Linear(in_features=128, out_features=32, bias=True)\n",
      "      (4): Linear(in_features=128, out_features=32, bias=True)\n",
      "      (5): Linear(in_features=128, out_features=32, bias=True)\n",
      "      (6): Linear(in_features=128, out_features=32, bias=True)\n",
      "      (7): Linear(in_features=128, out_features=32, bias=True)\n",
      "    )\n",
      "    (Softmax_layers): ModuleList(\n",
      "      (0): Softmax(dim=-1)\n",
      "      (1): Softmax(dim=-1)\n",
      "      (2): Softmax(dim=-1)\n",
      "      (3): Softmax(dim=-1)\n",
      "      (4): Softmax(dim=-1)\n",
      "      (5): Softmax(dim=-1)\n",
      "      (6): Softmax(dim=-1)\n",
      "      (7): Softmax(dim=-1)\n",
      "    )\n",
      "    (V_layer): Linear(in_features=128, out_features=32, bias=True)\n",
      "    (out_layer): Linear(in_features=32, out_features=128, bias=True)\n",
      "  )\n",
      "  (res_conn2_att): ResidualConnection(\n",
      "    (dropout): Dropout(p=0.01, inplace=False)\n",
      "    (glu): GLU(\n",
      "      (linear1): Linear(in_features=128, out_features=128, bias=False)\n",
      "      (linear2): Linear(in_features=128, out_features=128, bias=False)\n",
      "      (sigmoid): Sigmoid()\n",
      "    )\n",
      "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (grn2_att): GRN(\n",
      "    (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (elu): ELU(alpha=1.0)\n",
      "    (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (res_conn): ResidualConnection(\n",
      "      (dropout): Dropout(p=0.01, inplace=False)\n",
      "      (glu): GLU(\n",
      "        (linear1): Linear(in_features=128, out_features=128, bias=False)\n",
      "        (linear2): Linear(in_features=128, out_features=128, bias=False)\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (res_conn3_out): ResidualConnection(\n",
      "    (dropout): Dropout(p=0.01, inplace=False)\n",
      "    (glu): GLU(\n",
      "      (linear1): Linear(in_features=128, out_features=128, bias=False)\n",
      "      (linear2): Linear(in_features=128, out_features=128, bias=False)\n",
      "      (sigmoid): Sigmoid()\n",
      "    )\n",
      "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (outLinear): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (loss): L1Loss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#set the desirere model\n",
    "ts.set_model(model_linear,config=config )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2959dcdb-36fa-47c5-bc33-cc88c20d39ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##splitting parameters\n",
    "split_params = {'perc_train':0.6,'perc_valid':0.2,                             ##if not None it will split 70% 10% 20%\n",
    "               'range_train':None, 'range_validation':None, 'range_test':None, ## or we can split using ranges for example range_train=['2021-02-03','2022-04-08']\n",
    "               'past_steps':past_steps,\n",
    "               'future_steps':future_steps,\n",
    "               'shift':0,\n",
    "               'starting_point':None,                                          ## do not skip samples\n",
    "               'skip_step' : 1                                                 ## distance between two consecutive samples\n",
    "                             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fcda7e-4b30-45d7-9991-27dedcfd58cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-13 15:37:19,036] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 15:37:19,037] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:37:19,038] {utils.py:19} INFO - ####################################                                                                              ####################################\n",
      "[2023-10-13 15:37:19,038] {utils.py:20} INFO -                                                                   Training the model                                                                  \n",
      "[2023-10-13 15:37:19,039] {utils.py:21} INFO - ####################################                                                                              ####################################\n",
      "[2023-10-13 15:37:19,039] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:37:19,040] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 15:37:19,040] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:37:19,041] {utils.py:19} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 15:37:19,042] {utils.py:20} INFO -                                                                  Splitting for train                                                                  \n",
      "[2023-10-13 15:37:19,043] {utils.py:21} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 15:37:19,043] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:37:19,044] {utils.py:24} INFO - \n",
      "\n",
      "[2023-10-13 15:37:19,044] {utils.py:25} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:37:19,045] {utils.py:26} INFO -                                               Split temporally using perc_train: 0.6 and perc_valid:0.2                                               \n",
      "[2023-10-13 15:37:19,046] {utils.py:27} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:37:19,046] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 15:37:19,047] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:37:19,047] {utils.py:19} INFO - #########################                                                                                                    #########################\n",
      "[2023-10-13 15:37:19,048] {utils.py:20} INFO -                                                        Train categorical and numerical scalers                                                        \n",
      "[2023-10-13 15:37:19,048] {utils.py:21} INFO - #########################                                                                                                    #########################\n",
      "[2023-10-13 15:37:19,050] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:37:19,053] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 15:37:19,053] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:37:19,054] {utils.py:19} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 15:37:19,055] {utils.py:20} INFO -                                                                  Creating data loader                                                                 \n",
      "[2023-10-13 15:37:19,055] {utils.py:21} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 15:37:19,055] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:37:19,275] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 15:37:19,275] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:37:19,276] {utils.py:19} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 15:37:19,277] {utils.py:20} INFO -                                                                  Creating data loader                                                                 \n",
      "[2023-10-13 15:37:19,277] {utils.py:21} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 15:37:19,278] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:37:19,359] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 15:37:19,360] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:37:19,360] {utils.py:19} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 15:37:19,361] {utils.py:20} INFO -                                                                  Creating data loader                                                                 \n",
      "[2023-10-13 15:37:19,361] {utils.py:21} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 15:37:19,362] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:37:19,437] {utils.py:24} INFO - \n",
      "\n",
      "[2023-10-13 15:37:19,438] {utils.py:25} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:37:19,439] {utils.py:26} INFO -                                                        train:11872, validation:3872, test:3872                                                        \n",
      "[2023-10-13 15:37:19,439] {utils.py:27} INFO - ######################################################################################################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/agobbi/.conda/envs/tt/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:613: UserWarning: Checkpoint directory /home/agobbi/Projects/ExpTS/rf/tft exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "/home/agobbi/.conda/envs/tt/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/agobbi/.conda/envs/tt/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:488: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
      "  rank_zero_warn(\n",
      "/home/agobbi/.conda/envs/tt/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a26665028ca7485f875d4efbb4becdde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LR finder stopped early after 98 steps due to diverging loss.\n",
      "Learning rate set to 7.585775750291837e-08\n",
      "Restoring states from the checkpoint path at /home/agobbi/Projects/ExpTS/rf/tft/.lr_find_11bbc504-b140-4a27-9585-496ac5731ac6.ckpt\n",
      "Restored all states from the checkpoint file at /home/agobbi/Projects/ExpTS/rf/tft/.lr_find_11bbc504-b140-4a27-9585-496ac5731ac6.ckpt\n",
      "\n",
      "   | Name                   | Type                    | Params\n",
      "--------------------------------------------------------------------\n",
      "0  | target_linear          | Linear                  | 256   \n",
      "1  | linear_aux_past        | ModuleList              | 0     \n",
      "2  | linear_aux_fut         | ModuleList              | 256   \n",
      "3  | emb_cat_var            | embedding_cat_variables | 25.0 K\n",
      "4  | rnn                    | LSTM_Model              | 1.1 M \n",
      "5  | res_conn1_past         | ResidualConnection      | 33.0 K\n",
      "6  | res_conn1_fut          | ResidualConnection      | 33.0 K\n",
      "7  | grn1_past              | GRN                     | 66.0 K\n",
      "8  | grn1_fut               | GRN                     | 66.0 K\n",
      "9  | InterpretableMultiHead | InterpretableMultiHead  | 74.4 K\n",
      "10 | res_conn2_att          | ResidualConnection      | 33.0 K\n",
      "11 | grn2_att               | GRN                     | 66.0 K\n",
      "12 | res_conn3_out          | ResidualConnection      | 33.0 K\n",
      "13 | outLinear              | Linear                  | 129   \n",
      "14 | loss                   | L1Loss                  | 0     \n",
      "--------------------------------------------------------------------\n",
      "1.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.5 M     Total params\n",
      "5.981     Total estimated model params size (MB)\n",
      "/home/agobbi/.conda/envs/tt/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "#train the model for 50 epochs with auto_lr_find \n",
    "ts.train_model(dirpath=f\"/home/agobbi/Projects/ExpTS/rf/tft\",\n",
    "               split_params=split_params,\n",
    "               batch_size=32,\n",
    "               num_workers=2,\n",
    "               max_epochs=30,\n",
    "               auto_lr_find=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "8d0974c9-fc85-436d-b7c7-c6605b2a423a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TimeSeries' object has no attribute 'losses'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[157], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Print the losses, check overfitting\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlosses\u001b[49m\u001b[38;5;241m.\u001b[39mplot()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TimeSeries' object has no attribute 'losses'"
     ]
    }
   ],
   "source": [
    "#Print the losses, check overfitting\n",
    "ts.losses.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9df63a20-83b6-42c4-a7e4-30e4c7778cf3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-13 15:36:38,178] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 15:36:38,179] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:36:38,180] {utils.py:19} INFO - ######################                                                                                                          ######################\n",
      "[2023-10-13 15:36:38,181] {utils.py:20} INFO -                                                     Inference on a set (train, validation o test)                                                     \n",
      "[2023-10-13 15:36:38,181] {utils.py:21} INFO - ######################                                                                                                          ######################\n",
      "[2023-10-13 15:36:38,181] {utils.py:22} INFO - ######################################################################################################################################################\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'TimeSeries' object has no attribute 'split_params'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[158], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#make inferences on \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference_on_set\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mrescaling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/tt/lib/python3.10/site-packages/dsipts-0.0.1-py3.10.egg/dsipts/data_structure/data_structure.py:773\u001b[0m, in \u001b[0;36mTimeSeries.inference_on_set\u001b[0;34m(self, batch_size, num_workers, split_params, set, rescaling, data)\u001b[0m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m split_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 773\u001b[0m         beauty_string(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msplitting using train parameters \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_params\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msection\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[1;32m    774\u001b[0m         train,validation,test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_for_train(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_params)\n\u001b[1;32m    775\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TimeSeries' object has no attribute 'split_params'"
     ]
    }
   ],
   "source": [
    "#make inferences on \n",
    "res = ts.inference_on_set(200,4,set='test',rescaling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3cb2875c-5f47-4e47-9553-739dc821fe2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe8bc4e8970>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "lag = 15\n",
    "\n",
    "plt.plot(res[res.lag==lag].time, res[res.lag==lag].y,label='real',alpha=0.5)\n",
    "plt.plot(res[res.lag==lag].time, res[res.lag==lag].y_pred,label='pred',alpha=0.5)\n",
    "\n",
    "plt.title('Prediction on test for lag=7')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "77df437b-1a51-4447-89a4-3ccde0e393bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res['prediction_time'] = res.apply(lambda x: int(x.time-x.lag), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b5110597-f859-47bd-afaf-d21f8f9ddc08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag</th>\n",
       "      <th>time</th>\n",
       "      <th>y</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>prediction_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>16064</td>\n",
       "      <td>0.377953</td>\n",
       "      <td>0.399360</td>\n",
       "      <td>16063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>16065</td>\n",
       "      <td>0.370079</td>\n",
       "      <td>0.389656</td>\n",
       "      <td>16064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>16066</td>\n",
       "      <td>0.377953</td>\n",
       "      <td>0.395594</td>\n",
       "      <td>16065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>16067</td>\n",
       "      <td>0.385827</td>\n",
       "      <td>0.403635</td>\n",
       "      <td>16066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>16068</td>\n",
       "      <td>0.377953</td>\n",
       "      <td>0.401778</td>\n",
       "      <td>16067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247803</th>\n",
       "      <td>64</td>\n",
       "      <td>19994</td>\n",
       "      <td>0.771654</td>\n",
       "      <td>0.673848</td>\n",
       "      <td>19930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247804</th>\n",
       "      <td>64</td>\n",
       "      <td>19995</td>\n",
       "      <td>0.763780</td>\n",
       "      <td>0.676096</td>\n",
       "      <td>19931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247805</th>\n",
       "      <td>64</td>\n",
       "      <td>19996</td>\n",
       "      <td>0.755906</td>\n",
       "      <td>0.673301</td>\n",
       "      <td>19932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247806</th>\n",
       "      <td>64</td>\n",
       "      <td>19997</td>\n",
       "      <td>0.748031</td>\n",
       "      <td>0.675759</td>\n",
       "      <td>19933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247807</th>\n",
       "      <td>64</td>\n",
       "      <td>19998</td>\n",
       "      <td>0.755906</td>\n",
       "      <td>0.680349</td>\n",
       "      <td>19934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>247808 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lag   time         y    y_pred  prediction_time\n",
       "0         1  16064  0.377953  0.399360            16063\n",
       "1         1  16065  0.370079  0.389656            16064\n",
       "2         1  16066  0.377953  0.395594            16065\n",
       "3         1  16067  0.385827  0.403635            16066\n",
       "4         1  16068  0.377953  0.401778            16067\n",
       "...     ...    ...       ...       ...              ...\n",
       "247803   64  19994  0.771654  0.673848            19930\n",
       "247804   64  19995  0.763780  0.676096            19931\n",
       "247805   64  19996  0.755906  0.673301            19932\n",
       "247806   64  19997  0.748031  0.675759            19933\n",
       "247807   64  19998  0.755906  0.680349            19934\n",
       "\n",
       "[247808 rows x 5 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "55e04216-3178-4b2f-86ec-3abaad372424",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe87c310670>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "date = 19932\n",
    "\n",
    "plt.plot(res[res.prediction_time==date].time, res[res.prediction_time==date].y,label='real',alpha=0.5)\n",
    "plt.plot(res[res.prediction_time==date].time, res[res.prediction_time==date].y_pred,label='pred',alpha=0.5)\n",
    "#plt.ylim(res.y.min(),res.y.max())\n",
    "plt.title('Prediction on test for lag=7')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf41c3a1-4108-4d5e-a81f-baaaa00bcf26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## get the median MSE for each lag\n",
    "import numpy as np\n",
    "res.groupby('lag').apply(lambda x: np.nanmean((x.y-x.y_median)**2)).reset_index().rename(columns={0:'error'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8abe2ae-d010-4e95-b712-8e4084639d17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#save model \n",
    "ts.save(f\"{model_to_use}_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972f7417-48ea-4498-8724-89fb1eedccf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## load the model and check if we obtain the same result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1712bce-071f-4ea9-92bd-e4f4637ebb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.load(LinearTS,f\"{model_to_use}_test\",load_last=False)\n",
    "res = ts.inference_on_set(200,4,set='test',rescaling=True)\n",
    "error = res.groupby('lag').apply(lambda x: np.nanmean((x.y-x.y_median)**2)).reset_index().rename(columns={0:'error'}) \n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bcd30c-d798-4a15-8f8c-7587c807d284",
   "metadata": {},
   "outputs": [],
   "source": [
    "##print the mean MSE along the lag steps\n",
    "plt.plot(error.lag,error.error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b0f069-dc3c-4b16-9ede-747df97721f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "lag = 7\n",
    "try:\n",
    "    %matplotlib qast\n",
    "    to_plot = res\n",
    "except:\n",
    "    print('better to have qt, i will reduce the dataset')\n",
    "    plt.figure(figsize=(15,7))\n",
    "    to_plot = res[res.time>pd.to_datetime('2020-12-28')]\n",
    "plt.plot(to_plot[to_plot.lag==lag].time, to_plot[to_plot.lag==lag].y,label='real',alpha=0.5)\n",
    "plt.plot(to_plot[to_plot.lag==lag].time, to_plot[to_plot.lag==lag].y_median,label='median',alpha=0.5)\n",
    "plt.fill_between(to_plot[to_plot.lag==lag].time, to_plot[to_plot.lag==lag].y_low , to_plot[to_plot.lag==lag].y_high, alpha=0.2,label='error band')\n",
    "\n",
    "plt.title('Prediction on test for lag=7')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d6fd90-b6ae-4763-8d51-cb05de421797",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tot = pd.read_csv('/home/agobbi/Projects/ExpTS/csv/prova_test_tot_predictions.csv')\n",
    "tot.time = pd.to_datetime(tot.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f5246d-6540-4817-a342-bc164514ff29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pers = tot[(tot.model=='persistent_weather_1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f74643-7f33-411f-ba84-b046616ccb84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "lag = 7\n",
    "try:\n",
    "    %matplotlib qast\n",
    "    to_plot = pers\n",
    "except:\n",
    "    print('better to have qt, i will reduce the dataset')\n",
    "    plt.figure(figsize=(15,7))\n",
    "    to_plot = pers[pers.time>pd.to_datetime('2020-12-28')]\n",
    "plt.plot(to_plot[to_plot.lag==lag].time, to_plot[to_plot.lag==lag].y,label='real',alpha=0.5)\n",
    "plt.plot(to_plot[to_plot.lag==lag].time, to_plot[to_plot.lag==lag].y_pred,label='median',alpha=0.5)\n",
    "plt.fill_between(to_plot[to_plot.lag==lag].time, to_plot[to_plot.lag==lag].y_low , to_plot[to_plot.lag==lag].y_high, alpha=0.2,label='error band')\n",
    "\n",
    "plt.title('Prediction on test for lag=7')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470d8600-b39d-42b1-8ed4-b1cc198c2da3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
