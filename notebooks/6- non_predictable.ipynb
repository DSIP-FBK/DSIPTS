{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef8f4456-39e8-4bac-9514-dac172858380",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dsipts import TimeSeries, RNN,read_public_dataset, LinearTS, Persistent, TFT\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n",
    "import logging\n",
    "import sys\n",
    "import random\n",
    "\n",
    "file_handler = logging.FileHandler(filename='tmp.log')\n",
    "stdout_handler = logging.StreamHandler(stream=sys.stdout)\n",
    "handlers = [file_handler, stdout_handler]\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, \n",
    "    format='[%(asctime)s] {%(filename)s:%(lineno)d} %(levelname)s - %(message)s',\n",
    "    handlers=handlers\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98dc5459-3670-4357-8059-f3cccade6431",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def random_walk(n):\n",
    "    tot = np.zeros(n)\n",
    "    probs = np.zeros(n)\n",
    "    for i in range(n-1):\n",
    "        prob = random.random()\n",
    "        if prob<0.5:\n",
    "            delta = 1\n",
    "        else:\n",
    "            delta = -1\n",
    "        tot[i+1] = tot[i] + delta\n",
    "        probs[i+1]= prob\n",
    "    return tot, probs\n",
    "N = 20000\n",
    "random.seed(6)\n",
    "x, p = random_walk(N)\n",
    "data = pd.DataFrame({'y':x/x.max(),'p':p,'time':range(N)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fe218d82-40f9-43c9-8118-818249679ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-13 08:47:38,264] {utils.py:24} INFO - \n",
      "\n",
      "[2023-10-13 08:47:38,267] {utils.py:25} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 08:47:38,268] {utils.py:26} INFO -                                                        I will drop duplicates, I dont like them                                                       \n",
      "[2023-10-13 08:47:38,269] {utils.py:27} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 08:47:38,273] {utils.py:29} INFO -                I will update past column adding all target columns, if you want to avoid this beahviour please use check_pass as false                \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timeseries named weather of length 20000.\n",
       " Categorical variable: [],\n",
       " Future variables: ['p'],\n",
       " Past variables: ['y'],\n",
       " Target variables: ['y']\n",
       " With no group"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##loasklearnthe timeseries to the datastructure, adding the hour column and use all the covariates\n",
    "ts = TimeSeries('weather')\n",
    "ts.load_signal(data,enrich_cat=[],target_variables=['y'],past_variables= [],future_variables=['p'])\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e51045-5762-455c-9998-6129b3c7de46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5dc5ed48-70d2-45d4-9c21-4a5eb8122290",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Let now prepare a model predictin the next 16 step using the past 16 steps \n",
    "past_steps = 64\n",
    "future_steps = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3f6ad41f-6baf-43d2-961a-736a698785de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['p']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.future_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "1342a2f5-2992-447e-8c2b-ce7e04980a71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "config = dict(model_configs =dict(\n",
    "                                    past_steps = past_steps,\n",
    "                                    future_steps = future_steps,\n",
    "                                    past_channels = len(ts.past_variables),\n",
    "                                    future_channels = len(ts.future_variables),\n",
    "                                    embs = [ts.dataset[c].nunique() for c in ts.cat_var],\n",
    "                                      d_model=128,\n",
    "                                      d_head= 32,\n",
    "                                      n_head=8,\n",
    "                                     dropout_rate = 0.01,\n",
    "                                      num_layers_RNN= 8,\n",
    "                                      optim='torch.optim.SGD',\n",
    "                                     out_channels = len(ts.target_variables),\n",
    "                                    quantiles= [],\n",
    "                                   loss_type='exponential_penalization',\n",
    "                                 persistence_weight = 0,\n",
    "                                    ),\n",
    "                scheduler_config = dict(gamma=0.1,step_size=2400000000000),\n",
    "                optim_config = dict(lr = 0.0005,weight_decay=0.0))\n",
    "model_linear = TFT(**config['model_configs'],optim_config = config['optim_config'],scheduler_config =config['scheduler_config'],verbose=False )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1be1b3ad-36ef-4fdc-95df-cf0739633915",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-13 13:40:01,779] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 13:40:01,782] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 13:40:01,785] {utils.py:19} INFO - ####################################                                                                              ####################################\n",
      "[2023-10-13 13:40:01,786] {utils.py:20} INFO -                                                                   Setting the model                                                                   \n",
      "[2023-10-13 13:40:01,788] {utils.py:21} INFO - ####################################                                                                              ####################################\n",
      "[2023-10-13 13:40:01,789] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 13:40:01,791] {utils.py:31} INFO - TFT(\n",
      "  (target_linear): Linear(in_features=1, out_features=128, bias=True)\n",
      "  (linear_aux_past): ModuleList()\n",
      "  (linear_aux_fut): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=128, bias=True)\n",
      "  )\n",
      "  (emb_cat_var): embedding_cat_variables(\n",
      "    (cat_n_embd): ModuleList(\n",
      "      (0): Embedding(128, 128)\n",
      "      (1): Embedding(65, 128)\n",
      "      (2): Embedding(2, 128)\n",
      "    )\n",
      "  )\n",
      "  (rnn): LSTM_Model(\n",
      "    (lstm): LSTM(128, 128, num_layers=8, batch_first=True, dropout=0.01)\n",
      "    (linear): Linear(in_features=128, out_features=64, bias=True)\n",
      "  )\n",
      "  (res_conn1_past): ResidualConnection(\n",
      "    (dropout): Dropout(p=0.01, inplace=False)\n",
      "    (glu): GLU(\n",
      "      (linear1): Linear(in_features=128, out_features=128, bias=False)\n",
      "      (linear2): Linear(in_features=128, out_features=128, bias=False)\n",
      "      (sigmoid): Sigmoid()\n",
      "    )\n",
      "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (res_conn1_fut): ResidualConnection(\n",
      "    (dropout): Dropout(p=0.01, inplace=False)\n",
      "    (glu): GLU(\n",
      "      (linear1): Linear(in_features=128, out_features=128, bias=False)\n",
      "      (linear2): Linear(in_features=128, out_features=128, bias=False)\n",
      "      (sigmoid): Sigmoid()\n",
      "    )\n",
      "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (grn1_past): GRN(\n",
      "    (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (elu): ELU(alpha=1.0)\n",
      "    (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (res_conn): ResidualConnection(\n",
      "      (dropout): Dropout(p=0.01, inplace=False)\n",
      "      (glu): GLU(\n",
      "        (linear1): Linear(in_features=128, out_features=128, bias=False)\n",
      "        (linear2): Linear(in_features=128, out_features=128, bias=False)\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (grn1_fut): GRN(\n",
      "    (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (elu): ELU(alpha=1.0)\n",
      "    (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (res_conn): ResidualConnection(\n",
      "      (dropout): Dropout(p=0.01, inplace=False)\n",
      "      (glu): GLU(\n",
      "        (linear1): Linear(in_features=128, out_features=128, bias=False)\n",
      "        (linear2): Linear(in_features=128, out_features=128, bias=False)\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (InterpretableMultiHead): InterpretableMultiHead(\n",
      "    (Q_layers): ModuleList(\n",
      "      (0): Linear(in_features=128, out_features=32, bias=True)\n",
      "      (1): Linear(in_features=128, out_features=32, bias=True)\n",
      "      (2): Linear(in_features=128, out_features=32, bias=True)\n",
      "      (3): Linear(in_features=128, out_features=32, bias=True)\n",
      "      (4): Linear(in_features=128, out_features=32, bias=True)\n",
      "      (5): Linear(in_features=128, out_features=32, bias=True)\n",
      "      (6): Linear(in_features=128, out_features=32, bias=True)\n",
      "      (7): Linear(in_features=128, out_features=32, bias=True)\n",
      "    )\n",
      "    (K_layers): ModuleList(\n",
      "      (0): Linear(in_features=128, out_features=32, bias=True)\n",
      "      (1): Linear(in_features=128, out_features=32, bias=True)\n",
      "      (2): Linear(in_features=128, out_features=32, bias=True)\n",
      "      (3): Linear(in_features=128, out_features=32, bias=True)\n",
      "      (4): Linear(in_features=128, out_features=32, bias=True)\n",
      "      (5): Linear(in_features=128, out_features=32, bias=True)\n",
      "      (6): Linear(in_features=128, out_features=32, bias=True)\n",
      "      (7): Linear(in_features=128, out_features=32, bias=True)\n",
      "    )\n",
      "    (Softmax_layers): ModuleList(\n",
      "      (0): Softmax(dim=-1)\n",
      "      (1): Softmax(dim=-1)\n",
      "      (2): Softmax(dim=-1)\n",
      "      (3): Softmax(dim=-1)\n",
      "      (4): Softmax(dim=-1)\n",
      "      (5): Softmax(dim=-1)\n",
      "      (6): Softmax(dim=-1)\n",
      "      (7): Softmax(dim=-1)\n",
      "    )\n",
      "    (V_layer): Linear(in_features=128, out_features=32, bias=True)\n",
      "    (out_layer): Linear(in_features=32, out_features=128, bias=True)\n",
      "  )\n",
      "  (res_conn2_att): ResidualConnection(\n",
      "    (dropout): Dropout(p=0.01, inplace=False)\n",
      "    (glu): GLU(\n",
      "      (linear1): Linear(in_features=128, out_features=128, bias=False)\n",
      "      (linear2): Linear(in_features=128, out_features=128, bias=False)\n",
      "      (sigmoid): Sigmoid()\n",
      "    )\n",
      "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (grn2_att): GRN(\n",
      "    (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (elu): ELU(alpha=1.0)\n",
      "    (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (res_conn): ResidualConnection(\n",
      "      (dropout): Dropout(p=0.01, inplace=False)\n",
      "      (glu): GLU(\n",
      "        (linear1): Linear(in_features=128, out_features=128, bias=False)\n",
      "        (linear2): Linear(in_features=128, out_features=128, bias=False)\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (res_conn3_out): ResidualConnection(\n",
      "    (dropout): Dropout(p=0.01, inplace=False)\n",
      "    (glu): GLU(\n",
      "      (linear1): Linear(in_features=128, out_features=128, bias=False)\n",
      "      (linear2): Linear(in_features=128, out_features=128, bias=False)\n",
      "      (sigmoid): Sigmoid()\n",
      "    )\n",
      "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (outLinear): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (loss): L1Loss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#set the desirere model\n",
    "ts.set_model(model_linear,config=config )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2959dcdb-36fa-47c5-bc33-cc88c20d39ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##splitting parameters\n",
    "split_params = {'perc_train':0.6,'perc_valid':0.2,                             ##if not None it will split 70% 10% 20%\n",
    "               'range_train':None, 'range_validation':None, 'range_test':None, ## or we can split using ranges for example range_train=['2021-02-03','2022-04-08']\n",
    "               'past_steps':past_steps,\n",
    "               'future_steps':future_steps,\n",
    "               'shift':0,\n",
    "               'starting_point':None,                                          ## do not skip samples\n",
    "               'skip_step' : 1                                                 ## distance between two consecutive samples\n",
    "                             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f7fcda7e-4b30-45d7-9991-27dedcfd58cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-13 13:40:02,888] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 13:40:02,894] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 13:40:02,898] {utils.py:19} INFO - ####################################                                                                              ####################################\n",
      "[2023-10-13 13:40:02,901] {utils.py:20} INFO -                                                                   Training the model                                                                  \n",
      "[2023-10-13 13:40:02,903] {utils.py:21} INFO - ####################################                                                                              ####################################\n",
      "[2023-10-13 13:40:02,905] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 13:40:02,906] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 13:40:02,907] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 13:40:02,909] {utils.py:19} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 13:40:02,910] {utils.py:20} INFO -                                                                  Splitting for train                                                                  \n",
      "[2023-10-13 13:40:02,912] {utils.py:21} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 13:40:02,914] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 13:40:02,915] {utils.py:24} INFO - \n",
      "\n",
      "[2023-10-13 13:40:02,916] {utils.py:25} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 13:40:02,917] {utils.py:26} INFO -                                               Split temporally using perc_train: 0.6 and perc_valid:0.2                                               \n",
      "[2023-10-13 13:40:02,918] {utils.py:27} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 13:40:02,920] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 13:40:02,921] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 13:40:02,922] {utils.py:19} INFO - #########################                                                                                                    #########################\n",
      "[2023-10-13 13:40:02,923] {utils.py:20} INFO -                                                        Train categorical and numerical scalers                                                        \n",
      "[2023-10-13 13:40:02,923] {utils.py:21} INFO - #########################                                                                                                    #########################\n",
      "[2023-10-13 13:40:02,924] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 13:40:02,925] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 13:40:02,926] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 13:40:02,926] {utils.py:19} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 13:40:02,927] {utils.py:20} INFO -                                                                  Creating data loader                                                                 \n",
      "[2023-10-13 13:40:02,928] {utils.py:21} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 13:40:02,928] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 13:40:03,112] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 13:40:03,113] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 13:40:03,113] {utils.py:19} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 13:40:03,114] {utils.py:20} INFO -                                                                  Creating data loader                                                                 \n",
      "[2023-10-13 13:40:03,114] {utils.py:21} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 13:40:03,115] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 13:40:03,181] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 13:40:03,182] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 13:40:03,182] {utils.py:19} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 13:40:03,183] {utils.py:20} INFO -                                                                  Creating data loader                                                                 \n",
      "[2023-10-13 13:40:03,183] {utils.py:21} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 13:40:03,184] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 13:40:03,246] {utils.py:24} INFO - \n",
      "\n",
      "[2023-10-13 13:40:03,246] {utils.py:25} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 13:40:03,247] {utils.py:26} INFO -                                                        train:11872, validation:3872, test:3872                                                        \n",
      "[2023-10-13 13:40:03,247] {utils.py:27} INFO - ######################################################################################################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/agobbi/.conda/envs/tt/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:613: UserWarning: Checkpoint directory /home/agobbi/Projects/ExpTS/rf/tft exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "/home/agobbi/.conda/envs/tt/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/agobbi/.conda/envs/tt/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:488: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
      "  rank_zero_warn(\n",
      "/home/agobbi/.conda/envs/tt/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19bd21a342ac4977bfd05e8c0fe4e32a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LR finder stopped early after 91 steps due to diverging loss.\n",
      "Learning rate set to 0.005754399373371567\n",
      "Restoring states from the checkpoint path at /home/agobbi/Projects/ExpTS/rf/tft/.lr_find_ed55a495-d974-4b30-8b8e-e9713d9aafbe.ckpt\n",
      "Restored all states from the checkpoint file at /home/agobbi/Projects/ExpTS/rf/tft/.lr_find_ed55a495-d974-4b30-8b8e-e9713d9aafbe.ckpt\n",
      "\n",
      "   | Name                   | Type                    | Params\n",
      "--------------------------------------------------------------------\n",
      "0  | target_linear          | Linear                  | 256   \n",
      "1  | linear_aux_past        | ModuleList              | 0     \n",
      "2  | linear_aux_fut         | ModuleList              | 256   \n",
      "3  | emb_cat_var            | embedding_cat_variables | 25.0 K\n",
      "4  | rnn                    | LSTM_Model              | 1.1 M \n",
      "5  | res_conn1_past         | ResidualConnection      | 33.0 K\n",
      "6  | res_conn1_fut          | ResidualConnection      | 33.0 K\n",
      "7  | grn1_past              | GRN                     | 66.0 K\n",
      "8  | grn1_fut               | GRN                     | 66.0 K\n",
      "9  | InterpretableMultiHead | InterpretableMultiHead  | 74.4 K\n",
      "10 | res_conn2_att          | ResidualConnection      | 33.0 K\n",
      "11 | grn2_att               | GRN                     | 66.0 K\n",
      "12 | res_conn3_out          | ResidualConnection      | 33.0 K\n",
      "13 | outLinear              | Linear                  | 129   \n",
      "14 | loss                   | L1Loss                  | 0     \n",
      "--------------------------------------------------------------------\n",
      "1.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.5 M     Total params\n",
      "5.981     Total estimated model params size (MB)\n",
      "/home/agobbi/.conda/envs/tt/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "Epoch 0, global step 371: 'val_loss' reached 0.19511 (best 0.19511), saving model to '/home/agobbi/Projects/ExpTS/rf/tft/checkpoint-v11.ckpt' as top 1\n",
      "Epoch 1, global step 742: 'val_loss' reached 0.15211 (best 0.15211), saving model to '/home/agobbi/Projects/ExpTS/rf/tft/checkpoint-v11.ckpt' as top 1\n",
      "Epoch 2, global step 1113: 'val_loss' reached 0.13403 (best 0.13403), saving model to '/home/agobbi/Projects/ExpTS/rf/tft/checkpoint-v11.ckpt' as top 1\n",
      "Epoch 3, global step 1484: 'val_loss' reached 0.12667 (best 0.12667), saving model to '/home/agobbi/Projects/ExpTS/rf/tft/checkpoint-v11.ckpt' as top 1\n",
      "Epoch 4, global step 1855: 'val_loss' was not in top 1\n",
      "Epoch 5, global step 2226: 'val_loss' reached 0.12242 (best 0.12242), saving model to '/home/agobbi/Projects/ExpTS/rf/tft/checkpoint-v11.ckpt' as top 1\n",
      "Epoch 6, global step 2597: 'val_loss' reached 0.11974 (best 0.11974), saving model to '/home/agobbi/Projects/ExpTS/rf/tft/checkpoint-v11.ckpt' as top 1\n",
      "Epoch 7, global step 2968: 'val_loss' reached 0.11295 (best 0.11295), saving model to '/home/agobbi/Projects/ExpTS/rf/tft/checkpoint-v11.ckpt' as top 1\n",
      "Epoch 8, global step 3339: 'val_loss' reached 0.11043 (best 0.11043), saving model to '/home/agobbi/Projects/ExpTS/rf/tft/checkpoint-v11.ckpt' as top 1\n",
      "Epoch 9, global step 3710: 'val_loss' was not in top 1\n",
      "Epoch 10, global step 4081: 'val_loss' was not in top 1\n",
      "Epoch 11, global step 4452: 'val_loss' was not in top 1\n",
      "Epoch 12, global step 4823: 'val_loss' was not in top 1\n",
      "Epoch 13, global step 5194: 'val_loss' was not in top 1\n",
      "Epoch 14, global step 5565: 'val_loss' was not in top 1\n",
      "Epoch 15, global step 5936: 'val_loss' reached 0.10860 (best 0.10860), saving model to '/home/agobbi/Projects/ExpTS/rf/tft/checkpoint-v11.ckpt' as top 1\n",
      "Epoch 16, global step 6307: 'val_loss' was not in top 1\n",
      "Epoch 17, global step 6678: 'val_loss' was not in top 1\n",
      "Epoch 18, global step 7049: 'val_loss' reached 0.10787 (best 0.10787), saving model to '/home/agobbi/Projects/ExpTS/rf/tft/checkpoint-v11.ckpt' as top 1\n",
      "Epoch 19, global step 7420: 'val_loss' was not in top 1\n",
      "Epoch 20, global step 7791: 'val_loss' was not in top 1\n",
      "Epoch 21, global step 8162: 'val_loss' was not in top 1\n",
      "Epoch 22, global step 8533: 'val_loss' was not in top 1\n",
      "Epoch 23, global step 8904: 'val_loss' was not in top 1\n",
      "Epoch 24, global step 9275: 'val_loss' was not in top 1\n",
      "Epoch 25, global step 9646: 'val_loss' was not in top 1\n",
      "Epoch 26, global step 10017: 'val_loss' reached 0.10721 (best 0.10721), saving model to '/home/agobbi/Projects/ExpTS/rf/tft/checkpoint-v11.ckpt' as top 1\n",
      "Epoch 27, global step 10388: 'val_loss' was not in top 1\n",
      "Epoch 28, global step 10759: 'val_loss' was not in top 1\n",
      "Epoch 29, global step 11130: 'val_loss' reached 0.10719 (best 0.10719), saving model to '/home/agobbi/Projects/ExpTS/rf/tft/checkpoint-v11.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving losses on file because multigpu not working\n",
      "[2023-10-13 15:31:46,570] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 15:31:46,571] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 15:31:46,587] {utils.py:19} INFO - ###############################                                                                                        ###############################\n",
      "[2023-10-13 15:31:46,588] {utils.py:20} INFO -                                                              END of the training process                                                              \n",
      "[2023-10-13 15:31:46,589] {utils.py:21} INFO - ###############################                                                                                        ###############################\n",
      "[2023-10-13 15:31:46,589] {utils.py:22} INFO - ######################################################################################################################################################\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10718778520822525"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model for 50 epochs with auto_lr_find \n",
    "ts.train_model(dirpath=f\"/home/agobbi/Projects/ExpTS/rf/tft\",\n",
    "               split_params=split_params,\n",
    "               batch_size=32,\n",
    "               num_workers=2,\n",
    "               max_epochs=30,\n",
    "               auto_lr_find=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8d0974c9-fc85-436d-b7c7-c6605b2a423a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print the losses, check overfitting\n",
    "ts.losses.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9df63a20-83b6-42c4-a7e4-30e4c7778cf3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-13 13:35:07,775] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 13:35:07,777] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 13:35:07,778] {utils.py:19} INFO - ######################                                                                                                          ######################\n",
      "[2023-10-13 13:35:07,779] {utils.py:20} INFO -                                                     Inference on a set (train, validation o test)                                                     \n",
      "[2023-10-13 13:35:07,780] {utils.py:21} INFO - ######################                                                                                                          ######################\n",
      "[2023-10-13 13:35:07,781] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 13:35:07,782] {utils.py:24} INFO - \n",
      "\n",
      "[2023-10-13 13:35:07,783] {utils.py:25} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 13:35:07,784] {utils.py:26} INFO - splitting using train parameters {'perc_train': 0.6, 'perc_valid': 0.2, 'range_train': None, 'range_validation': None, 'range_test': None, 'past_steps': 64, 'future_steps': 64, 'shift': 0, 'starting_point': None, 'skip_step': 1}\n",
      "[2023-10-13 13:35:07,785] {utils.py:27} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 13:35:07,786] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 13:35:07,788] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 13:35:07,789] {utils.py:19} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 13:35:07,790] {utils.py:20} INFO -                                                                  Splitting for train                                                                  \n",
      "[2023-10-13 13:35:07,791] {utils.py:21} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 13:35:07,792] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 13:35:07,793] {utils.py:24} INFO - \n",
      "\n",
      "[2023-10-13 13:35:07,794] {utils.py:25} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 13:35:07,794] {utils.py:26} INFO -                                               Split temporally using perc_train: 0.6 and perc_valid:0.2                                               \n",
      "[2023-10-13 13:35:07,795] {utils.py:27} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 13:35:07,796] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 13:35:07,797] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 13:35:07,798] {utils.py:19} INFO - #########################                                                                                                    #########################\n",
      "[2023-10-13 13:35:07,798] {utils.py:20} INFO -                                                        Train categorical and numerical scalers                                                        \n",
      "[2023-10-13 13:35:07,799] {utils.py:21} INFO - #########################                                                                                                    #########################\n",
      "[2023-10-13 13:35:07,800] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 13:35:07,800] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 13:35:07,801] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 13:35:07,802] {utils.py:19} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 13:35:07,803] {utils.py:20} INFO -                                                                  Creating data loader                                                                 \n",
      "[2023-10-13 13:35:07,803] {utils.py:21} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 13:35:07,804] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 13:35:08,205] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 13:35:08,206] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 13:35:08,206] {utils.py:19} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 13:35:08,207] {utils.py:20} INFO -                                                                  Creating data loader                                                                 \n",
      "[2023-10-13 13:35:08,209] {utils.py:21} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 13:35:08,210] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 13:35:08,355] {utils.py:17} INFO - \n",
      "\n",
      "[2023-10-13 13:35:08,356] {utils.py:18} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 13:35:08,356] {utils.py:19} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 13:35:08,357] {utils.py:20} INFO -                                                                  Creating data loader                                                                 \n",
      "[2023-10-13 13:35:08,358] {utils.py:21} INFO - ###################################                                                                                ###################################\n",
      "[2023-10-13 13:35:08,359] {utils.py:22} INFO - ######################################################################################################################################################\n",
      "[2023-10-13 13:35:08,482] {utils.py:29} INFO -                                                                    Device used: cpu                                                                   \n",
      "[2023-10-13 13:36:26,938] {utils.py:29} INFO -                                                                      Scaling back                                                                     \n"
     ]
    }
   ],
   "source": [
    "#make inferences on \n",
    "res = ts.inference_on_set(200,4,set='test',rescaling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3cb2875c-5f47-4e47-9553-739dc821fe2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe8bc4e8970>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "lag = 15\n",
    "\n",
    "plt.plot(res[res.lag==lag].time, res[res.lag==lag].y,label='real',alpha=0.5)\n",
    "plt.plot(res[res.lag==lag].time, res[res.lag==lag].y_pred,label='pred',alpha=0.5)\n",
    "\n",
    "plt.title('Prediction on test for lag=7')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "77df437b-1a51-4447-89a4-3ccde0e393bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res['prediction_time'] = res.apply(lambda x: int(x.time-x.lag), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b5110597-f859-47bd-afaf-d21f8f9ddc08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag</th>\n",
       "      <th>time</th>\n",
       "      <th>y</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>prediction_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>16064</td>\n",
       "      <td>0.377953</td>\n",
       "      <td>0.399360</td>\n",
       "      <td>16063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>16065</td>\n",
       "      <td>0.370079</td>\n",
       "      <td>0.389656</td>\n",
       "      <td>16064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>16066</td>\n",
       "      <td>0.377953</td>\n",
       "      <td>0.395594</td>\n",
       "      <td>16065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>16067</td>\n",
       "      <td>0.385827</td>\n",
       "      <td>0.403635</td>\n",
       "      <td>16066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>16068</td>\n",
       "      <td>0.377953</td>\n",
       "      <td>0.401778</td>\n",
       "      <td>16067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247803</th>\n",
       "      <td>64</td>\n",
       "      <td>19994</td>\n",
       "      <td>0.771654</td>\n",
       "      <td>0.673848</td>\n",
       "      <td>19930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247804</th>\n",
       "      <td>64</td>\n",
       "      <td>19995</td>\n",
       "      <td>0.763780</td>\n",
       "      <td>0.676096</td>\n",
       "      <td>19931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247805</th>\n",
       "      <td>64</td>\n",
       "      <td>19996</td>\n",
       "      <td>0.755906</td>\n",
       "      <td>0.673301</td>\n",
       "      <td>19932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247806</th>\n",
       "      <td>64</td>\n",
       "      <td>19997</td>\n",
       "      <td>0.748031</td>\n",
       "      <td>0.675759</td>\n",
       "      <td>19933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247807</th>\n",
       "      <td>64</td>\n",
       "      <td>19998</td>\n",
       "      <td>0.755906</td>\n",
       "      <td>0.680349</td>\n",
       "      <td>19934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>247808 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lag   time         y    y_pred  prediction_time\n",
       "0         1  16064  0.377953  0.399360            16063\n",
       "1         1  16065  0.370079  0.389656            16064\n",
       "2         1  16066  0.377953  0.395594            16065\n",
       "3         1  16067  0.385827  0.403635            16066\n",
       "4         1  16068  0.377953  0.401778            16067\n",
       "...     ...    ...       ...       ...              ...\n",
       "247803   64  19994  0.771654  0.673848            19930\n",
       "247804   64  19995  0.763780  0.676096            19931\n",
       "247805   64  19996  0.755906  0.673301            19932\n",
       "247806   64  19997  0.748031  0.675759            19933\n",
       "247807   64  19998  0.755906  0.680349            19934\n",
       "\n",
       "[247808 rows x 5 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "55e04216-3178-4b2f-86ec-3abaad372424",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe87c310670>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "date = 19932\n",
    "\n",
    "plt.plot(res[res.prediction_time==date].time, res[res.prediction_time==date].y,label='real',alpha=0.5)\n",
    "plt.plot(res[res.prediction_time==date].time, res[res.prediction_time==date].y_pred,label='pred',alpha=0.5)\n",
    "#plt.ylim(res.y.min(),res.y.max())\n",
    "plt.title('Prediction on test for lag=7')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf41c3a1-4108-4d5e-a81f-baaaa00bcf26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## get the median MSE for each lag\n",
    "import numpy as np\n",
    "res.groupby('lag').apply(lambda x: np.nanmean((x.y-x.y_median)**2)).reset_index().rename(columns={0:'error'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8abe2ae-d010-4e95-b712-8e4084639d17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#save model \n",
    "ts.save(f\"{model_to_use}_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972f7417-48ea-4498-8724-89fb1eedccf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## load the model and check if we obtain the same result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1712bce-071f-4ea9-92bd-e4f4637ebb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.load(LinearTS,f\"{model_to_use}_test\",load_last=False)\n",
    "res = ts.inference_on_set(200,4,set='test',rescaling=True)\n",
    "error = res.groupby('lag').apply(lambda x: np.nanmean((x.y-x.y_median)**2)).reset_index().rename(columns={0:'error'}) \n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bcd30c-d798-4a15-8f8c-7587c807d284",
   "metadata": {},
   "outputs": [],
   "source": [
    "##print the mean MSE along the lag steps\n",
    "plt.plot(error.lag,error.error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b0f069-dc3c-4b16-9ede-747df97721f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "lag = 7\n",
    "try:\n",
    "    %matplotlib qast\n",
    "    to_plot = res\n",
    "except:\n",
    "    print('better to have qt, i will reduce the dataset')\n",
    "    plt.figure(figsize=(15,7))\n",
    "    to_plot = res[res.time>pd.to_datetime('2020-12-28')]\n",
    "plt.plot(to_plot[to_plot.lag==lag].time, to_plot[to_plot.lag==lag].y,label='real',alpha=0.5)\n",
    "plt.plot(to_plot[to_plot.lag==lag].time, to_plot[to_plot.lag==lag].y_median,label='median',alpha=0.5)\n",
    "plt.fill_between(to_plot[to_plot.lag==lag].time, to_plot[to_plot.lag==lag].y_low , to_plot[to_plot.lag==lag].y_high, alpha=0.2,label='error band')\n",
    "\n",
    "plt.title('Prediction on test for lag=7')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d6fd90-b6ae-4763-8d51-cb05de421797",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tot = pd.read_csv('/home/agobbi/Projects/ExpTS/csv/prova_test_tot_predictions.csv')\n",
    "tot.time = pd.to_datetime(tot.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f5246d-6540-4817-a342-bc164514ff29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pers = tot[(tot.model=='persistent_weather_1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f74643-7f33-411f-ba84-b046616ccb84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "lag = 7\n",
    "try:\n",
    "    %matplotlib qast\n",
    "    to_plot = pers\n",
    "except:\n",
    "    print('better to have qt, i will reduce the dataset')\n",
    "    plt.figure(figsize=(15,7))\n",
    "    to_plot = pers[pers.time>pd.to_datetime('2020-12-28')]\n",
    "plt.plot(to_plot[to_plot.lag==lag].time, to_plot[to_plot.lag==lag].y,label='real',alpha=0.5)\n",
    "plt.plot(to_plot[to_plot.lag==lag].time, to_plot[to_plot.lag==lag].y_pred,label='median',alpha=0.5)\n",
    "plt.fill_between(to_plot[to_plot.lag==lag].time, to_plot[to_plot.lag==lag].y_low , to_plot[to_plot.lag==lag].y_high, alpha=0.2,label='error band')\n",
    "\n",
    "plt.title('Prediction on test for lag=7')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470d8600-b39d-42b1-8ed4-b1cc198c2da3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
