{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "284d903f-91b0-48ca-98ed-b48d55b18712",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsipts import Categorical,TimeSeries, RNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "459c491c-98ab-4513-b5eb-9f5c604b9df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "settimana = Categorical('settimanale',1,[1,1,1,1,1,1,1],7,'multiplicative',[0.9,0.8,0.7,0.6,0.5,0.99,0.99])\n",
    "\n",
    "##montly, additive (here there are only 5 month)\n",
    "mese = Categorical('mensile',1,[31,28,20,10,33],5,'additive',[10,20,-10,20,0])\n",
    "\n",
    "##spot categorical variables: in this case it occurs every 100 days and it lasts 7 days adding 10 to the original timeseries\n",
    "spot = Categorical('spot',100,[7],1,'additive',[10])\n",
    "\n",
    "##initizate a timeseries object\n",
    "ts = TimeSeries('prova')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b53411e-8c81-4dc9-8e2e-c83c3a568be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.generate_signal(noise_mean=1,categorical_variables=[settimana,mese,spot],length=5000,type=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "beea9295-9164-4bae-b2e1-8c5cc6c585c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ts.dataset\n",
    "dataset['x_num'] = 0.0\n",
    "dataset.loc[:dataset.shape[0]-10,'x_num']= dataset['x_num'].values[9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "efd28d64-ba4e-436d-aafc-ee0a43ed6309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['signal']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_var_past = ts.cat_var\n",
    "cat_var_fut = ts.cat_fut\n",
    "num_var_past = ts.num_var+['x_num']\n",
    "num_var_fut = []\n",
    "group = None\n",
    "time_var = 'time'\n",
    "target = ['signal']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4d1b49d6-8e61-447d-9e2e-44893f104cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Union\n",
    "def extend_time_df(x:pd.DataFrame,freq:Union[str,int],group:Union[str,None]=None,global_minmax:bool=False)-> pd.DataFrame:\n",
    "    \"\"\"Utility for generating a full dataset and then merge the real data\n",
    "\n",
    "    Args:\n",
    "        x (pd.DataFrame): dataframe containing the column time\n",
    "        freq (str): frequency (in pandas notation) of the resulting dataframe\n",
    "        group (string or None): if not None the min max are computed by the group column, default None\n",
    "        global_minmax (bool): if True the min_max is computed globally for each group. Usually used for stacked model\n",
    "    Returns:\n",
    "        pd.DataFrame: a dataframe with the column time ranging from thr minumum of x to the maximum with frequency `freq`\n",
    "    \"\"\"\n",
    "\n",
    "    if group is None:\n",
    "\n",
    "        if isinstance(freq,int):\n",
    "            empty = pd.DataFrame({'time':list(range(x.time.min(),x.time.max(),freq))})\n",
    "        else:\n",
    "            empty = pd.DataFrame({'time':pd.date_range(x.time.min(),x.time.max(),freq=freq)})\n",
    "\n",
    "    else:\n",
    "        \n",
    "        if global_minmax:\n",
    "            _min = pd.DataFrame({group:x[group].unique(),'time':x.time.min()})\n",
    "            _max = pd.DataFrame({group:x[group].unique(),'time':x.time.max()})\n",
    "\n",
    "        else:\n",
    "            _min = x.groupby(group).time.min().reset_index()\n",
    "            _max = x.groupby(group).time.max().reset_index()\n",
    "        empty = []\n",
    "        for c in x[group].unique():\n",
    "            if isinstance(freq,int):\n",
    "                empty.append(pd.DataFrame({group:c,'time':np.arange(_min.time[_min[group]==c].values[0],_max.time[_max[group]==c].values[0],freq)}))\n",
    "\n",
    "            else:\n",
    "                empty.append(pd.DataFrame({group:c,'time':pd.date_range(_min.time[_min[group]==c].values[0],_max.time[_max[group]==c].values[0],freq=freq)}))\n",
    "            \n",
    "        empty = pd.concat(empty,ignore_index=True)\n",
    "    return empty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb0857c-8527-4a6a-9d32-9d7c78099431",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9e2ac8bd-fc6b-4400-b8f3-b86f1138671b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import datetime\n",
    "import lightning as L\n",
    "\n",
    "class PandasTSDataSet:\n",
    "    def __init__(self, df,time_var, cat_var_past, cat_var_fut, num_var_past, num_var_fut,target, group = None, metadata={},check_holes_and_duplicates=True,check_past=True):\n",
    "        \n",
    "        numerica_var = list(set(num_var_past).union(set(num_var_fut)).union(set(target)))\n",
    "        df_norm = df[numerica_var+[time_var]].copy()\n",
    "        label_encoders = {}\n",
    "        for c in set(cat_var_past).union(set(cat_var_fut)):\n",
    "            label_encoders[c] = LabelEncoder()\n",
    "            df_norm[c] = label_encoders[c].fit_transform(df[c])\n",
    "        if group is not None:\n",
    "            label_encoders[group] = LabelEncoder()\n",
    "            df_norm[group] = label_encoders[group].fit_transform(df[group])\n",
    "        \n",
    "        if check_holes_and_duplicates:\n",
    "            df_norm.drop_duplicates(subset=['time'] if group is None else [group,'time'],  keep='first', inplace=True, ignore_index=True)\n",
    "            print(df_norm.shape)\n",
    "            if group is None:\n",
    "                differences = df_norm.time.diff()[1:]\n",
    "            else:\n",
    "                differences = df_norm[df_norm[group]==df_norm[group].unique()[0]].time.diff()[1:]\n",
    "    \n",
    "            if isinstance(df_norm.time[0], datetime):\n",
    "                freq = pd.to_timedelta(differences.min())   \n",
    "            else:\n",
    "                if int(df_norm.time[0])==df_norm.time[0]: ##ONLY THINK THAT WORKS IN GENERAL\n",
    "                    freq = int(differences.min())\n",
    "                else:\n",
    "                    raise TypeError(\"time must be integer or datetime\")\n",
    "            metadata['fraq'] = freq \n",
    "            if differences.nunique()>1:\n",
    "                df_norm = extend_time_df(df_norm,freq,group).merge(dataset,how='left')\n",
    "                print(df_norm.shape)\n",
    "        \n",
    "        else:\n",
    "            self.freq =  dataset.time.diff()[1:].min() ##care there can be holes in data!\n",
    "\n",
    "        if check_past:\n",
    "            num_var_past = list(set(num_var_past).union(set(target)))\n",
    "        if group is None:\n",
    "            df_norm = df_norm.sort_values(by=time_var).reset_index()\n",
    "        else:\n",
    "            df_norm = df_norm.sort_values(by=[time_var,group]).reset_index()\n",
    "\n",
    "        self.df = df_norm\n",
    "        self.metadata = metadata   \n",
    "        self.target = target\n",
    "        self.num_var_past = num_var_past\n",
    "        self.num_var_fut = num_var_fut\n",
    "        self.cat_var_past = cat_var_past\n",
    "        self.cat_var_fut = cat_var_fut\n",
    "        self.length = 1 if group is None else df[group].nunique()\n",
    "        self.group = group\n",
    "    def __getitem__(self, idx):\n",
    "        # Returns only tensors, no metadata\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        if self.group is None:\n",
    "            df = self.df\n",
    "        else:\n",
    "            df = self.df[self.df.group==idx] ## ANOTHER COMMENT: IDX?? what if we have 10 timeseries with groups??\n",
    "            \n",
    "        result = {\n",
    "            #'t': tensor(...), ##FIRST COMMENT: TIMESTAMP CANT be cast as tensor! \n",
    "            'y': torch.tensor(df[self.target].values,dtype=torch.float32,device=device), ##SECOND COMMENT device\n",
    "            'x_past': torch.tensor(df[self.num_var_past].values,dtype=torch.float32,device=device), ##SECOND COMMENT device\n",
    "            #'t_f': tensor(...), ?? WHAT IS THAT?\n",
    "        \n",
    "            }\n",
    "        if self.group is not None:\n",
    "             result['group']= torch.tensor(idx,device=device,dtype=torch.long) \n",
    "        if len(self.num_var_fut)>0:\n",
    "             result['num_var_fut']= torch.tensor(df[self.num_var_fut].values,dtype=torch.float32,device=device)\n",
    "        if len(self.cat_var_fut)>0:\n",
    "             result['cat_var_fut']= torch.tensor(df[self.cat_var_fut].values,dtype=torch.long,device=device)\n",
    "        if len(self.cat_var_fut)>0:\n",
    "             result['cat_var_fut']= torch.tensor(df[self.cat_var_fut].values,dtype=torch.long,device=device)\n",
    "        return result\n",
    "    def get_metadata(self):\n",
    "        return self.metadata\n",
    "\n",
    "# Layer D2\n",
    "\n",
    "\n",
    "class DecoderEncoderDataModule(L.LightningDataModule):\n",
    "    def __init__(self, d1_dataset, batch_size=32, num_workers=4,metadata=None):\n",
    "        super().__init__()\n",
    "        # initialize other  params\n",
    "        self.d1_dataset = d1_dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.metadata = None  # Will be set in setup() NO! THhe metadata for training are not related with metadata of the data!\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        # Get metadata from D1 layer during setup\n",
    "        #self.metadata = self.d1_dataset.get_metadata() ##NO SEE COMMENT BEFORE!\n",
    "        \n",
    "        if stage == 'fit' or stage is None: \n",
    "            ##CLEAR FOR ME IN CASE OF SINGLE TIMESERIES (EG PANDAS LOADER) not clear in case of chunk of data of the same \n",
    "            ## do we suppose to have NO HOLES in data? do we check it runtime?\n",
    "            pass\n",
    "        \n",
    "        if stage == 'test' or stage is None:\n",
    "            # Any test-specific setup\n",
    "            pass\n",
    "            \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.d1_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            **other_params\n",
    "        )\n",
    "\n",
    "# Layer M\n",
    "class DecoderEncoderModel(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.metadata = None\n",
    "        \n",
    "    def setup(self, stage=None):\n",
    "        # Get metadata from datamodule during setup\n",
    "        self.metadata = self.trainer.datamodule.metadata\n",
    "        \n",
    "        # Initialize layer T model using metadata\n",
    "    \n",
    "    def forward(self, x):\n",
    "     # forward logic\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "290ab40d-f440-4f7f-9ae9-8855a04f1ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module_metadata = dict(\n",
    "  perc_train= 0.7,\n",
    "  perc_valid= 0.1,\n",
    "  range_train= None,\n",
    "  range_validation= None ,\n",
    "  range_test= None,\n",
    "  shift= 0,\n",
    "  starting_point= None,\n",
    "  skip_step= 1,\n",
    "  past_steps=16,\n",
    "  future_steps= 16,\n",
    "  scaler= 'sklearn.preprocessing.StandardScaler()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a9788854-81eb-49de-a974-5e3a9144a59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_var_past = ts.cat_var\n",
    "cat_var_fut = ts.cat_var\n",
    "num_var_past = ts.num_var+['x_num']\n",
    "num_var_fut = []\n",
    "group = None\n",
    "time_var = 'time'\n",
    "target = ['signal']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e4ca4055-7f36-446c-9b21-6c0456b152cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 6)\n"
     ]
    }
   ],
   "source": [
    "ds = PandasTSDataSet(dataset,'time', \n",
    "                     cat_var_past, \n",
    "                     cat_var_fut, \n",
    "                     num_var_past,\n",
    "                     num_var_fut,\n",
    "                     target,\n",
    "                     group = None, \n",
    "                     metadata={}\n",
    "                     ,check_holes_and_duplicates=True,check_past=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "519ebe66-3d64-41df-a191-81c0ba518e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 1])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(ds))['y'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4c6bec-ee6e-4c54-9223-bf3a72ed46da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
