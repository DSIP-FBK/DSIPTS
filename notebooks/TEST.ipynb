{
 "cells": [
  {
   "cell_type": "raw",
   "id": "55c75749-ec70-4365-ac8a-f96552da4528",
   "metadata": {},
   "source": [
    "from dsipts import Categorical,TimeSeries, RNN\n",
    "settimana = Categorical('settimanale',1,[1,1,1,1,1,1,1],7,'multiplicative',[0.9,0.8,0.7,0.6,0.5,0.99,0.99])\n",
    "\n",
    "##montly, additive (here there are only 5 month)\n",
    "mese = Categorical('mensile',1,[31,28,20,10,33],5,'additive',[10,20,-10,20,0])\n",
    "\n",
    "##spot categorical variables: in this case it occurs every 100 days and it lasts 7 days adding 10 to the original timeseries\n",
    "spot = Categorical('spot',100,[7],1,'additive',[10])\n",
    "\n",
    "##initizate a timeseries object\n",
    "ts = TimeSeries('prova')\n",
    "ts.generate_signal(noise_mean=1,categorical_variables=[settimana,mese,spot],length=5000,type=0)\n",
    "dataset = ts.dataset\n",
    "dataset['x_num'] = 0.0\n",
    "dataset.loc[:dataset.shape[0]-10,'x_num']= dataset['x_num'].values[9:]\n",
    "cat_var_past = ts.cat_var\n",
    "cat_var_fut = ts.cat_fut\n",
    "num_var_past = ts.num_var+['x_num']\n",
    "import pickle \n",
    "with open('example.pkl', 'wb') as f:\n",
    "    pickle.dump([dataset,cat_var_past,cat_var_fut,num_var_past],f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "459c491c-98ab-4513-b5eb-9f5c604b9df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.to_csv('dataset.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b53411e-8c81-4dc9-8e2e-c83c3a568be1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "beea9295-9164-4bae-b2e1-8c5cc6c585c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import pandas as pd\n",
    "from typing import Union\n",
    "from sklearn.preprocessing import LabelEncoder,OrdinalEncoder\n",
    "from datetime import datetime\n",
    "import lightning as L\n",
    "with open('example.pkl', 'rb') as f:\n",
    "    dataset,cat_var_past,cat_var_fut,num_var_past = pickle.load(f)\n",
    "num_var_fut = []\n",
    "group = None\n",
    "time_var = 'time'\n",
    "target = ['signal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db453ed2-df16-44bf-bc86-184fd4010e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = dataset.copy()\n",
    "dataset2['group'] = 2\n",
    "dataset['group'] = 1 \n",
    "dataset = pd.concat([dataset, dataset2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd967d57-478d-4bd5-bf92-b369ca730c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d1b49d6-8e61-447d-9e2e-44893f104cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extend_time_df(x:pd.DataFrame,freq:Union[str,int],group:Union[str,None]=None,global_minmax:bool=False)-> pd.DataFrame:\n",
    "    \"\"\"Utility for generating a full dataset and then merge the real data\n",
    "\n",
    "    Args:\n",
    "        x (pd.DataFrame): dataframe containing the column time\n",
    "        freq (str): frequency (in pandas notation) of the resulting dataframe\n",
    "        group (string or None): if not None the min max are computed by the group column, default None\n",
    "        global_minmax (bool): if True the min_max is computed globally for each group. Usually used for stacked model\n",
    "    Returns:\n",
    "        pd.DataFrame: a dataframe with the column time ranging from thr minumum of x to the maximum with frequency `freq`\n",
    "    \"\"\"\n",
    "\n",
    "    if group is None:\n",
    "\n",
    "        if isinstance(freq,int):\n",
    "            empty = pd.DataFrame({'time':list(range(x.time.min(),x.time.max(),freq))})\n",
    "        else:\n",
    "            empty = pd.DataFrame({'time':pd.date_range(x.time.min(),x.time.max(),freq=freq)})\n",
    "\n",
    "    else:\n",
    "        \n",
    "        if global_minmax:dataset\n",
    "            _min = pd.DataFrame({group:x[group].unique(),'time':x.time.min()})\n",
    "            _max = pd.DataFrame({group:x[group].unique(),'time':x.time.max()})\n",
    "\n",
    "        else:\n",
    "            _min = x.groupby(group).time.min().reset_index()\n",
    "            _max = x.groupby(group).time.max().reset_index()\n",
    "        empty = []\n",
    "        for c in x[group].unique():\n",
    "            if isinstance(freq,int):\n",
    "                empty.append(pd.DataFrame({group:c,'time':np.arange(_min.time[_min[group]==c].values[0],_max.time[_max[group]==c].values[0],freq)}))\n",
    "\n",
    "            else:\n",
    "                empty.append(pd.DataFrame({group:c,'time':pd.date_range(_min.time[_min[group]==c].values[0],_max.time[_max[group]==c].values[0],freq=freq)}))\n",
    "            \n",
    "        empty = pd.concat(empty,ignore_index=True)\n",
    "    return empty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e2ac8bd-fc6b-4400-b8f3-b86f1138671b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PandasTSDataSet:\n",
    "    def __init__(self, df,time_var, cat_var_past, cat_var_fut, num_var_past, num_var_fut,target, group = None, metadata={},check_holes_and_duplicates=True,check_past=True):\n",
    "        \n",
    "        numerica_var = list(set(num_var_past).union(set(num_var_fut)).union(set(target)))\n",
    "        df_norm = df[numerica_var+[time_var]].copy()\n",
    "        label_encoders = {}\n",
    "        ##Encoders for categorical since we want to return tensors\n",
    "        for c in set(cat_var_past).union(set(cat_var_fut)):\n",
    "            label_encoders[c] = LabelEncoder()\n",
    "            df_norm[c] = label_encoders[c].fit_transform(df[c])\n",
    "        if group is not None:\n",
    "            label_encoders[group] = OrdinalEncoder()\n",
    "            df_norm[group] = label_encoders[group].fit_transform(df[group])\n",
    "        #complete the dataset, we can think to devide it in chunks of consecutive ts....\n",
    "        if check_holes_and_duplicates:\n",
    "            df_norm.drop_duplicates(subset=['time'] if group is None else [group,'time'],  keep='first', inplace=True, ignore_index=True)\n",
    "            print(df_norm.shape)\n",
    "            if group is None:\n",
    "                differences = df_norm.time.diff()[1:]\n",
    "            else:\n",
    "                differences = df_norm[df_norm[group]==df_norm[group].unique()[0]].time.diff()[1:]\n",
    "    \n",
    "            if isinstance(df_norm.time[0], datetime):\n",
    "                freq = pd.to_timedelta(differences.min())   \n",
    "            else:\n",
    "                if int(df_norm.time[0])==df_norm.time[0]: ##ONLY THINK THAT WORKS IN GENERAL\n",
    "                    freq = int(differences.min())\n",
    "                else:\n",
    "                    raise TypeError(\"time must be integer or datetime\")\n",
    "            metadata['fraq'] = freq \n",
    "            if differences.nunique()>1:\n",
    "                df_norm = extend_time_df(df_norm,freq,group).merge(dataset,how='left')\n",
    "                print(df_norm.shape)\n",
    "        \n",
    "        else:\n",
    "            metadata['freq'] =  dataset.time.diff()[1:].min() ##care there can be holes in data!\n",
    "\n",
    "        if check_past:\n",
    "            num_var_past = list(set(num_var_past).union(set(target)))\n",
    "        if group is None:\n",
    "            df_norm = df_norm.sort_values(by=time_var).reset_index()\n",
    "            self.lengths = df_norm.shape[0]\n",
    "        else:\n",
    "            df_norm = df_norm.sort_values(by=[time_var,group]).reset_index()\n",
    "        \n",
    "        df_norm['valid'] = ~pd.isnull(dataset.max(axis=1))\n",
    "        df_norm['valid'] = df_norm['valid'].astype(int)\n",
    "        self.df = df_norm\n",
    "        metadata['target'] =  target\n",
    "        metadata['num_var_past'] = num_var_past\n",
    "        metadata['num_var_fut'] = num_var_fut\n",
    "        metadata['cat_var_past'] = cat_var_past\n",
    "        metadata['cat_var_fut'] = cat_var_fut\n",
    "        metadata['past_variables'] = list(set(cat_var_past).union(set(num_var_past)))\n",
    "        metadata['future_variables'] = list(set(cat_var_fut).union(set(num_var_fut)).union(set(target)))\n",
    "        metadata['time_var'] =time_var\n",
    "        metadata['group'] = group\n",
    "        \n",
    "        self.metadata = metadata\n",
    "        ## compute the length of each timeseries\n",
    "        ll = {}\n",
    "        if group is None:\n",
    "            ll[0] = self.df.shape[0]\n",
    "        else:\n",
    "            for i,row in self.df.groupby(group)[time_var].count().reset_index().iterrows():\n",
    "                ll[row[group]] = row[time_var]\n",
    "        self.lengths  = ll\n",
    "        \n",
    "\n",
    "    def get_total_len(self):\n",
    "        return sum(self.lengths.values())\n",
    "\n",
    "    def get_id_ts_by_idx(self,idx):\n",
    "        tmp = np.cumsum(sum(self.lengths.values()))\n",
    "        idx =  min(np.where(tmp>idx)[0])\n",
    "        return idx, 0 if idx==0 else tmp[idx-1]\n",
    "\n",
    "    ## this is the most delicate part\n",
    "    def __getitem__(self, idx):\n",
    "        # Returns only tensors, no metadata\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        if self.metadata['group'] is None:\n",
    "            df = self.df\n",
    "        else:\n",
    "            df = self.df[self.df.group==idx] ## ANOTHER COMMENT: IDX?? what if we have 10 timeseries with groups??\n",
    "            \n",
    "        result = {\n",
    "            #'t': tensor(...), ##FIRST COMMENT: TIMESTAMP CANT be cast as tensor! \n",
    "            'y': torch.tensor(df[self.metadata['target']].values,dtype=torch.float32,device=device), ##SECOND COMMENT device\n",
    "            'x_past': torch.tensor(df[self.metadata['num_var_past']].values,dtype=torch.float32,device=device), ##SECOND COMMENT device\n",
    "            'is_valid': torch.tensor(df.valid.values,dtype=torch.int,device=device), ##SECOND COMMENT device\n",
    "            #'t_f': tensor(...), ?? WHAT IS THAT?\n",
    "        \n",
    "            }\n",
    "        if self.metadata['group'] is not None:\n",
    "             result['group']= torch.tensor(idx,device=device,dtype=torch.long) \n",
    "        if len(self.metadata['num_var_fut'])>0:\n",
    "             result['num_var_fut']= torch.tensor(df[self.metadata['num_var_fut']].values,dtype=torch.float32,device=device)\n",
    "        if len(self.metadata['cat_var_fut'])>0:\n",
    "             result['cat_var_past']= torch.tensor(df[self.metadata['cat_var_past']].values,dtype=torch.long,device=device)\n",
    "        if len(self.metadata['cat_var_fut'])>0:\n",
    "             result['cat_var_fut']= torch.tensor(df[self.metadata['cat_var_fut']].values,dtype=torch.long,device=device)\n",
    "        return result\n",
    "    def get_metadata(self):\n",
    "        return self.metadata\n",
    "\n",
    "# Layer D2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "290ab40d-f440-4f7f-9ae9-8855a04f1ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module_metadata = dict(\n",
    "  perc_train= 0.7,\n",
    "  perc_valid= 0.1,\n",
    "  range_train= None,\n",
    "  range_validation= None ,\n",
    "  range_test= None,\n",
    "  shift= 0,\n",
    "  starting_point= None,\n",
    "  skip_step= 1,\n",
    "  past_steps=16,\n",
    "  future_steps= 16,\n",
    "  scaler= 'sklearn.preprocessing.StandardScaler()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4ca4055-7f36-446c-9b21-6c0456b152cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 6)\n"
     ]
    }
   ],
   "source": [
    "ds = PandasTSDataSet(dataset,'time', \n",
    "                     cat_var_past, \n",
    "                     cat_var_fut, \n",
    "                     num_var_past,\n",
    "                     num_var_fut,\n",
    "                     target,\n",
    "                     group = None, \n",
    "                     metadata={}\n",
    "                     ,check_holes_and_duplicates=True,check_past=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "519ebe66-3d64-41df-a191-81c0ba518e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12bc5f1c-2de1-4837-9d2a-e764fa395bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import default_collate\n",
    "import torch\n",
    "def my_collate(batch):\n",
    "    batch = list(filter(lambda x : x is not None, batch))\n",
    "    print(len(batch))\n",
    "    return default_collate(batch)\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self,data,metadata)->torch.utils.data.Dataset:\n",
    "       \n",
    "        self.data = data  \n",
    "        self.metadata = metadata\n",
    "        self.metadata_dataset = data.metadata\n",
    "    def __len__(self):\n",
    "        \n",
    "        return self.data.get_total_len()-len(self.data.lengths)*self.metadata['future_steps']\n",
    "    ##this getitem calls the getitem of the data as desired\n",
    "    def __getitem__(self, idxs): \n",
    "        sample = {}\n",
    "        IDX,difference = self.data.get_id_ts_by_idx(idxs) \n",
    "        idxs-=difference\n",
    "        tmp = self.data.__getitem__(IDX)\n",
    "        if idxs+self.metadata['future_steps']>self.data.lengths[IDX]:\n",
    "            return None\n",
    "        \n",
    "        for k in tmp.keys():\n",
    "\n",
    "            if len(tmp[k][idxs-self.metadata['past_steps']:idxs]) + len(tmp[k][idxs:idxs+self.metadata['future_steps']]) == self.metadata['future_steps']+self.metadata['past_steps']:\n",
    "                if tmp['is_valid'][idxs-self.metadata['past_steps']:idxs+self.metadata['future_steps']].sum()==self.metadata['future_steps']+self.metadata['past_steps']:\n",
    "                    if '_past' in k:\n",
    "                        sample[k] = tmp[k][idxs-self.metadata['past_steps']:idxs]\n",
    "                    elif '_fut' in k or k=='y':\n",
    "                        sample[k] = tmp[k][idxs:idxs+self.metadata['future_steps']]\n",
    "                    else:\n",
    "                        pass\n",
    "        if len(sample)==0:\n",
    "            return None\n",
    "        else:\n",
    "            return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e43bfd7-12b3-48c2-8b33-d5ca6681959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl =  DataLoader(\n",
    "            MyDataset(ds,data_module_metadata), ##change respect to the initial vignette, can not use standard dataset\n",
    "            batch_size=32,\n",
    "            collate_fn=my_collate\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dde2ba1f-f6f8-483c-a404-5917b84ce37a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "torch.Size([16, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "32\n",
      "torch.Size([32, 16, 1])\n",
      "24\n",
      "torch.Size([24, 16, 1])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "for x in dl:\n",
    "    \n",
    "    print(x['y'].shape)  #It works! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaff143f-9754-4335-8a68-c5829d2d22d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##WIP IN THE NEXT CELLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4c6bec-ee6e-4c54-9223-bf3a72ed46da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DecoderEncoderDataModule(L.LightningDataModule):\n",
    "    def __init__(self, d1_dataset, batch_size=32, num_workers=4,metadata=None):\n",
    "        super().__init__()\n",
    "        # initialize other  params\n",
    "        self.d1_dataset = d1_dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.metadata = None  # Will be set in setup() NO! THhe metadata for training are not related with metadata of the data!\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        # Get metadata from D1 layer during setup\n",
    "        #self.metadata = self.d1_dataset.get_metadata() ##NO SEE COMMENT BEFORE!\n",
    "        \n",
    "        if stage == 'fit' or stage is None: \n",
    "            ##CLEAR FOR ME IN CASE OF SINGLE TIMESERIES (EG PANDAS LOADER) not clear in case of chunk of data of the same \n",
    "            ## do we suppose to have NO HOLES in data? do we check it runtime?\n",
    "            #I can precompute here the indexes \n",
    "            \n",
    "        \n",
    "                    \n",
    "            pass\n",
    "        \n",
    "        if stage == 'test' or stage is None:\n",
    "            # Any test-specific setup\n",
    "            pass\n",
    "            \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            MyDataset(self.d1_dataset),\n",
    "            batch_size=self.batch_size,\n",
    "            **other_params\n",
    "        )\n",
    "\n",
    "# Layer M\n",
    "class DecoderEncoderModel(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.metadata = None\n",
    "        \n",
    "    def setup(self, stage=None):\n",
    "        # Get metadata from datamodule during setup\n",
    "        self.metadata = self.trainer.datamodule.metadata\n",
    "        \n",
    "        # Initialize layer T model using metadata\n",
    "    \n",
    "    def forward(self, x):\n",
    "     # forward logic\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
