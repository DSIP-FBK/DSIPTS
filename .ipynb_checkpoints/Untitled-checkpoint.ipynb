{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b721edcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agobbi/.local/lib/python3.9/site-packages/sktime/utils/data_io.py:722: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"dim_\" + str(dim)] = instance_list[dim]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='3' class='' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      3.00% [3/100 03:04<1:39:32]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.189713</td>\n",
       "      <td>0.714368</td>\n",
       "      <td>0.538922</td>\n",
       "      <td>0.531215</td>\n",
       "      <td>02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.199110</td>\n",
       "      <td>0.720016</td>\n",
       "      <td>0.546068</td>\n",
       "      <td>0.539160</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.193862</td>\n",
       "      <td>0.715890</td>\n",
       "      <td>0.550892</td>\n",
       "      <td>0.540579</td>\n",
       "      <td>00:32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='30' class='' max='92' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      32.61% [30/92 00:12<00:26 1.2015]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-b2ceb1b78d5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m learn = Learner(dls, model, loss_func=LabelSmoothingCrossEntropyFlat(), \n\u001b[1;32m      9\u001b[0m                 metrics=[RocAucBinary(), accuracy],  cbs=ShowGraphCallback2())\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/callback/schedule.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    111\u001b[0m     scheds = {'lr': combined_cos(pct_start, lr_max/div, lr_max, lr_max/div_final),\n\u001b[1;32m    112\u001b[0m               'mom': combined_cos(pct_start, *(self.moms if moms is None else moms))}\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mParamScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_hypers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelFitException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_end_cleanup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_end_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelTrainException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mall_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tsai/learner.py\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mb_on_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_on_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_one_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'batch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelBatchException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_one_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_pred'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tsai/models/TST.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;31m# Encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m                                             \u001b[0;31m# z: [bs x q_len x d_model]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m                \u001b[0;31m# z: [bs x q_len * d_model]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                         \u001b[0;31m# z: [bs x d_model x q_len]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tsai/models/TST.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tsai/models/TST.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, mask)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;31m## Add & Norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Add: residual connection with residual dropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchnorm_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m# Norm: batchnorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;31m# Feed-forward sublayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         return F.batch_norm(\n\u001b[0m\u001b[1;32m    168\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2279\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2281\u001b[0;31m     return torch.batch_norm(\n\u001b[0m\u001b[1;32m   2282\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2283\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tsai.all import *\n",
    "\n",
    "X, y, splits = get_UCR_data('FaceDetection', return_split=False)\n",
    "tfms  = [None, [Categorize()]]\n",
    "dsets = TSDatasets(X, y, tfms=tfms, splits=splitslits,verbose=True)\n",
    "dls   = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=64, batch_tfms=TSStandardize(by_var=True))\n",
    "model = TST(dls.vars, dls.c, dls.len, res_dropout=0.3, fc_dropout=0.9)\n",
    "learn = Learner(dls, model, loss_func=LabelSmoothingCrossEntropyFlat(), \n",
    "                metrics=[RocAucBinary(), accuracy],  cbs=ShowGraphCallback2())\n",
    "learn.fit_one_cycle(100, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96df70f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch import Tensor\n",
    "from typing import Optional, Tuple, List\n",
    "from torch import nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.nn.init import kaiming_uniform_,uniform_,xavier_uniform_,normal_\n",
    "import inspect\n",
    "def module(*flds, **defaults):\n",
    "    \"Decorator to create an `nn.Module` using `f` as `forward` method\"\n",
    "    pa = [inspect.Parameter(o, inspect.Parameter.POSITIONAL_OR_KEYWORD) for o in flds]\n",
    "    pb = [inspect.Parameter(k, inspect.Parameter.POSITIONAL_OR_KEYWORD, default=v)\n",
    "          for k,v in defaults.items()]\n",
    "    params = pa+pb\n",
    "    all_flds = [*flds,*defaults.keys()]\n",
    "\n",
    "    def _f(f):\n",
    "        class c(nn.Module):\n",
    "            def __init__(self, *args, **kwargs):\n",
    "                super().__init__()\n",
    "                for i,o in enumerate(args): kwargs[all_flds[i]] = o\n",
    "                kwargs = merge(defaults,kwargs)\n",
    "                for k,v in kwargs.items(): \n",
    "                    setattr(self,k,v)\n",
    "            #__repr__ = basic_repr(all_flds)\n",
    "            forward = f\n",
    "        c.__signature__ = inspect.Signature(params)\n",
    "        c.__name__ = c.__qualname__ = f.__name__\n",
    "        c.__doc__  = f.__doc__\n",
    "        return c\n",
    "    return _f\n",
    "\n",
    "def sigmoid_range(x, low, high):\n",
    "    \"Sigmoid function with range `(low, high)`\"\n",
    "    return torch.sigmoid(x) * (high - low) + low\n",
    "\n",
    "\n",
    "@module('low', 'high')\n",
    "def SigmoidRange(self, x):\n",
    "    \"Sigmoid module with range `(low, high)`\"\n",
    "    return sigmoid_range(x, self.low, self.high)\n",
    "\n",
    "\n",
    "def get_output_shape(model, image_dim):\n",
    "    return model(torch.rand(*(image_dim))).data.shape\n",
    "\n",
    "\n",
    "def ifnone(a, b):\n",
    "    # From fastai.fastcore\n",
    "    \"`b` if `a` is None else `a`\"\n",
    "    return b if a is None else a\n",
    "\n",
    "\n",
    "# Internal Cell\n",
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "\n",
    "class Pad1d(nn.ConstantPad1d):\n",
    "    def __init__(self, padding, value=0.):\n",
    "        super().__init__(padding, value)\n",
    "\n",
    "\n",
    "def same_padding1d(seq_len, ks, stride=1, dilation=1):\n",
    "\n",
    "    \"Same padding formula as used in Tensorflow\"\n",
    "    p = (seq_len - 1) * stride + (ks - 1) * dilation + 1 - seq_len\n",
    "    return p // 2, p - p // 2\n",
    "\n",
    "\n",
    "#@delegates(nn.Conv1d)\n",
    "class Conv1dSame(nn.Module):\n",
    "    \"Conv1d with padding='same'\"\n",
    "\n",
    "    def __init__(self, ni, nf, ks=3, stride=1, dilation=1, **kwargs):\n",
    "        super().__init__()\n",
    "        self.ks, self.stride, self.dilation = ks, stride, dilation\n",
    "        self.conv1d_same = nn.Conv1d(ni, nf, ks, stride=stride, dilation=dilation, **kwargs)\n",
    "        self.weight = self.conv1d_same.weight\n",
    "        self.bias = self.conv1d_same.bias\n",
    "        self.pad = Pad1d\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.padding = same_padding1d(x.shape[-1], self.ks, dilation=self.dilation)  #stride=self.stride not used in padding calculation!\n",
    "        return self.conv1d_same(self.pad(self.padding)(x))\n",
    "\n",
    "def init_linear(m, act_func=None, init='auto', bias_std=0.01):\n",
    "    if getattr(m,'bias',None) is not None and bias_std is not None:\n",
    "        if bias_std != 0: normal_(m.bias, 0, bias_std)\n",
    "        else: m.bias.data.zero_()\n",
    "    if init=='auto':\n",
    "        if act_func in (F.relu_,F.leaky_relu_): init = kaiming_uniform_\n",
    "        else: init = getattr(act_func.__class__, '__default_init__', None)\n",
    "        if init is None: init = getattr(act_func, '__default_init__', None)\n",
    "    if init is not None: init(m.weight)\n",
    "\n",
    "#@delegates(nn.Conv1d)\n",
    "def Conv1d(ni, nf, kernel_size=None, ks=None, stride=1, padding='same', dilation=1, init='auto', bias_std=0.01, **kwargs):\n",
    "    \"conv1d layer with padding='same', 'causal', 'valid', or any integer (defaults to 'same')\"\n",
    "    assert not (kernel_size and ks), 'use kernel_size or ks but not both simultaneously'\n",
    "    assert kernel_size is not None or ks is not None, 'you need to pass a ks'\n",
    "    kernel_size = kernel_size or ks\n",
    "    if padding == 'same':\n",
    "        if kernel_size % 2 == 1:\n",
    "            conv = nn.Conv1d(ni, nf, kernel_size, stride=stride, padding=kernel_size // 2 * dilation, dilation=dilation, **kwargs)\n",
    "        else:\n",
    "            conv = Conv1dSame(ni, nf, kernel_size, stride=stride, dilation=dilation, **kwargs)\n",
    "    elif padding == 'causal':\n",
    "        conv = Conv1dCausal(ni, nf, kernel_size, stride=stride, dilation=dilation, **kwargs)\n",
    "    elif padding == 'valid':\n",
    "        conv = nn.Conv1d(ni, nf, kernel_size, stride=stride, padding=0, dilation=dilation, **kwargs)\n",
    "    else:\n",
    "        conv = nn.Conv1d(ni, nf, kernel_size, stride=stride, padding=padding, dilation=dilation, **kwargs)\n",
    "    init_linear(conv, None, init=init, bias_std=bias_std)\n",
    "    return conv\n",
    "\n",
    "\n",
    "class Conv1dCausal(nn.Module):\n",
    "    def __init__(self, ni, nf, ks, stride=1, dilation=1, **kwargs):\n",
    "        super().__init__()\n",
    "        padding = (ks - 1) * dilation\n",
    "        self.conv_causal = nn.Conv1d(ni, nf, ks, stride=stride, padding=padding, dilation=dilation, **kwargs)\n",
    "        self.weight = self.conv_causal.weight\n",
    "        self.bias = self.conv_causal.bias\n",
    "        self.chomp_size = padding\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_causal(x)\n",
    "        return x[..., :-self.chomp_size].contiguous()\n",
    "\n",
    "\n",
    "class Concat(nn.Module):\n",
    "    def __init__(self, dim=1):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, *x):\n",
    "        return torch.cat(*x, dim=self.dim)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}(dim={self.dim})'\n",
    "\n",
    "\n",
    "class Transpose(nn.Module):\n",
    "    def __init__(self, *dims, contiguous=False):\n",
    "        super().__init__()\n",
    "        self.dims, self.contiguous = dims, contiguous\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.contiguous: return x.transpose(*self.dims).contiguous()\n",
    "        else: return x.transpose(*self.dims)\n",
    "\n",
    "    def __repr__(self):\n",
    "        if self.contiguous: return f\"{self.__class__.__name__}(dims={', '.join([str(d) for d in self.dims])}).contiguous()\"\n",
    "        else: return f\"{self.__class__.__name__}({', '.join([str(d) for d in self.dims])})\"\n",
    "\n",
    "\n",
    "class _ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, d_k: int):\n",
    "        super().__init__()\n",
    "        self.d_k = d_k\n",
    "\n",
    "    def forward(self, q: Tensor, k: Tensor, v: Tensor, mask: Optional[Tensor] = None):\n",
    "\n",
    "        # MatMul (q, k) - similarity scores for all pairs of positions in an input sequence\n",
    "        scores = torch.matmul(q, k)  # scores : [bs x n_heads x q_len x q_len]\n",
    "\n",
    "        # Scale\n",
    "        scores = scores / (self.d_k**0.5)\n",
    "\n",
    "        # Mask (optional)\n",
    "        if mask is not None: scores.masked_fill_(mask, -1e9)\n",
    "\n",
    "        # SoftMax\n",
    "        attn = F.softmax(scores, dim=-1)  # attn   : [bs x n_heads x q_len x q_len]\n",
    "\n",
    "        # MatMul (attn, v)\n",
    "        context = torch.matmul(attn, v)  # context: [bs x n_heads x q_len x d_v]\n",
    "\n",
    "        return context, attn\n",
    "\n",
    "\n",
    "# Internal Cell\n",
    "class _MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model: int, n_heads: int, d_k: int, d_v: int):\n",
    "        r\"\"\"\n",
    "        Input shape:  Q, K, V:[batch_size (bs) x q_len x d_model], mask:[q_len x q_len]\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.n_heads, self.d_k, self.d_v = n_heads, d_k, d_v\n",
    "\n",
    "        self.W_Q = nn.Linear(d_model, d_k * n_heads, bias=False)\n",
    "        self.W_K = nn.Linear(d_model, d_k * n_heads, bias=False)\n",
    "        self.W_V = nn.Linear(d_model, d_v * n_heads, bias=False)\n",
    "\n",
    "        self.W_O = nn.Linear(n_heads * d_v, d_model, bias=False)\n",
    "\n",
    "    def forward(self, Q: Tensor, K: Tensor, V: Tensor, mask: Optional[Tensor] = None):\n",
    "\n",
    "        bs = Q.size(0)\n",
    "\n",
    "        # Linear (+ split in multiple heads)\n",
    "        q_s = self.W_Q(Q).view(bs, -1, self.n_heads, self.d_k).transpose(1, 2)  # q_s    : [bs x n_heads x q_len x d_k]\n",
    "        k_s = self.W_K(K).view(bs, -1, self.n_heads, self.d_k).permute(0, 2, 3,\n",
    "                                                                       1)  # k_s    : [bs x n_heads x d_k x q_len] - transpose(1,2) + transpose(2,3)\n",
    "        v_s = self.W_V(V).view(bs, -1, self.n_heads, self.d_v).transpose(1, 2)  # v_s    : [bs x n_heads x q_len x d_v]\n",
    "\n",
    "        # Scaled Dot-Product Attention (multiple heads)\n",
    "        context, attn = _ScaledDotProductAttention(self.d_k)(q_s, k_s,\n",
    "                                                             v_s)  # context: [bs x n_heads x q_len x d_v], attn: [bs x n_heads x q_len x q_len]\n",
    "\n",
    "        # Concat\n",
    "        context = context.transpose(1, 2).contiguous().view(bs, -1, self.n_heads * self.d_v)  # context: [bs x q_len x n_heads * d_v]\n",
    "\n",
    "        # Linear\n",
    "        output = self.W_O(context)  # context: [bs x q_len x d_model]\n",
    "\n",
    "        return output, attn\n",
    "\n",
    "\n",
    "# Internal Cell\n",
    "def get_activation_fn(activation):\n",
    "    if activation == \"relu\": return nn.ReLU()\n",
    "    elif activation == \"gelu\": return nn.GELU()\n",
    "    else: return activation()\n",
    "\n",
    "\n",
    "#         raise ValueError(f'{activation} is not available. You can use \"relu\" or \"gelu\"')\n",
    "\n",
    "\n",
    "class _TSTEncoderLayer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 q_len: int,\n",
    "                 d_model: int,\n",
    "                 n_heads: int,\n",
    "                 d_k: Optional[int] = None,\n",
    "                 d_v: Optional[int] = None,\n",
    "                 d_ff: int = 256,\n",
    "                 dropout: float = 0.1,\n",
    "                 activation: str = \"gelu\"):\n",
    "        super().__init__()\n",
    "        assert d_model // n_heads, f\"d_model ({d_model}) must be divisible by n_heads ({n_heads})\"\n",
    "        d_k = ifnone(d_k, d_model // n_heads)\n",
    "        d_v = ifnone(d_v, d_model // n_heads)\n",
    "\n",
    "        # Multi-Head attention\n",
    "        self.self_attn = _MultiHeadAttention(d_model, n_heads, d_k, d_v)\n",
    "\n",
    "        # Add & Norm\n",
    "        self.dropout_attn = nn.Dropout(dropout)\n",
    "        self.batchnorm_attn = nn.Sequential(Transpose(1, 2), nn.BatchNorm1d(d_model), Transpose(1, 2))\n",
    "\n",
    "        # Position-wise Feed-Forward\n",
    "        self.ff = nn.Sequential(nn.Linear(d_model, d_ff), get_activation_fn(activation), nn.Dropout(dropout), nn.Linear(d_ff, d_model))\n",
    "\n",
    "        # Add & Norm\n",
    "        self.dropout_ffn = nn.Dropout(dropout)\n",
    "        self.batchnorm_ffn = nn.Sequential(Transpose(1, 2), nn.BatchNorm1d(d_model), Transpose(1, 2))\n",
    "\n",
    "    def forward(self, src: Tensor, mask: Optional[Tensor] = None) -> Tensor:\n",
    "\n",
    "        # Multi-Head attention sublayer\n",
    "        ## Multi-Head attention\n",
    "        src2, attn = self.self_attn(src, src, src, mask=mask)\n",
    "        ## Add & Norm\n",
    "        src = src + self.dropout_attn(src2)  # Add: residual connection with residual dropout\n",
    "        src = self.batchnorm_attn(src)  # Norm: batchnorm\n",
    "\n",
    "        # Feed-forward sublayer\n",
    "        ## Position-wise Feed-Forward\n",
    "        src2 = self.ff(src)\n",
    "        ## Add & Norm\n",
    "        src = src + self.dropout_ffn(src2)  # Add: residual connection with residual dropout\n",
    "        src = self.batchnorm_ffn(src)  # Norm: batchnorm\n",
    "\n",
    "        return src\n",
    "\n",
    "\n",
    "# Internal Cell\n",
    "class _TSTEncoder(nn.Module):\n",
    "    def __init__(self, q_len, d_model, n_heads, d_k=None, d_v=None, d_ff=None, dropout=0.1, activation='gelu', n_layers=1):\n",
    "\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            _TSTEncoderLayer(q_len, d_model, n_heads=n_heads, d_k=d_k, d_v=d_v, d_ff=d_ff, dropout=dropout, activation=activation)\n",
    "            for i in range(n_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, src):\n",
    "        output = src\n",
    "        for mod in self.layers:\n",
    "            output = mod(output)\n",
    "        return output\n",
    "\n",
    "# Cell\n",
    "class TST(nn.Module):\n",
    "    def __init__(self,\n",
    "                 c_in: int,\n",
    "                 c_out: int,\n",
    "                 seq_len: int,\n",
    "                 max_seq_len: Optional[int] = None,\n",
    "                 n_layers: int = 3,\n",
    "                 d_model: int = 128,\n",
    "                 n_heads: int = 16,\n",
    "                 d_k: Optional[int] = None,\n",
    "                 d_v: Optional[int] = None,\n",
    "                 d_ff: int = 256,\n",
    "                 dropout: float = 0.1,\n",
    "                 act: str = \"gelu\",\n",
    "                 fc_dropout: float = 0.,\n",
    "                 y_range: Optional[tuple] = None,\n",
    "                 verbose: bool = False,\n",
    "                 sample_embeddings: List[Tuple[int, int]] = [],\n",
    "                 c_in_future: int = 0,\n",
    "                 seq_len_future: int = 0,\n",
    "                 conv_mul: int = 2,\n",
    "                 virtual_channels: int = 16,\n",
    "                 **kwargs):\n",
    "        r\"\"\"TST (Time Series Transformer) is a Transformer that takes continuous time series as inputs.\n",
    "        As mentioned in the paper, the input must be standardized by_var based on the entire training set.\n",
    "        Args:\n",
    "            c_in: the number of features (aka variables, dimensions, channels) in the time series dataset.\n",
    "            c_out: the number of target classes.\n",
    "            seq_len: number of time steps in the time series.\n",
    "            max_seq_len: useful to control the temporal resolution in long time series to avoid memory issues.\n",
    "            d_model: total dimension of the model (number of features created by the model)\n",
    "            n_heads:  parallel attention heads.\n",
    "            d_k: size of the learned linear projection of queries and keys in the MHA. Usual values: 16-512. Default: None -> (d_model/n_heads) = 32.\n",
    "            d_v: size of the learned linear projection of values in the MHA. Usual values: 16-512. Default: None -> (d_model/n_heads) = 32.\n",
    "            d_ff: the dimension of the feedforward network model.\n",
    "            dropout: amount of residual dropout applied in the encoder.\n",
    "            act: the activation function of intermediate layer, relu or gelu.\n",
    "            n_layers: the number of sub-encoder-layers in the encoder.\n",
    "            fc_dropout: dropout applied to the final fully connected layer.\n",
    "            y_range: range of possible y values (used in regression tasks).\n",
    "            kwargs: nn.Conv1d kwargs. If not {}, a nn.Conv1d with those kwargs will be applied to original time series.\n",
    "        Input shape:\n",
    "            bs (batch size) x nvars (aka features, variables, dimensions, channels) x seq_len (aka time steps)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        ##embeddings\n",
    "        out_dim_embdedding = 0\n",
    "        self.embeddings = []\n",
    "        use_combine = False\n",
    "        for e in sample_embeddings:\n",
    "            self.embeddings.append(nn.Embedding(e[0], e[1] if e[1] > 0 else 1))\n",
    "            out_dim_embdedding += e[1]\n",
    "            use_combine = True\n",
    "        self.embeddings = nn.ModuleList(self.embeddings)\n",
    "        if seq_len_future < 4:\n",
    "            self.futuro = nn.Sequential(Flatten(), nn.Linear(seq_len_future * c_in_future, seq_len_future * c_in_future // 2),\n",
    "                                        nn.BatchNorm1d(seq_len_future * c_in_future // 2), nn.ReLU(),\n",
    "                                        nn.Linear(seq_len_future * c_in_future // 2, seq_len_future * c_in_future // 4),\n",
    "                                        nn.BatchNorm1d(seq_len_future * c_in_future // 4), nn.ReLU())\n",
    "            self.out_dim_futuro = seq_len_future * c_in_future // 4\n",
    "            use_combine = True\n",
    "        else:\n",
    "            if seq_len_future > 0:\n",
    "                self.futuro = nn.Sequential(\n",
    "                    nn.Conv1d(in_channels=c_in_future,\n",
    "                              out_channels=c_in_future * conv_mul,\n",
    "                              kernel_size=3,\n",
    "                              stride=1,\n",
    "                              padding=0,\n",
    "                              dilation=1,\n",
    "                              bias=True,\n",
    "                              padding_mode='zeros'), nn.BatchNorm1d(c_in_future * conv_mul), nn.ReLU(),\n",
    "                    nn.Conv1d(in_channels=c_in_future * conv_mul,\n",
    "                              out_channels=1,\n",
    "                              kernel_size=1,\n",
    "                              stride=1,\n",
    "                              padding=0,\n",
    "                              dilation=1,\n",
    "                              bias=True,\n",
    "                              padding_mode='zeros'), nn.BatchNorm1d(1), nn.ReLU(), Flatten())\n",
    "                out_dim_futuro = np.prod(list(get_output_shape(self.futuro, (1, c_in_future, seq_len_future))))\n",
    "                use_combine = True\n",
    "            else:\n",
    "                out_dim_futuro = 0\n",
    "            self.out_dim_futuro = out_dim_futuro\n",
    "        self.combine = nn.Linear(out_dim_futuro + out_dim_embdedding, virtual_channels)\n",
    "        if use_combine:\n",
    "            c_in += virtual_channels\n",
    "        ##parte copiata da tsai\n",
    "        self.c_out, self.seq_len = c_out, seq_len\n",
    "\n",
    "        # Input encoding\n",
    "        q_len = seq_len\n",
    "        self.new_q_len = False\n",
    "        if max_seq_len is not None and seq_len > max_seq_len:  # Control temporal resolution\n",
    "            self.new_q_len = True\n",
    "            q_len = max_seq_len\n",
    "            tr_factor = math.ceil(seq_len / q_len)\n",
    "            total_padding = (tr_factor * q_len - seq_len)\n",
    "            padding = (total_padding // 2, total_padding - total_padding // 2)\n",
    "            self.W_P = nn.Sequential(Pad1d(padding), Conv1d(c_in, d_model, kernel_size=tr_factor, stride=tr_factor))\n",
    "            pv(f'temporal resolution modified: {seq_len} --> {q_len} time steps: kernel_size={tr_factor}, stride={tr_factor}, padding={padding}.\\n',\n",
    "               verbose)\n",
    "        elif kwargs:\n",
    "            self.new_q_len = True\n",
    "            t = torch.rand(1, 1, seq_len)\n",
    "            q_len = nn.Conv1d(1, 1, **kwargs)(t).shape[-1]\n",
    "            self.W_P = nn.Conv1d(c_in, d_model, **kwargs)  # Eq 2\n",
    "            pv(f'Conv1d with kwargs={kwargs} applied to input to create input encodings\\n', verbose)\n",
    "        else:\n",
    "            self.W_P = nn.Linear(c_in, d_model)  # Eq 1: projection of feature vectors onto a d-dim vector space\n",
    "\n",
    "        # Positional encoding\n",
    "        W_pos = torch.empty((q_len, d_model))\n",
    "        nn.init.uniform_(W_pos, -0.02, 0.02)\n",
    "        self.W_pos = nn.Parameter(W_pos, requires_grad=True)\n",
    "\n",
    "        # Residual dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = _TSTEncoder(q_len, d_model, n_heads, d_k=d_k, d_v=d_v, d_ff=d_ff, dropout=dropout, activation=act, n_layers=n_layers)\n",
    "        self.flatten = Flatten()\n",
    "\n",
    "        # Head\n",
    "        self.head_nf = q_len * d_model\n",
    "\n",
    "        ##Il loro layer esce con c_out (tipo classi) noi facciamo regressione e mi serve anche il pezzo degli embedding e futuro\n",
    "        self.head = self.create_head(self.head_nf, self.head_nf, act=act, fc_dropout=fc_dropout, y_range=y_range)\n",
    "\n",
    "        ##fine parte copiata,\n",
    "        N = out_dim_embdedding + self.out_dim_futuro + self.head_nf\n",
    "        self.last = nn.Sequential(nn.Linear(N, N // 2), nn.BatchNorm1d(N // 2), nn.ReLU(), nn.Linear(N // 2, N // 4), nn.BatchNorm1d(N // 4),\n",
    "                                  nn.ReLU(), nn.Linear(N // 4, c_out))\n",
    "\n",
    "    def create_head(self, nf, c_out, act=\"gelu\", fc_dropout=0., y_range=None, **kwargs):\n",
    "        layers = [get_activation_fn(act), Flatten()]\n",
    "        if fc_dropout:\n",
    "            layers += [nn.Dropout(fc_dropout)]\n",
    "        layers += [nn.Linear(nf, c_out)]\n",
    "        if y_range:\n",
    "            layers += [SigmoidRange(*y_range)]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: Tensor, x_e: Optional[Tensor], x_f: Optional[Tensor], mask: Optional[Tensor] = None) -> Tensor:  # x: [bs x nvars x q_len]\n",
    "\n",
    "        tmp = []\n",
    "        if len(self.embeddings) > 0:\n",
    "            for e in self.embeddings:\n",
    "                tmp.append(e(x_e))\n",
    "        if self.out_dim_futuro:\n",
    "            tmp.append(self.futuro(x_f))\n",
    "        if len(tmp) > 0:\n",
    "            tmp = torch.cat(tmp, 1)\n",
    "            tmp = self.combine(tmp)\n",
    "            tmp = tmp.unsqueeze(2).repeat(1, 1, x.size(2))\n",
    "            x = torch.cat([x, tmp], 1)\n",
    "        # Input encoding\n",
    "        if self.new_q_len:\n",
    "            u = self.W_P(x).transpose(2, 1)  # Eq 2        # u: [bs x d_model x q_len] transposed to [bs x q_len x d_model]\n",
    "        else:\n",
    "            u = self.W_P(x.transpose(2, 1))  # Eq 1                     # u: [bs x q_len x nvars] converted to [bs x q_len x d_model]\n",
    "\n",
    "        # Positional encoding\n",
    "        u = self.dropout(u + self.W_pos)\n",
    "\n",
    "        # Encoder\n",
    "        z = self.encoder(u)  # z: [bs x q_len x d_model]\n",
    "        z = z.transpose(2, 1).contiguous()  # z: [bs x d_model x q_len]\n",
    "\n",
    "        # Classification/ Regression head\n",
    "        tmp = [self.head(z)]\n",
    "        if len(self.embeddings) > 0:\n",
    "            for e in self.embeddings:\n",
    "                tmp.append(e(x_e))\n",
    "        if self.out_dim_futuro:\n",
    "            tmp.append(self.futuro(x_f))\n",
    "        #import pdb\n",
    "        #pdb.set_trace()\n",
    "        z = self.last(torch.cat(tmp, 1))\n",
    "\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf71997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c50ed25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pickle \n",
    "from torch.nn import functional as F\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import logging\n",
    "import os\n",
    "class EarlyStopper:\n",
    "    def __init__(\n",
    "        self,\n",
    "        patience: int,\n",
    "        verbose: Optional[bool] = False,\n",
    "        delta: Optional[float] = 0,\n",
    "        log_path: Optional[str] = \"\",\n",
    "        run_name: Optional[str] = \"\",\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "            patience: int = How long to wait after last time validation loss\n",
    "                            improvment\n",
    "            verbose: bool = If True, prints a message for each validation loss\n",
    "                            improvement\n",
    "            delta: float = Minimum change in the monitored quantity to qualify\n",
    "                           as an improvement.\n",
    "            log_path: str = directory where checkpoints will be saved\n",
    "            run_name: str = run name used to checkpoint filename\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.log_path = log_path\n",
    "        self.run_name = run_name\n",
    "\n",
    "    def __call__(self, val_loss: float, model: torch.nn.Module) -> None:\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "            val_loss: flaot = loss value for a specific epoch\n",
    "            model: torch.nn.Module = model\n",
    "        \"\"\"\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                logging.info(f\"EarlyStopper counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss: float, model: torch.nn.Module) -> None:\n",
    "        \"\"\"\n",
    "        Saves model when validation loss decrease\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "            val_loss: flaot = loss value for a specific epoch\n",
    "            model: torch.nn.Module = model\n",
    "        \"\"\"\n",
    "        name_checkpoint = self.run_name + \"_early_stop.pth\"\n",
    "        if self.verbose:\n",
    "            logging.info(f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...\")\n",
    "        torch.save(model.state_dict(), os.path.join(self.log_path, name_checkpoint))\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "class get_batch(Dataset):\n",
    "    def __init__(self, x, x_f,x_e, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.x_f = x_f\n",
    "        self.x_e = x_e\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = {\n",
    "            'x': self.x[idx],\n",
    "            'y': self.y[idx],\n",
    "            'x_f': self.x_f[idx],\n",
    "            'x_e': self.x_e[idx]\n",
    "        }\n",
    "        \n",
    "        return sample\n",
    "        \n",
    "\n",
    "lr = 0.5\n",
    "early_stopping = 30\n",
    "path = 'res'\n",
    "filename = 'prova.pth'\n",
    "bs = 32\n",
    "epochs =10 \n",
    "with open('train.pkl', 'rb') as f:\n",
    "    x_train, x_futuro_train, y_train = pickle.load(f)\n",
    "    x_e_train = x_train[:,0,0].astype(int)\n",
    "    x_train =  x_train[:,1:,:]\n",
    "    x_futuro_train =  x_futuro_train[:,1:,:]\n",
    "with open('val.pkl', 'rb') as f:\n",
    "    x_val, x_futuro_val, y_val = pickle.load(f)\n",
    "    x_e_val = x_val[:,0,0].astype(int)\n",
    "    x_val = x_val[:,1:,:]\n",
    "    x_futuro_val =  x_futuro_val[:,1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c35c5ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TST( c_in=x_train.shape[1], c_out=1, seq_len=x_train.shape[2],sample_embeddings=[(x_e_train.max()+1,2*x_e_train.max())],\n",
    "            c_in_future=x_futuro_val.shape[1], seq_len_future=x_futuro_val.shape[2],n_layers=3,\n",
    "                 d_model=128,\n",
    "                 n_heads=16,\n",
    "          virtual_channels=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbafb64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10, loss: 0.00444293, valid_rmse: 0.15047489\n",
      "Epoch: 2/10, loss: 0.00257830, valid_rmse: 0.14944267\n",
      "Epoch: 3/10, loss: 0.00225603, valid_rmse: 0.14797173\n",
      "Epoch: 4/10, loss: 0.00209308, valid_rmse: 0.14438699\n",
      "Epoch: 5/10, loss: 0.00199425, valid_rmse: 0.14187007\n",
      "Epoch: 6/10, loss: 0.00192051, valid_rmse: 0.14176992\n",
      "Epoch: 7/10, loss: 0.00187164, valid_rmse: 0.14252909\n",
      "Epoch: 8/10, loss: 0.00183287, valid_rmse: 0.14534767\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-75937cbbeefc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x_e'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x_f'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-d7a462e95234>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, x_e, x_f, mask)\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m             \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m             \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "    \n",
    "\n",
    "    \n",
    "train_dl = DataLoader(get_batch(x_train, x_futuro_train,x_e_train, y_train), batch_size=bs, shuffle=True, drop_last=True, num_workers=0)\n",
    "val_dl = DataLoader(get_batch(x_val, x_futuro_val,x_e_val, y_val), batch_size=bs, shuffle=False, drop_last=True, num_workers=0)\n",
    "\n",
    "\n",
    "loss_f = nn.L1Loss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr)  #, weight_decay=0.0005, nesterov=True, momentum=0.9)  #SGD\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lambda x: lr * (1. + 0.0003 * float(x))**(-0.75))\n",
    "\n",
    "#scheduler = None\n",
    "if early_stopping is not None:\n",
    "    early_stopper = EarlyStopper(\n",
    "        patience=early_stopping,\n",
    "        log_path=path,\n",
    "        run_name=filename,\n",
    "    )\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_samples = 0\n",
    "    epoch_loss = 0.0\n",
    "    for d in train_dl:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(d['x'],d['x_e'], d['x_f'])\n",
    "        loss = loss_f(outputs, d['y'])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_samples += len(d['x'])\n",
    "        epoch_loss += loss\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "    epoch_loss /= epoch_samples\n",
    "\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    targets = []\n",
    "    for d in val_dl:\n",
    "        outputs.append(model(d['x'],d['x_e'], d['x_f']).detach().numpy().flatten())\n",
    "        targets.append(d['y'].flatten())\n",
    "    outputs = np.hstack(outputs).flatten()\n",
    "    y = np.hstack(targets).flatten()\n",
    "\n",
    "    valid_rmse = np.sqrt(mean_squared_error(outputs, y))\n",
    "\n",
    "    if early_stopping is not None:\n",
    "\n",
    "        early_stopper(valid_rmse, model)\n",
    "        if early_stopper.early_stop:\n",
    "            logging.info(\"Early stopper activated. Exit...\")\n",
    "            break\n",
    "\n",
    "    print(f'Epoch: {epoch+1}/{epochs}, loss: { epoch_loss:.8f}, valid_rmse: {valid_rmse:.8f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bff4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch: 1/10, loss: 0.00422143, valid_rmse: 0.15405713\n",
    "Epoch: 2/10, loss: 0.00260175, valid_rmse: 0.14514244\n",
    "Epoch: 3/10, loss: 0.00226576, valid_rmse: 0.15606090\n",
    "Epoch: 4/10, loss: 0.00209538, valid_rmse: 0.14184056\n",
    "Epoch: 5/10, loss: 0.00200051, valid_rmse: 0.14208730\n",
    "Epoch: 6/10, loss: 0.00192406, valid_rmse: 0.13974003\n",
    "Epoch: 7/10, loss: 0.00185898, valid_rmse: 0.14025766\n",
    "Epoch: 8/10, loss: 0.00179434, valid_rmse: 0.13760763\n",
    "Epoch: 9/10, loss: 0.00174920, valid_rmse: 0.14342999\n",
    "Epoch: 10/10, loss: 0.00170894, valid_rmse: 0.13879022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718c7d72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
