# @package _global_
ts:
  version: 1
  name: stacked
  type: stacked
  enrich: []
  use_covariates: false ##does not matter but it is mandatory
  
model:
  type: linear
  retrain: true

##where are the initial model
stack:
  #models: config_test
  models: ['config_used/'tft2_test_1_loss_type=std_normpersistence_weight=1.yaml','config_used/crossformer_test_1_loss_type=std_penpersistence_weight=10.yaml','config_used/mymodel_test_1.yaml','config_used/rnn_gru_1.yaml']
  dirpath: "/home/agobbi/Projects/ExpTS/incube"
  set: 'test'
  name: 'prova'
  rescaling: true

model_configs:
  quantiles: [0.1,0.5,0.9]
  cat_emb_dim: 128
  hidden_RNN: 128
  num_layers_RNN: 2
  kernel_size: 3
  kind: 'gru'
  sum_emb: true
  use_bn: false  
  optim: torch.optim.Adam
  activation: torch.nn.PReLU
  dropout_rate: 0.4
  persistence_weight: 0.010
  loss_type: 'l1'
  remove_last: true



split_params:
  perc_train: 0.8
  perc_valid: 0.2
  past_steps: null
  starting_point: null
  future_steps: null


train_config:
  batch_size: 64
  max_epochs: 1000

