# @package _global_

model:
  type: 'informer'
  retrain: true
ts:
  name: ${dataset.dataset}
  version: 1
  enrich: ['hour']
  use_covariates: true


model_configs:
  d_model: 64
  hidden_size: 64
  n_layer_encoder: 4
  n_layer_decoder: 4
  n_head: 4
  dropout_rate: 0.5
  optim: torch.optim.Adam
  activation: torch.nn.PReLU
  persistence_weight: 0.010
  loss_type: 'l1'
  remove_last: true

train_config:
  batch_size: 64
  max_epochs: 100
            
split_params:
  shift:  ${model_configs.future_steps}
  keep_entire_seq_while_shifting: true