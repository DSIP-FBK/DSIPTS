# @package _global_

model:
  type: 'mymodel'
  retrain: true
ts:
  name: 'mymodel'
  version: 1
  enrich: []
  use_covariates: true

model_configs:
  cat_emb_dim: 256
  hidden_RNN: 128
  num_layers_RNN: 4
  kernel_size: 5
  kind: 'gru'
  sum_emb: true
  persistence_weight: 0.5
  use_bn: false
  use_glu: false
  glu_percentage: 0.2
  quantiles: [0.1,0.5,0.9]
  optim: torch.optim.SGD
  activation: torch.nn.LeakyReLU
  loss_type: 'linear_penalization'

train_config:
  batch_size: 64
  max_epochs: 250
  gradient_clip_val: null
  gradient_clip_algorithm: 'norm'
